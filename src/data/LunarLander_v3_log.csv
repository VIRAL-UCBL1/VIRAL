path;env;llm;llm_param;algo;algo_param;total_timesteps;reward_function;rewards;mean_reward;std_reward;sr
data/model/LunarLander-v3_700272_1.pth;LunarLander-v3;qwen2.5-coder_llama3.2-vision;{'seed': 700272};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'model/LunarLanderDQN/', 'seed': 700272};300000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    # Extract relevant observations
    x_pos = observations[0]
    y_pos = observations[1]
    linear_vel_x = observations[2]
    linear_vel_y = observations[3]
    angle = observations[4]

    # Define target area around the red trajectory (example values)
    target_radius = 5.0
    target_center_x = 0.0
    target_center_y = -10.0

    # Calculate distance from target center
    distance_to_target = np.sqrt((x_pos - target_center_x)**2 + (y_pos - target_center_y)**2)

    # Define reward components
    proximity_reward = -distance_to_target  # Reward for being closer to the target
    velocity_reward = -(np.abs(linear_vel_x) + np.abs(linear_vel_y)) / 10.0  # Penalize high velocities
    orientation_reward = -np.abs(angle) / (np.pi / 2)  # Penalize large angles

    # Combine rewards
    total_reward = proximity_reward + velocity_reward + orientation_reward

    # Adjust reward based on success or failure conditions
    if is_success:
        total_reward += 100.0  # Large reward for successfully landing
    elif is_failure:
        total_reward -= 50.0  # Penalty for failing to land

    return total_reward";-0.019435298,-0.031667475,-0.01738622,-0.026346963,-0.031768326,-0.028724384,-0.032096297,-0.028825272,-0.028547958,-0.039472986,-0.029423704,-0.035277598,-0.034619406,-0.019565828,-0.021191353,-0.022524886,-0.022356546,-0.028316924,-0.02418166,-0.030779125,-0.023246458,-0.022175306,-0.022953827,-0.027022272,-0.023237634,-0.03658909,-0.0224737,-0.038531166,-0.03622853,-0.023896083,-0.022946762,-0.024340166,-0.029849613,-0.026127642,-0.023862395,-0.018241525,-0.030616485,-0.023925478,-0.019084822,-0.032582026,-0.037939023,-0.022333667,-0.021940378,-0.026667751,-0.029887075,-0.031093515,-0.01864217,-0.020955006,-0.021433618,-0.0244398,-0.017553998,-0.022638602,-0.025988499,-0.018293884,-0.021435598,-0.019068304,-0.027105644,-0.032069795,-0.022846894,-0.024296684,-0.025903096,-0.021882847,-0.018100962,-0.021374362,-0.025875611,-0.026330099,-0.029317802,-0.024637803,-0.029988796,-0.036551997,-0.02029962,-0.02261572,-0.02786023,-0.02968537,-0.017969247,-0.019896252,-0.019395985,-0.02090116,-0.025884682,-0.019681565,-0.019650858,-0.030503297,-0.023256227,-0.023244997,-0.033301145,-0.021703647,-0.029394269,-0.018074056,-0.025371164,-0.020554287,-0.025982812,-0.027614597,-0.027560188,-0.030573973,-0.026910564,-0.016634958,-0.015886571,-0.023164276,-0.024510387,-0.019193528,-0.021610046,-0.017261,-0.023546174,-0.023222992,-0.027731137,-0.030172423,-0.026567943,-0.019295394,-0.027896276,-0.028727962,-0.031596683,-0.022846742,-0.032205626,-0.023218418,-0.016894536,-0.026776208,-0.016239718,-0.028249329,-0.01879641,-0.019405529,-0.026186137,-0.029265195,-0.025017982,-0.02102459,-0.018098438,-0.016845267,-0.016699642,-0.023109801,-0.017237583,-0.029465625,-0.01989049,-0.019799644,-0.028033914,-0.016617635,-0.018114615,-0.01920333,-0.023987535,-0.017170547,-0.027735561,-0.027365852,-0.024359645,-0.016729372,-0.025895512,-0.026998322,-0.019712025,-0.018743316,-0.024006596,-0.020957526,-0.018315926,-0.022754302,-0.026134284,-0.019777479,-0.028331337,-0.01747041,-0.02645632,-0.022793846,-0.029987821,-0.023687588,-0.023475558,-0.026490664,-0.019731693,-0.01900006,-0.020011073,-0.017846214,-0.017232394,-0.025823396,-0.020072587,-0.020091921,-0.024187779,-0.025905449,-0.023139095,-0.019707745,-0.016987566,-0.019678265,-0.02130269,-0.018161964,-0.019805666,-0.023162263,-0.025197785,-0.027634585,-0.024709456,-0.019967502,-0.027849112,-0.01592789,-0.020160418,-0.023865927,-0.020323938,-0.027529653,-0.020342302,-0.028333524,-0.016673721,-0.018490484,-0.024916016,-0.015967244,-0.021961894,-0.018064955,-0.025595177,-0.016491551,-0.018076183,-0.018612823,-0.019006897,-0.018437617,-0.01743559,-0.02601287,-0.021202281,-0.017424148,-0.016569722,-0.02423221,-0.021539902,-0.02409392,-0.026360467,-0.022142168,-0.017637849,-0.015949138,-0.017718308,-0.024236158,-0.028183803,-0.016036326,-0.017389134,-0.022588396,-0.026198983,-0.016679375,-0.017217517,-0.017932393,-0.01629437,-0.021197546,-0.02521551,-0.02486128,-0.016485138,-0.02491048,-0.016721636,-0.02389622,-0.026469631,-0.02422636,-0.016964784,-0.02321307,-0.01710858,-0.02368557,-0.02202948,-0.020127455,-0.021723898,-0.022330645,-0.02226699,-0.02028897,-0.021130146,-0.016467506,-0.02044671,-0.015524109,-0.01873615,-0.019883664,-0.02100054,-0.019454537,-0.01743843,-0.02224668,-0.01778921,-0.018184153,-0.023302862,-0.025284346,-0.025889695,-0.024594458,-0.016635384,-0.017726773,-0.025244743,-0.019028304,-0.024924291,-0.0190721,-0.020167148,-0.017356128,-0.02397825,-0.024030738,-0.022283932,-0.016766261,-0.017331205,-0.01658448,-0.022981117,-0.028540386,-0.022218412,-0.02279129,-0.016021308,-0.019519093,-0.020467674,-0.027711533,-0.021556716,-0.021759473,-0.025636576,-0.020418234,-0.020805608,-0.016316116,-0.016175658,-0.017177027,-0.025447184,-0.021471795,-0.021877384,-0.026867392,-0.026494369,-0.018644221,-0.016954385,-0.016835699,-0.01684075,-0.022922428,-0.017137427,-0.020855721,-0.016964741,-0.024535714,-0.020999556,-0.0211913,-0.0290515,-0.025871009,-0.029089995,-0.020254984,-0.019957576,-0.024575252,-0.018071739,-0.023322877,-0.029015422,-0.02311353,-0.024904927,-0.018244741,-0.017486408,-0.025344074,-0.019140447,-0.020331644,-0.016888278,-0.02363242,-0.023408111,-0.020010628,-0.020164844,-0.020381842,-0.029023116,-0.023340018,-0.019374045,-0.019758511,-0.021611061,-0.016231956,-0.02320946,-0.025899462,-0.027954726,-0.019833345,-0.016754318,-0.016136102,-0.0181294,-0.017905748,-0.024233665,-0.02321495,-0.02372863,-0.019463388,-0.023181878,-0.018142926,-0.017480453,-0.02785478,-0.019764848,-0.021753255,-0.02517374,-0.016190443,-0.029579207,-0.028564118,-0.02415852,-0.015590761,-0.018471375,-0.02011678,-0.01565589,-0.019850397,-0.0212236,-0.018823896,-0.025739692,-0.0234529,-0.023610452,-0.01630998,-0.023905922,-0.020450315,-0.023697684,-0.01681618,-0.016387708,-0.015316627,-0.02513286,-0.021747516,-0.018248111,-0.016580483,-0.02365333,-0.028446006,-0.022112757,-0.01609403,-0.024559943,-0.027956948,-0.019251782,-0.027430272,-0.017067924,-0.040164497,-0.019917876,-0.025823193,-0.019095158,-0.017585438,-0.024222368,-0.018235395,-0.023198828,-0.025385957,-0.019217208,-0.028686203,-0.024574177,-0.020627629,-0.01896235,-0.024795806,-0.022154797,-0.017362978,-0.020105854,-0.019229554,-0.021407008,-0.027676063,-0.020398224,-0.027442452,-0.017451564,-0.017766345,-0.019826412,-0.02047637,-0.019297661,-0.022205891,-0.017989464,-0.016878398,-0.027754141,-0.018807653,-0.021377442,-0.021013869,-0.01975972,-0.023853038,-0.018006308,-0.017600331,-0.027043162,-0.027575178,-0.024974983,-0.019770032,-0.017170731,-0.027837573,-0.018934943,-0.021472622,-0.01783959,-0.023283394,-0.021926666,-0.019392587,-0.017161088,-0.02089972,-0.02185556,-0.017969528,-0.020067995,-0.020114923,-0.018718373,-0.024416333,-0.017697267,-0.02255717,-0.018958863,-0.021467723,-0.024752522,-0.017044809,-0.018982075,-0.027422346,-0.024951985,-0.016068088,-0.015617891,-0.023816805,-0.020525828,-0.024654124,-0.021326728,-0.020036874,-0.019114036,-0.02534376,-0.017620783,-0.024512818,-0.016980505,-0.028011257,-0.019651975,-0.02242501,-0.020464895,-0.02093058,-0.022902647,-0.01891578,-0.024213228,-0.026409531,-0.017867347,-0.027731717,-0.017229514,-0.028886316,-0.016979178,-0.01750342,-0.027190797,-0.022922067,-0.016444674,-0.025857076,-0.021664418,-0.018915385,-0.015503166,-0.028205113,-0.024324724,-0.01637031,-0.02215837,-0.021806465,-0.018466007,-0.022664733,-0.02199813,-0.023925204,-0.027400086,-0.02273324,-0.025902841,-0.020712141,-0.026965465,-0.024303934,-0.024574012,-0.016505217,-0.025828674,-0.016163832,-0.017626958,-0.027645785,-0.021513818,-0.024489323,-0.017659087,-0.017740564,-0.028153248,-0.026113778,-0.027646333,-0.01569261,-0.016859671,-0.01654777,-0.020367222,-0.026889967,-0.016262237,-0.017847907,-0.016276466,-0.021142447,-0.022622721,-0.01937098,-0.018835755,-0.028576475,-0.02740914,-0.016628448,-0.02105839,-0.026183423,-0.02069153,-0.018537644,-0.028230563,-0.025326615,-0.017457807,-0.017911118,-0.025264448,-0.019203268,-0.018007679,-0.016572064,-0.0159928,-0.016894313,-0.0249391,-0.020017043,-0.026665742,-0.023345625,-0.022195254,-0.024678364,-0.028602945,-0.016612012,-0.01800697,-0.01847508,-0.027367242,-0.018709555,-0.018999446,-0.022667266,-0.017291531,-0.019235572,-0.018829107,-0.016151642,-0.021801177,-0.026235731,-0.02724346,-0.017216446,-0.017702764,-0.019681802,-0.022231473,-0.020929402,-0.025160266,-0.020266613,-0.025009453,-0.026640212,-0.026702154,-0.030251032,-0.026285755,-0.017013716,-0.016075496,-0.023524186,-0.020629523,-0.017867688,-0.020764636,-0.021308132,-0.017885955,-0.016610844,-0.017042069,-0.01953393,-0.020696638,-0.023949273,-0.02099035,-0.024390193,-0.017983554,-0.026773557,-0.016574427,-0.023827778,-0.0243315,-0.027361587,-0.023789834,-0.020650286,-0.016970854,-0.02364909,-0.025052832,-0.022294175,-0.023223486,-0.027147897,-0.0246812,-0.026456408,-0.01594004,-0.02327471,-0.021360356,-0.02242896,-0.027613595,-0.022034641,-0.026980918,-0.016723845,-0.024305033,-0.027076302,-0.023673406,-0.017591981,-0.023877064,-0.020042097,-0.017849952,-0.019226892,-0.028094616,-0.025311954,-0.016144136,-0.025690828,-0.015686687,-0.025089273,-0.02040152,-0.020588629,-0.027652163,-0.02074852,-0.023594147,-0.020341527,-0.019618262,-0.016092202,-0.024945322,-0.018000294,-0.016149791,-0.020685693,-0.017060684,-0.02715887,-0.024940256,-0.017330773,-0.025267644,-0.016888324,-0.027255565,-0.017211001,-0.022951726,-0.023208827,-0.01954878,-0.01611127,-0.020356346,-0.026231475,-0.021164117,-0.02491529,-0.01837873,-0.02240186,-0.025279947,-0.02699691,-0.017369686,-0.020423839,-0.018324763,-0.019880988,-0.02100833,-0.019989207,-0.019874912,-0.016608495,-0.019822722,-0.019475413,-0.023582922,-0.021652773,-0.034400903,-0.022618284,-0.016814593,-0.022986906,-0.026842715,-0.026406635,-0.018810896,-0.023401372,-0.01718697,-0.018421004,-0.025903303,-0.023495864,-0.02212729,-0.019389909,-0.028558234,-0.025503933,-0.027656386,-0.022491323,-0.021948101,-0.026258098,-0.019179896,-0.02696663,-0.016100641,-0.025170723,-0.022833494,-0.016634837,-0.028537361,-0.018586153,-0.026869515,-0.023330383,-0.02003589,-0.02170377,-0.0155859105,-0.016641568,-0.023587976,-0.023341343,-0.019095536,-0.021481233,-0.018502655,-0.017485388,-0.018231653,-0.018819315,-0.021274582,-0.021439306,-0.020705096,-0.022222469,-0.02561062,-0.021729216,-0.017086048,-0.022013789,-0.016119685,-0.020189648,-0.026405081,-0.016490154,-0.017989157,-0.01894599,-0.018695058,-0.019365462,-0.01956756,-0.01756216,-0.025072893,-0.022677278,-0.02377644,-0.025681697,-0.01957891,-0.022075867,-0.019305933,-0.019975154,-0.022029163,-0.018720914,-0.020052208,-0.0241322,-0.02056318,-0.016950814,-0.02120501,-0.01772764,-0.023545302,-0.024482127,-0.022628587,-0.025726812,-0.018884337,-0.02440418,-0.025851447,-0.024353491,-0.02321386,-0.018373914,-0.017501747,-0.023209123,-0.018666346,-0.025164764,-0.02132663,-0.0280042,-0.017536677,-0.020473203,-0.022132477,-0.021968052,-0.028476406,-0.023152284,-0.02203106,-0.021967642,-0.023575699,-0.021475498,-0.026687665,-0.016132805,-0.02042706,-0.020471573,-0.024781864,-0.020545805,-0.016802246,-0.026711907,-0.016939452,-0.019356309,-0.021409925,-0.018145908,-0.020890346,-0.021048075,-0.02114907,-0.021150466,-0.018059347,-0.022152893,-0.018236164,-0.016159661,-0.016971502,-0.019846542,-0.018455701,-0.020782612,-0.018846659,-0.017531853,-0.023993254,-0.018529069,-0.01686145,-0.01711753,-0.021202005,-0.018000072,-0.022415465,-0.016649393,-0.021687042,-0.021873755,-0.024211818,-0.017123368,-0.019322544,-0.028290054,-0.023496829,-0.024032254,-0.022824826,-0.020493073,-0.01885055,-0.01963432,-0.01872458,-0.025640802,-0.01682631,-0.015349168,-0.022896942,-0.025812792,-0.022348138,-0.02174129,-0.018932775,-0.025244977,-0.0206739,-0.01819933,-0.025953827,-0.019084722,-0.0248151,-0.02200511,-0.0164977,-0.016811525,-0.018755982,-0.018006934,-0.024154676,-0.016668055,-0.018025031,-0.0241094,-0.025426537,-0.022796543,-0.015875185,-0.018421244,-0.018445399,-0.025866875,-0.026857119,-0.016552282,-0.02121107,-0.015666457,-0.024263727,-0.021802127,-0.02232496,-0.020179996,-0.016248174,-0.021331921,-0.016013969,-0.019698286,-0.018937299,-0.016066868,-0.019299919,-0.021469792,-0.025168091,-0.023791136,-0.020377921,-0.023316333,-0.024485763,-0.026211495,-0.0247403,-0.0199777,-0.016057396,-0.01829019,-0.024965161,-0.025638456,-0.019908575,-0.02080129,-0.019953411,-0.023311801,-0.020123776,-0.02163129,-0.022550512,-0.023064585,-0.02712688,-0.020420605,-0.024528569,-0.015849553,-0.019555913,-0.02408261,-0.01839391,-0.023498232,-0.02081223,-0.026588714,-0.02735187,-0.024116764,-0.020620458,-0.01727509,-0.022556607,-0.017658258,-0.024566544,-0.01688656,-0.022782993,-0.016338257,-0.021151224,-0.021800622,-0.02102719,-0.021364138,-0.017774843,-0.021571929,-0.026852539,-0.01934537,-0.023313783,-0.020419165,-0.022541944,-0.017176423,-0.022734541,-0.015492112,-0.023808278,-0.02039642,-0.024356514,-0.019642113,-0.021236446,-0.01912286,-0.023283107,-0.029479126,-0.023768827,-0.019731203,-0.026684245,-0.020272505,-0.026120424,-0.019303119,-0.025964726,-0.016486531,-0.020761432,-0.018246243,-0.023505911,-0.026162038,-0.025087057,-0.016876178,-0.027734239,-0.026723955,-0.02412412,-0.02299562,-0.028903836,-0.01615318,-0.016790055,-0.016734166,-0.023933439,-0.03017602,-0.022163544,-0.0171085,-0.018992413,-0.025698502,-0.019567454,-0.023278369,-0.02740213,-0.017052898,-0.021811394,-0.015574747,-0.017817812,-0.023770468,-0.016845796,-0.017226154,-0.022426216,-0.016094392,-0.023642957,-0.017615797,-0.026212316,-0.033855703,-0.026200563,-0.020621827,-0.025174504,-0.019892216,-0.016127493,-0.01724706,-0.02424649,-0.018578136,-0.026024358,-0.028239852,-0.01586491,-0.021890203,-0.021039518,-0.020152444,-0.023565823,-0.019952385,-0.023193507,-0.024459977,-0.022850761,-0.024882108,-0.016805125,-0.027734546,-0.021895653,-0.018533181,-0.020080116,-0.02011607,-0.022158457,-0.020739462,-0.023585312,-0.01956821,-0.021030845,-0.020072244,-0.025142012,-0.022749886,-0.01675952,-0.01705844,-0.021013856,-0.025442582,-0.017307201,-0.016189976,-0.022801826,-0.019959234,-0.025223523,-0.026655259,-0.018874547,-0.027289372,-0.019341798,-0.015890528,-0.021342393,-0.024393631,-0.025644926,-0.022215532,-0.023926353,-0.022580137,-0.01673196,-0.023130933,-0.020820221,-0.025106352,-0.026484706,-0.018203296,-0.017372742,-0.017981047,-0.018255655,-0.024007564,-0.026770735,-0.021156102,-0.01884197,-0.028965851,-0.03137851,-0.0220539,-0.026428023,-0.019730426,-0.018040525,-0.018893817,-0.016019681,-0.02438937,-0.022660332,-0.019627467,-0.022226766,-0.024177615,-0.020034883,-0.028011892,-0.022876585,-0.021120572,-0.02168494,-0.02449568,-0.021669906,-0.023966648,-0.026351906,-0.023226848,-0.028101753,-0.028172327,-0.02605497,-0.02827546,-0.02625638,-0.019159434,-0.018860223,-0.025641242,-0.020408165,-0.017020386,-0.019867241,-0.025632154,-0.015267371,-0.01652343,-0.01723421,-0.019800406,-0.018683972,-0.016372092,-0.020779317,-0.018197194,-0.027458245,-0.027945306,-0.027907848,-0.016941374,-0.017037177,-0.027080882,-0.02121799,-0.020072445,-0.02122439,-0.021817151,-0.023208018,-0.018818516,-0.026051546,-0.021375373,-0.026795615,-0.026312439,-0.016979465,-0.028317634,-0.020756673,-0.018679354,-0.020076742,-0.024208646,-0.021022156,-0.026032284,-0.021524338,-0.026009634,-0.021711675,-0.019500151,-0.015826046,-0.019522088,-0.020611983,-0.019752907,-0.023670077,-0.019492825,-0.018037573,-0.018094016,-0.022884216,-0.016373327,-0.026333146,-0.02317715,-0.028513916,-0.027850997,-0.025995651,-0.020291232,-0.016627243,-0.018964408,-0.024772495,-0.0175348,-0.020036774,-0.020026213,-0.02306359,-0.024425216,-0.024934502,-0.022660358,-0.02272042,-0.024339681,-0.019298898,-0.019406421,-0.025354618,-0.017007468,-0.019510632,-0.024658745,-0.025378924,-0.023062337,-0.015680116,-0.022929369,-0.020298805,-0.017924083,-0.019456591,-0.021298153,-0.015478907,-0.02506429,-0.016621567,-0.018865105,-0.0245346,-0.020439569,-0.015725898,-0.024678387,-0.016183171,-0.015279351,-0.022604585,-0.018930038,-0.016900685,-0.01800245,-0.02499587,-0.019984556,-0.017438058,-0.018049458,-0.014985528,-0.015532591,-0.018202797,-0.018925525,-0.025847895,-0.024426106,-0.018048914,-0.019430181,-0.02392913,-0.01861624,-0.017118238,-0.015802925,-0.02354854,-0.020348726,-0.025209095,-0.017942332,-0.020997556,-0.018717987,-0.021758229,-0.021489104,-0.02414603,-0.016950596,-0.017491614,-0.02036337,-0.021840237,-0.019790456,-0.023549533,-0.024896747,-0.0227249,-0.018112708,-0.018219573,-0.02273522,-0.0156043675,-0.01811908,-0.023808125,-0.021409165,-0.0209599,-0.026988849,-0.018677773,-0.023373704,-0.020092025,-0.024409276,-0.016517324,-0.01954725,-0.016366944,-0.022150401,-0.02330305,-0.02003803,-0.02441445,-0.019534128,-0.020985968,-0.018498307,-0.026094045,-0.020379994,-0.01614956,-0.015881121,-0.018962374,-0.020968087,-0.022157235,-0.022182861,-0.021940855,-0.022056844,-0.019837767,-0.016746972,-0.01585367,-0.03283527,-0.022890046,-0.022431212,-0.025542052,-0.020614756,-0.016821604,-0.02578539,-0.021037046,-0.021891003,-0.0309894,-0.022465,-0.017131554,-0.023388859,-0.026328705,-0.019349886,-0.017954815,-0.018474117,-0.0241776,-0.016471244,-0.023215711,-0.030647056,-0.02199079,-0.025201526,-0.022404766,-0.023639508,-0.022902813,-0.019527817,-0.015152916,-0.02791629,-0.02738296,-0.020867432,-0.016783925,-0.022279272,-0.01862768,-0.016168965,-0.016181028,-0.020701593,-0.0210482,-0.026806226,-0.021022545,-0.021527192,-0.023609536,-0.018191919,-0.023630422,-0.022454286,-0.027372852,-0.021776298,-0.023231015,-0.021408966,-0.0184123,-0.02551155,-0.019572333,-0.020282496,-0.019210165,-0.022718953,-0.01950777,-0.017450437,-0.017411496,-0.015797397,-0.0175759,-0.016655914,-0.019123228,-0.021047648,-0.026658466,-0.016383393,-0.016327709,-0.024054615,-0.016732354,-0.01875817,-0.016095512,-0.02244274,-0.016838573,-0.025182026,-0.028623922,-0.016420636,-0.024930289,-0.029108793,-0.019816443,-0.015955204,-0.02800946,-0.016476845,-0.022584153,-0.016775178,-0.018738354,-0.01606762,-0.020839665,-0.029787995,-0.018056897,-0.02279287,-0.02979026,-0.018906448,-0.022081465,-0.01571282,-0.016526474,-0.022947595,-0.027586509,-0.028813746,-0.023229256,-0.019854516,-0.02406909,-0.023013739,-0.02189924,-0.022888534,-0.031429697,-0.022560297,-0.020864245,-0.020817544,-0.020075407,-0.023187568,-0.022443637,-0.02048656,-0.019392382,-0.019671012,-0.031549085,-0.017660704,-0.02023438,-0.020002363,-0.016138997,-0.015897235,-0.0241878,-0.022539163,-0.0167238,-0.026398238,-0.019705022,-0.016027931,-0.02206617,-0.022057207,-0.022848457,-0.016467286,-0.02271149,-0.01601291,-0.02344013,-0.019220382,-0.023369597,-0.024916906,-0.02374171,-0.0223708,-0.0205813,-0.017706096,-0.01635879,-0.023885846,-0.02055992,-0.022981595,-0.019757772,-0.021527234,-0.018507442,-0.02322664,-0.021076538,-0.01608642,-0.019854864,-0.0205952,-0.01718083,-0.021648513,-0.020368725,-0.022437526,-0.022048963,-0.017165909,-0.020317467,-0.017223991,-0.04331035,-0.023140589,-0.02317607,-0.021721093,-0.018891202,-0.018898204,-0.016381478,-0.020335611,-0.027044632,-0.019338612,-0.02400221,-0.01977904,-0.019481027,-0.017007027,-0.02030327,-0.017202327,-0.016288063,-0.021187846,-0.020643089,-0.019994922,-0.021226378,-0.026013518,-0.020017426,-0.023511121,-0.015553433,-0.016393377,-0.017468693,-0.020007227,-0.024951763,-0.019881489,-0.016041921,-0.018653376,-0.016887002,-0.026085606,-0.01562463,-0.026200665,-0.023603788,-0.022168774,-0.022031713,-0.0188443,-0.017344633,-0.025106689,-0.016220436,-0.024356887,-0.02179554,-0.017998543,-0.024087109,-0.017705947,-0.022207245,-0.0194593,-0.018710418,-0.017034426,-0.01923908,-0.01901184,-0.016026225,-0.017001955,-0.022005875,-0.018913534,-0.025632074,-0.022185456,-0.024926255,-0.02166401,-0.016779192,-0.025903795,-0.021558195,-0.018661734,-0.015319335,-0.01666695,-0.01706562,-0.018254748,-0.020819046,-0.016888656,-0.022640826,-0.0201046,-0.024782462,-0.023433449,-0.017052397,-0.02213703,-0.016162924,-0.026061049,-0.024218114,-0.019142272,-0.018716265,-0.02163852,-0.023759468,-0.018306892,-0.016919428,-0.015823314,-0.022234347,-0.017857691,-0.018222649,-0.021543482,-0.016923467,-0.017767066,-0.02108336,-0.01931151,-0.02329563,-0.016430683,-0.020165756,-0.016957639,-0.01635711,-0.019413851,-0.0183362,-0.019007659,-0.025425449,-0.02171251,-0.018351968,-0.025109686,-0.018408522,-0.019504828,-0.022836164,-0.027222805,-0.01645464,-0.016686914,-0.018491583,-0.019796846,-0.016654657,-0.023286296,-0.018347919,-0.026503608,-0.023057932,-0.017830359,-0.016935578,-0.017841684,-0.016396752,-0.020773511,-0.020907214,-0.017810393,-0.023348792,-0.028844416,-0.026992636,-0.022121131,-0.016258398,-0.027047155,-0.021489587,-0.019529868,-0.016898789,-0.018649379,-0.024241341,-0.020531502,-0.022318304,-0.02321933,-0.02196909,-0.017555784,-0.02799288,-0.019482492,-0.021936577,-0.019192532,-0.024858305,-0.01896647,-0.026303567,-0.025551092,-0.025118554,-0.025236204,-0.016391085,-0.02145478,-0.022756463,-0.016128633,-0.024151333,-0.018963229,-0.01908379,-0.021722062,-0.016886655,-0.017267944,-0.019438162,-0.021795133,-0.017219106,-0.024342239,-0.022358758,-0.02090489,-0.016987262,-0.022608409,-0.016291693,-0.026640631,-0.019767828,-0.018957956,-0.02078718,-0.023309331,-0.021924725,-0.025030075,-0.0275419,-0.028619876,-0.019466162,-0.020744866,-0.028113559,-0.016691629,-0.021199137,-0.03779856,-0.017846905,-0.020052692,-0.022811698,-0.018952295,-0.02269475,-0.0290834,-0.02408668,-0.020514581,-0.023481842,-0.018737268,-0.016622873,-0.016685579,-0.025719851,-0.02202981,-0.018959256,-0.016178783,-0.016133077,-0.0155541515,-0.01874286,-0.020572878,-0.026945103,-0.015621047,-0.020064563,-0.026867542,-0.022977397,-0.019745851,-0.015412948,-0.019165779,-0.022434045,-0.023054319,-0.025900386,-0.025899634,-0.016251514,-0.020684155,-0.029019311,-0.016157895,-0.019668836,-0.024063716,-0.02148672,-0.017778466,-0.017530093,-0.024271253,-0.017002359,-0.019150494,-0.016156333,-0.016403817,-0.016166555,-0.021282924,-0.018710105,-0.020346288,-0.026366306,-0.01609352,-0.018418284,-0.022401035,-0.027662482,-0.015527403,-0.019193858,-0.026393829,-0.021414248,-0.021724014,-0.016955487,-0.018849617,-0.025397537,-0.017731978,-0.024995903,-0.01732172,-0.018808886,-0.020977728,-0.016410206,-0.015838245,-0.017447686,-0.01766545,-0.023138933,-0.02026512,-0.016795022,-0.016551448,-0.022609575,-0.02088774,-0.020247094,-0.01834443,-0.021238852,-0.02204781,-0.017493473,-0.020650337,-0.021809148,-0.016320031,-0.02203966,-0.021782199,-0.023126908,-0.016707245,-0.025961945,-0.01847559,-0.018894102,-0.019325837,-0.020663626,-0.02070509,-0.025517048,-0.025697384,-0.018660257,-0.02144312,-0.024396388,-0.018228196,-0.018054277,-0.024057131,-0.02160072,-0.016498217,-0.018180573,-0.017816354,-0.01747255,-0.021770991,-0.02236937,-0.021428104,-0.019131763,-0.016504928,-0.022413593,-0.022644315,-0.021322995,-0.016547982,-0.019413315,-0.021105628,-0.023119994,-0.023834312,-0.027050242,-0.020889077,-0.018976793,-0.02557998,-0.018258344,-0.021458322,-0.015601214,-0.023392977,-0.021310983,-0.023603914,-0.022795135,-0.024667006,-0.016494937,-0.022851033,-0.025847314,-0.01801441,-0.018066,-0.017935736,-0.018979952,-0.015566896,-0.024321137,-0.018797169,-0.019431029,-0.020492114,-0.021356627,-0.025015589,-0.024721991,-0.017478852,-0.020350635,-0.021837384,-0.019359417,-0.019920643,-0.017193805,-0.016100746,-0.018361567,-0.01910035,-0.017883722,-0.01774526,-0.022453055,-0.017726421,-0.021158533,-0.02494572,-0.019728353,-0.020114968,-0.016868051,-0.021756766,-0.021533025,-0.017485538,-0.022230862,-0.025182428,-0.022330744,-0.020929527,-0.021025525,-0.017358992,-0.022496283,-0.01910558,-0.016184501,-0.019442419,-0.020789621,-0.017290492,-0.021137288,-0.021202536,-0.018112231,-0.018226696,-0.020004934,-0.024508052,-0.020188669,-0.017839678,-0.021444531,-0.023734894,-0.021245204,-0.016818086,-0.022853855,-0.021808738,-0.02179062,-0.017744588,-0.02315086,-0.018219832,-0.022868337,-0.02008086,-0.018935299,-0.015482934,-0.017429773,-0.023058092,-0.020346817,-0.019156808,-0.026627487,-0.025266923,-0.02239197,-0.026849376,-0.023483168,-0.025550496,-0.020835819,-0.022941278,-0.019523539,-0.016686274,-0.017809087,-0.02232262,-0.021477178,-0.020937923,-0.017987391,-0.01743258,-0.018358758,-0.015797611,-0.021613315,-0.018472277,-0.02133171,-0.020390796,-0.023902638,-0.016366955,-0.025284754,-0.028527701,-0.020916684,-0.01953236,-0.018693773,-0.028270932,-0.017929073,-0.021014912,-0.015903203,-0.017314129,-0.018170308,-0.021976113,-0.015982937,-0.019111067,-0.02457483,-0.022274029,-0.018349785,-0.017193675,-0.026105143,-0.019911677,-0.026829727,-0.01838129,-0.016696783,-0.019142594,-0.027255908,-0.02028275,-0.01835948,-0.020422928,-0.020647395,-0.023344168,-0.022744782,-0.0240353,-0.017078219,-0.019675745,-0.015533033,-0.018357778,-0.026822027,-0.020103762,-0.021994187,-0.027061922,-0.019737612,-0.024330614,-0.018973904,-0.017302204,-0.020106923,-0.019163806,-0.029983977,-0.016080538,-0.023350503,-0.022059478,-0.021828199,-0.016909717,-0.021329127,-0.026481122,-0.017425505,-0.019552507,-0.022658046,-0.02990248,-0.027906075,-0.020768816,-0.019266434,-0.024545768,-0.019859748,-0.019542236,-0.024533534,-0.018060854,-0.0155115845,-0.018651111,-0.020665694,-0.01708542,-0.019995365,-0.01581905,-0.015808525,-0.017783202,-0.016921576,-0.018277729,-0.02040641,-0.022232797,-0.017019598,-0.020879176,-0.017553529,-0.025016742,-0.020897102,-0.016762499,-0.027993254,-0.02631315,-0.020580804,-0.019750752,-0.027101073,-0.0246944,-0.023086797,-0.02091666,-0.020111537,-0.026266648,-0.020457692,-0.019800406,-0.025248941,-0.01831812,-0.028625268,-0.025080761,-0.021828663,-0.024484785,-0.025165454,-0.017822875,-0.02447944,-0.020432208,-0.024473036,-0.026166266,-0.016327165,-0.022158876,-0.017169863,-0.016914817,-0.01861068,-0.024665788,-0.01724868,-0.02179939,-0.018935228,-0.023816338,-0.02168258,-0.016396321,-0.018845547,-0.015793622,-0.017203826,-0.020708455,-0.022008909,-0.025856217,-0.02351141,-0.01999256,-0.022009254,-0.022353508,-0.018609382,-0.017866304,-0.022263667,-0.020909447,-0.020013396,-0.015573566,-0.02616128,-0.02692827,-0.025876097,-0.018915625,-0.01917459,-0.020358475,-0.023474513,-0.019797795,-0.026005512,-0.023045378,-0.023561805,-0.018964184,-0.027355872,-0.015479804,-0.016689168,-0.027064923,-0.0223664,-0.018279754,-0.017501712,-0.020665497,-0.02202,-0.02499556,-0.017775802,-0.021747325,-0.018108817,-0.018585756,-0.01998186,-0.021410478,-0.028310774,-0.02086005,-0.019467339,-0.020999411,-0.023040468,-0.02003058,-0.020428877,-0.021080306,-0.016960204,-0.01716269,-0.016626587,-0.024948118,-0.01682264,-0.019969404,-0.026797708,-0.021265851,-0.0266338,-0.021303402,-0.017251493,-0.019265866,-0.020146724,-0.023115207,-0.01874103,-0.022170136,-0.017370557,-0.025380757,-0.027199753,-0.018180707,-0.021906225,-0.022733156,-0.016245028,-0.020688118,-0.016684677,-0.024432007,-0.021003898,-0.025631627,-0.01874511,-0.018135168,-0.023446053,-0.018940976,-0.026489235,-0.016425483,-0.018058287,-0.022474153,-0.017082145,-0.021944528,-0.026153492,-0.019103594,-0.01744928,-0.020060245,-0.01703268,-0.01750805,-0.02326301,-0.017684089,-0.016039606,-0.021210158,-0.015927887,-0.019817773,-0.015717706,-0.020425342,-0.019490711,-0.02592274,-0.016811859,-0.028641827,-0.023107294,-0.022708591,-0.016440818,-0.02788098,-0.018143794,-0.020096486,-0.016182395,-0.018183649,-0.018136237,-0.015929364,-0.02322936,-0.01777899,-0.019070918,-0.016200904,-0.022022596,-0.018930705,-0.0188794,-0.020722417,-0.023036314,-0.018551186,-0.033487476,-0.017131103,-0.015909161,-0.017386487,-0.026854312,-0.017265918,-0.022466324,-0.019733433,-0.016328683,-0.024427682,-0.01821628,-0.018672133,-0.019279568,-0.018772677,-0.024602087,-0.017876828,-0.018583275,-0.019245565,-0.021306533,-0.01926178,-0.025323411,-0.022499772,-0.019854695,-0.023317177,-0.022673955,-0.023055991,-0.022689043,-0.020969925,-0.015813168,-0.021315515,-0.027575225,-0.016608758,-0.019524327,-0.02489011,-0.020996744,-0.021892535,-0.018924648,-0.020157889,-0.024715764,-0.02646071,-0.022598686,-0.019994933,-0.016379707,-0.019773364,-0.01927948,-0.01714216,-0.02314418,-0.02213682,-0.0160886;-0.021394482;0.0038845146;0.0
data/model/LunarLander-v3_451229_1.pth;LunarLander-v3;qwen2.5-coder_llama3.2-vision;{'seed': 451229};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'model/LunarLanderDQN/', 'seed': 451229};400000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    angle = observations[4]
    
    target_x, target_y = -5.0, 5.0  # Adjust these values based on the red trajectory
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        distance_to_target = np.sqrt((x - target_x)**2 + (y - target_y)**2)
        angle_diff = np.abs(angle) - np.pi / 4  # Adjust this value based on the red trajectory
        
        return -distance_to_target - 0.1 * angle_diff";-0.019980805,-0.0150781805,-0.016852893,-0.020049084,-0.020954065,-0.0146095725,-0.018542355,-0.019015104,-0.022767192,-0.020301597,-0.016950773,-0.02101162,-0.02775914,-0.019749325,-0.031309843,-0.020546742,-0.023798108,-0.017809663,-0.015948884,-0.024133798,-0.019231673,-0.027528405,-0.022342557,-0.021810954,-0.022093538,-0.033305794,-0.017890507,-0.02471411,-0.015897993,-0.02519829,-0.023447687,-0.022622036,-0.025554338,-0.025312133,-0.019791378,-0.024570685,-0.021429889,-0.019615497,-0.02710471,-0.026655255,-0.021608876,-0.022869322,-0.027676614,-0.027240273,-0.018536516,-0.028647477,-0.023243785,-0.020799074,-0.017676298,-0.019531174,-0.015692448,-0.02013339,-0.02583244,-0.029441725,-0.026617905,-0.024481323,-0.02621657,-0.023173757,-0.021061452,-0.035575315,-0.021265903,-0.02675612,-0.024711257,-0.020729749,-0.021496383,-0.027283765,-0.03457884,-0.020215962,-0.019079799,-0.020715283,-0.022662329,-0.024215594,-0.0188145,-0.017275259,-0.019043446,-0.020856244,-0.02394242,-0.02214027,-0.026213102,-0.026241342,-0.022965143,-0.01588876,-0.020796878,-0.024423867,-0.016437298,-0.018056378,-0.02202966,-0.018432586,-0.027330691,-0.03083603,-0.027975542,-0.032372333,-0.018125568,-0.01875313,-0.021641187,-0.029555297,-0.016546976,-0.018196875,-0.016255476,-0.03161565,-0.025327224,-0.018843515,-0.03174764,-0.019079888,-0.020539021,-0.025856325,-0.028162066,-0.029449506,-0.02685099,-0.022741571,-0.020669702,-0.018876228,-0.027074767,-0.02318226,-0.014432901,-0.020415816,-0.044498313,-0.015030101,-0.029565994,-0.02062379,-0.01548628,-0.021072816,-0.014682304,-0.032644995,-0.027543617,-0.016498411,-0.016261024,-0.026732147,-0.019865446,-0.016234588,-0.024638852,-0.028354654,-0.01950095,-0.019306067,-0.016280182,-0.015631607,-0.013751916,-0.0152812,-0.020067899,-0.01417002,-0.01470209,-0.014955569,-0.02145629,-0.028208565,-0.01391873,-0.04269672,-0.01857872,-0.015397015,-0.014401649,-0.021121738,-0.015593827,-0.024935165,-0.019284857,-0.019459542,-0.017034698,-0.014730252,-0.019482093,-0.019191366,-0.014703313,-0.0194915,-0.017466787,-0.015377169,-0.018712481,-0.018261967,-0.019839622,-0.016227197,-0.017333072,-0.01578629,-0.017460357,-0.016342558,-0.015106972,-0.01640991,-0.0193077,-0.018275961,-0.019212168,-0.019827992,-0.016226126,-0.018507319,-0.01353343,-0.012903011,-0.014637463,-0.018841319,-0.016267348,-0.017499862,-0.017593151,-0.0140968235,-0.018343493,-0.01867122,-0.015343553,-0.014878183,-0.014581622,-0.01808338,-0.01512571,-0.015152566,-0.018487368,-0.01454612,-0.014834887,-0.019548815,-0.014436396,-0.015071572,-0.014906171,-0.01316274,-0.014997079,-0.013896516,-0.01976736,-0.015783643,-0.0154841,-0.014170856,-0.0141486125,-0.018007617,-0.016987957,-0.01472876,-0.014438159,-0.02009193,-0.017598007,-0.017530387,-0.014399473,-0.013772312,-0.01448497,-0.013748049,-0.013581385,-0.01747156,-0.019096756,-0.019216923,-0.016085535,-0.016619893,-0.018060055,-0.017242521,-0.017596886,-0.016723268,-0.017697353,-0.014095804,-0.019221036,-0.0155771375,-0.016504006,-0.016552709,-0.013399165,-0.016699558,-0.01665923,-0.018994829,-0.017431103,-0.014089623,-0.019135725,-0.01525943,-0.01668784,-0.017004007,-0.01830134,-0.013380138,-0.015105134,-0.013566873,-0.013660485,-0.0151854735,-0.014953643,-0.014084534,-0.016034823,-0.013333881,-0.016901964,-0.013986457,-0.01671749,-0.014016384,-0.016545868,-0.019165121,-0.01412406,-0.017087737,-0.013777908,-0.016692536,-0.01358313,-0.016107649,-0.018670894,-0.017397275,-0.015310864,-0.018337753,-0.018027449,-0.013868742,-0.016037814,-0.014813718,-0.017602779,-0.013830524,-0.016743233,-0.013536371,-0.016275382,-0.014724113,-0.01491761,-0.016571734,-0.014338906,-0.013346331,-0.01781954,-0.013222424,-0.017374955,-0.015965968,-0.013691885,-0.018073574,-0.019504026,-0.016149681,-0.015912855,-0.012760643,-0.016134799,-0.017223312,-0.013256758,-0.014318082,-0.013961734,-0.018549569,-0.015020734,-0.014777416,-0.014675461,-0.013419777,-0.014878327,-0.017560951,-0.019710068,-0.015622587,-0.013636822,-0.020217834,-0.018875115,-0.01829834,-0.0185629,-0.013689341,-0.01668974,-0.017503079,-0.019325051,-0.01942846,-0.017099021,-0.017659469,-0.016246459,-0.01614683,-0.0154117355,-0.020029726,-0.016980726,-0.015761051,-0.021094361,-0.020706598,-0.01891072,-0.019986443,-0.02266385,-0.026780788,-0.02838871,-0.018876417,-0.020969434,-0.0195753,-0.017649421,-0.018336633,-0.014944416,-0.016297106,-0.014402386,-0.022296645,-0.016541503,-0.018776888,-0.016643822,-0.01901977,-0.01372139,-0.017444313,-0.013714536,-0.01685068,-0.013462839,-0.017789997,-0.014805437,-0.01668864,-0.017017018,-0.015956696,-0.019170824,-0.015222657,-0.013971677,-0.017434698,-0.014292201,-0.020963635,-0.016879024,-0.016815815,-0.015166866,-0.01364888,-0.017145649,-0.017181035,-0.02046138,-0.01564019,-0.016304007,-0.013174081,-0.01796569,-0.016337952,-0.017765278,-0.014250328,-0.018316561,-0.0155666,-0.019164165,-0.013043289,-0.017306114,-0.013670181,-0.017261239,-0.017320972,-0.01835174,-0.01869216,-0.020786721,-0.013043171,-0.01937358,-0.01303203,-0.023354212,-0.014805434,-0.018509544,-0.01567896,-0.017524328,-0.018836424,-0.017684985,-0.019310486,-0.016097702,-0.018038236,-0.0127909975,-0.016337838,-0.019948691,-0.016686209,-0.01699505,-0.019019097,-0.022080444,-0.01650113,-0.014297098,-0.01805505,-0.018370837,-0.015677888,-0.018245444,-0.014874677,-0.020389087,-0.025308883,-0.01391256,-0.01443772,-0.01331715,-0.019553399,-0.014928258,-0.017399572,-0.019829573,-0.016000632,-0.014982946,-0.016013106,-0.017858064,-0.022265257,-0.017517468,-0.01371196,-0.013457731,-0.019502712,-0.017248167,-0.013531137,-0.017554794,-0.019490909,-0.019593252,-0.0142666185,-0.013753626,-0.015252299,-0.019225024,-0.013940828,-0.013350814,-0.017885363,-0.014802531,-0.016149938,-0.017722243,-0.013503025,-0.019598067,-0.01646311,-0.017981624,-0.01622088,-0.015808126,-0.017012144,-0.021875054,-0.017334487,-0.022687307,-0.02256072,-0.018098345,-0.02024489,-0.01687613,-0.022246499,-0.021582032,-0.019400293,-0.017762452,-0.021534028,-0.022334589,-0.018958868,-0.020118982,-0.022762429,-0.024939278,-0.02044084,-0.02423425,-0.023661228,-0.030051036,-0.023002937,-0.02540991,-0.025960118,-0.0270306,-0.019949876,-0.021954589,-0.020283194,-0.02269287,-0.033141453,-0.025866447,-0.025473263,-0.026236542,-0.021555826,-0.029234102,-0.023855953,-0.03184857,-0.030392896,-0.021287598,-0.026092824,-0.026305174,-0.026414588,-0.041823342,-0.030677732,-0.05098414,-0.054989405,-0.060362346,-0.0699789,-0.05079493,-0.077608764,-0.050612066,-0.018014384,-0.016497843,-0.019202812,-0.059615705,-0.040619742,-0.026013039,-0.04847085,-0.019636935,-0.037746288,-0.016008005,-0.020491641,-0.031925034,-0.03415257,-0.02783811,-0.035923857,-0.017319638,-0.03667056,-0.019801687,-0.022850335,-0.017937826,-0.017165635,-0.027679177,-0.022822566,-0.021138258,-0.021909688,-0.023677927,-0.020774445,-0.030006843,-0.018304916,-0.022792552,-0.022877691,-0.017848607,-0.017379357,-0.028895445,-0.030124445,-0.03557293,-0.01894057,-0.026502695,-0.017523235,-0.020245027,-0.023640715,-0.02195296,-0.022070177,-0.022573905,-0.02241544,-0.0227081,-0.021859618,-0.028263373,-0.026046015,-0.024075486,-0.03644547,-0.026677614,-0.034047484,-0.02667188,-0.027788784,-0.02734827,-0.019035917,-0.029098792,-0.026714185,-0.020135593,-0.036692027,-0.02398478,-0.016665041,-0.035532802,-0.027120817,-0.020348936,-0.035763472,-0.02246228,-0.018771812,-0.02725239,-0.019222703,-0.018103482,-0.02228957,-0.02395157,-0.022218935,-0.039252654,-0.03167277,-0.033984005,-0.033731285,-0.019149818,-0.022033162,-0.020256951,-0.029736299,-0.021211555,-0.020167211,-0.020508379,-0.041135743,-0.030796677,-0.026701607,-0.02438918,-0.030263415,-0.016380547,-0.019819833,-0.022794457,-0.027774867,-0.03590009,-0.036262315,-0.030806657,-0.026147325,-0.027446723,-0.018873071,-0.02305508,-0.018831374,-0.017490549,-0.029548202,-0.030966181,-0.02212003,-0.02346394,-0.0360411,-0.026386837,-0.021763397,-0.022308247,-0.02906902,-0.0173055,-0.02482947,-0.024364155,-0.02116656,-0.020586861,-0.018732395,-0.017293451,-0.02544186,-0.019127158,-0.0351465,-0.01791527,-0.01870632,-0.024287445,-0.02833239,-0.02264023,-0.019328145,-0.02512265,-0.018988747,-0.025762578,-0.021077797,-0.023290414,-0.028857624,-0.024337934,-0.020695396,-0.023326207,-0.015776321,-0.022647535,-0.018772673,-0.018008763,-0.028022924,-0.018233716,-0.029354857,-0.016318042,-0.02082244,-0.022025296,-0.025766334,-0.015543593,-0.018438142,-0.019755322,-0.024795102,-0.025105335,-0.017190326,-0.022820324,-0.01660144,-0.027498951,-0.018059367,-0.021528529,-0.02198379,-0.022953534,-0.024193196,-0.024418311,-0.027405117,-0.025223162,-0.03185964,-0.021328056,-0.019380411,-0.016352618,-0.017448531,-0.021394432,-0.016197212,-0.016140418,-0.023550201,-0.018322637,-0.021017458,-0.02447301,-0.01688793,-0.027307628,-0.017728824,-0.021806752,-0.023157187,-0.023596887,-0.030375043,-0.016991276,-0.027433515,-0.019626422,-0.028492052,-0.017478183,-0.02072126,-0.019141171,-0.01875919,-0.021739597,-0.031867042,-0.029633956,-0.020443838,-0.01898337,-0.016602702,-0.016487561,-0.01919155,-0.0187081,-0.019326001,-0.020287795,-0.020836577,-0.016991923,-0.024492921,-0.025092654,-0.02979791,-0.016261933,-0.01856777,-0.018257847,-0.028040411,-0.023268467,-0.019141447,-0.017439878,-0.032640833,-0.020348486,-0.018011158,-0.018392593,-0.015162908,-0.02354493,-0.021347305,-0.015097297,-0.020887718,-0.017111316,-0.022930693,-0.024087012,-0.023870567,-0.019179456,-0.016069854,-0.014914637,-0.019388754,-0.024379382,-0.017562507,-0.0174588,-0.023582658,-0.02061137,-0.025495313,-0.017089132,-0.019261934,-0.01585355,-0.017846992,-0.019326951,-0.016381325,-0.01782243,-0.015293247,-0.021286514,-0.024293678,-0.031067083,-0.024412462,-0.023861276,-0.02168176,-0.02109251,-0.02207584,-0.0191529,-0.018355872,-0.020178333,-0.01985193,-0.02418804,-0.02031755,-0.027113989,-0.0219053,-0.017508619,-0.015138033,-0.014660932,-0.026590748,-0.017839067,-0.027951311,-0.021031521,-0.017957466,-0.016442,-0.023559868,-0.017356468,-0.017017102,-0.025914425,-0.016944071,-0.01395911,-0.02303925,-0.020734254,-0.016706109,-0.017385468,-0.025129966,-0.018555772,-0.018229077,-0.02993652,-0.023923062,-0.019869795,-0.014437763,-0.020425698,-0.02494884,-0.015644245,-0.024695596,-0.025418403,-0.015927335,-0.017712591,-0.0148094,-0.016116865,-0.015122127,-0.027182452,-0.02040617,-0.024815457,-0.021077361,-0.014733514,-0.025823062,-0.0143991215,-0.018539574,-0.018119814,-0.017007057,-0.02116647,-0.019344114,-0.017000716,-0.026587434,-0.02323822,-0.018928355,-0.021785105,-0.025462124,-0.03314612,-0.018145598,-0.0146395555,-0.025705932,-0.020044113,-0.021323567,-0.014481164,-0.016681079,-0.015457419,-0.016165553,-0.0202861,-0.026600298,-0.020144569,-0.018168312,-0.017125357,-0.015599616,-0.022482296,-0.0142446365,-0.023078283,-0.025646525,-0.023294076,-0.022086304,-0.017484589,-0.017009001,-0.018589307,-0.014455841,-0.015509818,-0.019750401,-0.027451295,-0.022426412,-0.01498197,-0.017147439,-0.027464917,-0.020685699,-0.025955172,-0.018490812,-0.020001529,-0.015442009,-0.023869628,-0.028114533,-0.023527348,-0.015936723,-0.02514364,-0.017258702,-0.017750306,-0.025483875,-0.015023707,-0.028160313,-0.01955624,-0.01604857,-0.025858197,-0.019447777,-0.01900191,-0.015949301,-0.015181104,-0.023109958,-0.016871076,-0.02157654,-0.020758582,-0.030655695,-0.016264813,-0.017238231,-0.02670608,-0.01694237,-0.019581066,-0.015830586,-0.025631594,-0.028376298,-0.028436456,-0.020377206,-0.01871001,-0.026288781,-0.017265027,-0.01727148,-0.024318518,-0.017661769,-0.016825207,-0.023231572,-0.02570054,-0.01879209,-0.018555831,-0.018909082,-0.022368217,-0.019262042,-0.024222663,-0.025875501,-0.029412616,-0.026598133,-0.013242208,-0.027991949,-0.02325611,-0.019073732,-0.0170912,-0.02506843,-0.03311616,-0.022027837,-0.01647425,-0.022029897,-0.018744025,-0.019225603,-0.01866205,-0.017443383,-0.019780606,-0.014761479,-0.027141029,-0.021461194,-0.017425125,-0.016310794,-0.020763174,-0.01845122,-0.017064674,-0.018794872,-0.018070979,-0.02314824,-0.023029538,-0.027211305,-0.018783946,-0.023450127,-0.02061401,-0.019948566,-0.017152919,-0.017745944,-0.02636229,-0.029176349,-0.021917064,-0.024020154,-0.01881669,-0.018610949,-0.022302562,-0.045112222,-0.025375282,-0.028875172,-0.015611371,-0.023100376,-0.02533328,-0.024883922,-0.016547408,-0.016433217,-0.018199833,-0.014341686,-0.016566914,-0.023960844,-0.015518653,-0.017233083,-0.040680405,-0.023964113,-0.01654681,-0.019713528,-0.016455201,-0.017977344,-0.01859028,-0.025431875,-0.022460232,-0.017174244,-0.022293966,-0.019570356,-0.01431664,-0.02517659,-0.018338818,-0.032436814,-0.014481486,-0.024123378,-0.019176189,-0.018026544,-0.014879264,-0.019489301,-0.02699775,-0.014439798,-0.029030843,-0.023554197,-0.016659992,-0.0141708,-0.01600789,-0.022406071,-0.027648991,-0.015558522,-0.023948003,-0.019876068,-0.024914552,-0.020532506,-0.020793078,-0.017539484,-0.025934974,-0.016101876,-0.018234802,-0.016976127,-0.016853197,-0.01599734,-0.014896428,-0.015277703,-0.015846862,-0.013708341,-0.013970166,-0.02918007,-0.013358951,-0.017536271,-0.017235069,-0.016481396,-0.016223567,-0.013691645,-0.017225873,-0.015731819,-0.013878844,-0.01785868,-0.016506055,-0.016377095,-0.020096187,-0.018336015,-0.013895096,-0.013932161,-0.014148412,-0.014233333,-0.016911672,-0.023232136,-0.018853556,-0.01801663,-0.013176752,-0.026805826,-0.021208134,-0.020473784,-0.015277685,-0.018434929,-0.018443152,-0.017888574,-0.013111102,-0.020463496,-0.021718785,-0.015279187,-0.013282307,-0.013466156,-0.017293023,-0.013694681,-0.013280283,-0.016348762,-0.016116144,-0.014823585,-0.01910468,-0.016101893,-0.016708989,-0.015770698,-0.014772158,-0.014899234,-0.018204082,-0.016195696,-0.01824698,-0.016158748,-0.015494067,-0.013853077,-0.015724476,-0.016511025,-0.015716322,-0.022779653,-0.01650852,-0.012551564,-0.015416404,-0.013935128,-0.017198581,-0.014345277,-0.018027226,-0.012848483,-0.014403192,-0.01598169,-0.014840751,-0.015575622,-0.016781976,-0.021933254,-0.016120464,-0.01344651,-0.015354556,-0.015650256,-0.015225375,-0.015522493,-0.018256037,-0.013528559,-0.016971814,-0.0152388755,-0.02072144,-0.015821675,-0.017883787,-0.014374502,-0.014331428,-0.015660074,-0.015139896,-0.013371168,-0.015136765,-0.017856058,-0.013584144,-0.015034825,-0.020512953,-0.014592239,-0.01754752,-0.019819364,-0.015388603,-0.013617059,-0.019061854,-0.014633792,-0.014485854,-0.019994019,-0.017066397,-0.019214824,-0.013961998,-0.014843591,-0.019284172,-0.020142173,-0.014092454,-0.014046168,-0.015809665,-0.014786045,-0.017054724,-0.017844979,-0.020876419,-0.01413845,-0.019088963,-0.013990981,-0.018927049,-0.013544531,-0.023684269,-0.019041078,-0.015702233,-0.0194049,-0.020772696,-0.013049289,-0.015615816,-0.015221833,-0.0156947,-0.02612646,-0.014060051,-0.016173895,-0.02098223,-0.017525593,-0.013291382,-0.01786829,-0.021049779,-0.018116457,-0.013764557,-0.02054039,-0.018542562,-0.014165483,-0.023360636,-0.0163726,-0.017377865,-0.015543847,-0.015869513,-0.017243285,-0.014349205,-0.016590709,-0.017418649,-0.016936215,-0.017170507,-0.01408972,-0.013442297,-0.013674889,-0.015119557,-0.018844932,-0.015367495,-0.020346602,-0.0132850595,-0.0157092,-0.019229762,-0.022034612,-0.01323951,-0.014079732,-0.014849363,-0.01616347,-0.018821305,-0.013411099,-0.016719764,-0.01588273,-0.012911468,-0.016048638,-0.020926759,-0.02013479,-0.017384622,-0.017311431,-0.017827956,-0.018144825,-0.01690371,-0.014876137,-0.016645137,-0.023334896,-0.019879103,-0.018501297,-0.018512722,-0.018949296,-0.013954354,-0.016727097,-0.015820181,-0.014958403,-0.014532079,-0.020508759,-0.023213219,-0.0127894385,-0.0191159,-0.013543373,-0.01801859,-0.014407199,-0.019239213,-0.013757307,-0.013358059,-0.01564002,-0.018395763,-0.017127331,-0.015275239,-0.016360132,-0.01717614,-0.018946549,-0.015200537,-0.019323142,-0.017049678,-0.018846774,-0.019486789,-0.017595723,-0.016372962,-0.0144323325,-0.018350976,-0.017460523,-0.014639962,-0.01497836,-0.017784024,-0.018484352,-0.016104903,-0.01562719,-0.012990201,-0.014897002,-0.01837052,-0.019479452,-0.021405872,-0.016612893,-0.020476859,-0.019842086,-0.020962376,-0.018591333,-0.020407185,-0.020527495,-0.025024196,-0.020385675,-0.021308389,-0.022509199,-0.0424519,-0.012760759,-0.029987372,-0.027953984,-0.025326183,-0.024891604,-0.025714375,-0.028454533,-0.030363847,-0.03784481,-0.028669842,-0.029532041,-0.03280428,-0.032500442,-0.03962884,-0.022972038,-0.031614702,-0.022195147,-0.02096949,-0.016683519,-0.019934662,-0.019939585,-0.026664855,-0.021208508,-0.025158038,-0.022654863,-0.023293028,-0.028110309,-0.021696862,-0.016965372,-0.023657978,-0.036257915,-0.021448594,-0.023759387,-0.03094238,-0.02667171,-0.0224916,-0.01348112,-0.02456542,-0.02435716,-0.033486072,-0.028667767,-0.02344158,-0.017115384,-0.018172534,-0.02299269,-0.041003887,-0.024735209,-0.014472061,-0.02088232,-0.0182444,-0.035627864,-0.018548153,-0.020034065,-0.031423077,-0.07244754,-0.026756387,-0.05720332,-0.020813053,-0.04739393,-0.02061703,-0.021110455,-0.015905965,-0.03146541,-0.028309911,-0.0315195,-0.075425945,-0.050743457,-0.0141082425,-0.04947632,-0.019155435,-0.017709838,-0.064129196,-0.058485076,-0.020170316,-0.016772425,-0.023861604,-0.04185969,-0.02096703,-0.021655036,-0.021038132,-0.026954543,-0.023935148,-0.020792937,-0.021778047,-0.015972106,-0.02980207,-0.020978322,-0.02224595,-0.019848911,-0.031329203,-0.02151537,-0.036658164,-0.024121711,-0.023895089,-0.01982853,-0.019462578,-0.03338894,-0.023161495,-0.016939737,-0.0157179,-0.025948664,-0.019567717,-0.030464409,-0.01629876,-0.02092494,-0.018956754,-0.01915587,-0.029659824,-0.016803471,-0.0239398,-0.015800875,-0.019194957,-0.022883032,-0.01938681,-0.01625455,-0.018426767,-0.023822563,-0.02279159,-0.018897938,-0.018480945,-0.017977746,-0.027060619,-0.017321289,-0.02235038,-0.02012958,-0.023535255,-0.020305103,-0.023048725,-0.02045178,-0.02071382,-0.028558658,-0.019795345,-0.018927313,-0.021976722,-0.029699182,-0.027810318,-0.02256275,-0.016184725,-0.017498625,-0.023212371,-0.022955004,-0.01465153,-0.026235677,-0.044694345,-0.024444055,-0.021185312,-0.028430961,-0.02286615,-0.0191305,-0.0206386,-0.022758834,-0.025001384,-0.026312914,-0.023326753,-0.018980647,-0.017010149,-0.017803676,-0.028110206,-0.01793335,-0.020135991,-0.017594075,-0.023242695,-0.018815868,-0.018846815,-0.023133649,-0.016601432,-0.027855868,-0.031346556,-0.02711406,-0.019697838,-0.027608544,-0.024868466,-0.018803813,-0.01700577,-0.015493808,-0.02088877,-0.017248096,-0.026915094,-0.020099927,-0.031490088,-0.019800352,-0.01809666,-0.024225099,-0.024615515,-0.018166287,-0.016801713,-0.016737893,-0.017955624,-0.016555207,-0.032422695,-0.016453868,-0.023802731,-0.02105504,-0.029326295,-0.027463412,-0.017155508,-0.017532876,-0.016435387,-0.025787957,-0.02075046,-0.025561733,-0.017217685,-0.021150187,-0.020386549,-0.02363113,-0.017200062,-0.01603039,-0.01983035,-0.020034593,-0.018645456,-0.018924985,-0.02629307,-0.018438978,-0.022266531,-0.017101632,-0.028808134,-0.021767229,-0.023262396,-0.015856698,-0.028813295,-0.021077272,-0.016590822,-0.021458736,-0.021135837,-0.01580301,-0.017596863,-0.01555996,-0.019932505,-0.016358756,-0.017472912,-0.022478463,-0.021211265,-0.017431479,-0.02155556,-0.016454775,-0.020874048,-0.017241014,-0.01686716,-0.024203693,-0.020369904,-0.020146657,-0.019213008,-0.015047028,-0.018964367,-0.016952584,-0.027421208,-0.021189746,-0.019042179,-0.016812323,-0.019007307,-0.016036557,-0.01995907,-0.019588895,-0.021237642,-0.023142036,-0.020774666,-0.02330325,-0.018227372,-0.021597033,-0.020545341,-0.017185153,-0.027712652,-0.021187907,-0.019110441,-0.021649497,-0.019786006,-0.019308176,-0.025271907,-0.019998582,-0.022467429,-0.015888639,-0.016569974,-0.020387772,-0.022402082,-0.018972695,-0.02597268,-0.020596847,-0.017381495,-0.015693245,-0.027762491,-0.024698356,-0.019436304,-0.020538429,-0.021284819,-0.029358169,-0.026399488,-0.018422961,-0.027529027,-0.01924698,-0.020429326,-0.01973655,-0.03351247,-0.024273776,-0.017031072,-0.030019576,-0.019580875,-0.027016137,-0.017026057,-0.014635098,-0.030895839,-0.016215539,-0.016722953,-0.014741779,-0.0314948,-0.016931707,-0.021308623,-0.023429576,-0.020194368,-0.10540687,-0.023187479,-0.016931923,-0.024107823,-0.015490719,-0.01860133,-0.01623799,-0.023607355,-0.020287482,-0.019328654,-0.021169275,-0.016286895,-0.019250525,-0.01717165,-0.018429086,-0.018094515,-0.017831765,-0.015023986,-0.016282864,-0.015402684,-0.02681801,-0.021251496,-0.018509556,-0.016267546,-0.015649445,-0.01670503,-0.015717788,-0.015056366,-0.014248308,-0.019742357,-0.017236894,-0.018233497,-0.014944936,-0.01466021,-0.017831221,-0.015762143,-0.018524356,-0.014760456,-0.014518254,-0.017878942,-0.01497138,-0.013902825,-0.022120394,-0.015668876,-0.01473382,-0.015812587,-0.017351989,-0.015540785,-0.017697783,-0.014703749,-0.014711685,-0.020221097,-0.013748017,-0.015820839,-0.026962603,-0.01613158,-0.01654476,-0.013675089,-0.024562731,-0.017656954,-0.017621992,-0.019452086,-0.016576264,-0.017549438,-0.020447334,-0.016019855,-0.017573472,-0.018821942,-0.015652463,-0.017557917,-0.02252956,-0.016383948,-0.020950476,-0.0179808,-0.019223815,-0.019649135,-0.027459115,-0.016114911,-0.013880327,-0.0131781595,-0.016687758,-0.018805213,-0.016164234,-0.019222014,-0.0139156,-0.014135426,-0.019270226,-0.018241521,-0.019553233,-0.016733909,-0.021312848,-0.0135328155,-0.019506,-0.02128978,-0.019136993,-0.013038159,-0.018353647,-0.015033159,-0.0193305,-0.01509115,-0.019086845,-0.013835987,-0.019723194,-0.017620467,-0.013900023,-0.01663514,-0.012958937,-0.013306428,-0.015399267,-0.020485094,-0.016299348,-0.015094806,-0.015533438,-0.01929126,-0.012976101,-0.016458333,-0.015687492,-0.018075278,-0.020569857,-0.01753564,-0.020982966,-0.014711696,-0.020423781,-0.015584671,-0.014438748,-0.017791536,-0.014899727,-0.014261482,-0.014397269,-0.015086954,-0.013944711,-0.019667521,-0.015362309,-0.016921861,-0.0145395985,-0.01973177,-0.015230095,-0.020793064,-0.014172838,-0.015470689,-0.016805826,-0.015168633,-0.015488382,-0.01307165,-0.015598445,-0.020313358,-0.02070779,-0.02007464,-0.017015576,-0.015929876,-0.016970342,-0.014488748,-0.016222216,-0.017215831,-0.013238118,-0.016053407,-0.01580268,-0.014775008,-0.01409906,-0.019677144,-0.019247016,-0.013664972,-0.016148247,-0.019977638,-0.013909083,-0.0192667,-0.021174954,-0.01854153,-0.017383501,-0.018505722,-0.016766569,-0.015242496,-0.01324097,-0.01563326,-0.013545402,-0.017550854,-0.014578428,-0.016028428,-0.014213979,-0.018852098,-0.016389925,-0.013358389,-0.016249808,-0.013449838,-0.015363497,-0.018081665,-0.015767358,-0.013129976,-0.01715545,-0.0141342515,-0.018318592,-0.018036079,-0.016364198,-0.01796083,-0.01366018,-0.024962697,-0.01351475,-0.014893421,-0.015237959,-0.019441249,-0.014279787,-0.015247118,-0.018017167,-0.01408458,-0.019327493,-0.016027778,-0.017934047,-0.014122892,-0.014971106,-0.02027826,-0.013584799,-0.01776359,-0.018297305,-0.017983116,-0.013871613,-0.014208665,-0.017673185,-0.016040282,-0.015278887,-0.013890963,-0.013091908,-0.018204926,-0.0164582,-0.017969277,-0.01967485,-0.013709764,-0.020545019,-0.013774206,-0.016323665,-0.021070024,-0.020685785,-0.015583197,-0.015146821,-0.013044608,-0.016629165,-0.01564236,-0.01933452,-0.0131972665,-0.016662892,-0.017966816,-0.017937226,-0.0152528845,-0.014509119,-0.018177878,-0.019013021,-0.017680362,-0.017843414,-0.014769627,-0.019267151,-0.01434069,-0.013249041,-0.015989143,-0.01440482,-0.013600527,-0.019949015,-0.017748535,-0.015007532,-0.013525829,-0.020178938,-0.015994096,-0.013745835,-0.021222843,-0.016829466,-0.018647391,-0.015350112,-0.018702442,-0.019503066,-0.015218451,-0.021179182,-0.016593564,-0.015900811,-0.015784862,-0.015095842,-0.018099632,-0.01718387,-0.020570772,-0.013307449,-0.017629012,-0.014824733,-0.017341029,-0.019420175,-0.013286068,-0.014211105,-0.014172508,-0.018737692,-0.017735053,-0.017397452,-0.015653802,-0.018685766,-0.015354006,-0.016530557,-0.019500745,-0.013798873,-0.025510477,-0.019460632,-0.013685891,-0.016366187,-0.020465381,-0.019046094,-0.026686603,-0.015962975,-0.020131785,-0.017135337,-0.019756798,-0.022135941,-0.019439837,-0.015577611,-0.01589508,-0.016388696,-0.01975027,-0.02170753,-0.019102009,-0.023556855,-0.033413175,-0.021385025,-0.01645089,-0.01787805,-0.020566208,-0.016572295,-0.021291627,-0.019147173,-0.019927919,-0.025395025,-0.03125755,-0.02206833,-0.026264498,-0.023394495,-0.023777796,-0.023902507,-0.019152595,-0.037865885,-0.023221627,-0.020798525,-0.03642997,-0.024273945,-0.028951455,-0.02911067,-0.03872565,-0.02298592,-0.019597387,-0.021759376,-0.042336162,-0.01641205,-0.037934996,-0.018678537,-0.019376338,-0.028079404,-0.018134259,-0.019794678,-0.023415701,-0.015748242,-0.021731386,-0.029403409,-0.018276185,-0.03254705,-0.019184193,-0.02681496,-0.021588737,-0.017882826,-0.024383456,-0.022188894,-0.023860795,-0.0205087,-0.022244768,-0.02652815,-0.041666135,-0.017337956,-0.024881525,-0.016576452,-0.023960046,-0.031166824,-0.019864261,-0.017841553,-0.029980186,-0.030348077,-0.026813444,-0.019444758,-0.019691315,-0.023569077,-0.022041693,-0.026188144,-0.05417262,-0.025238978,-0.028509319,-0.04445208,-0.027900409,-0.019602112,-0.021123467,-0.01704904,-0.016816627,-0.023938702,-0.030453332,-0.017616829,-0.017528525,-0.04619788,-0.022445887,-0.016015297,-0.01781935,-0.019862032,-0.025051199,-0.018552067,-0.01921729,-0.020563908,-0.019985862,-0.01997924,-0.024350923,-0.04520878,-0.05076014,-0.030158855,-0.026742216,-0.0132484725,-0.017058833,-0.027027098,-0.028292248,-0.013935276,-0.027056,-0.018422188,-0.021560598,-0.017814893,-0.013857904,-0.03347292,-0.014412187,-0.015394649,-0.02080933,-0.02605418,-0.013516883,-0.016048495,-0.016484171,-0.020820132,-0.020436546,-0.027857907,-0.044127934,-0.01518289,-0.02213168,-0.017605813,-0.04260417,-0.014393596,-0.015229152,-0.013580403,-0.014489465,-0.015636731,-0.015311568,-0.016058993,-0.016997041,-0.019007694,-0.016885335,-0.014750879,-0.015456266,-0.018064143,-0.013941025,-0.013327007,-0.013695742,-0.017781962,-0.016680196,-0.014953542,-0.014078698,-0.013199646,-0.019803567,-0.018048514,-0.014819618,-0.019498935,-0.014891384,-0.018582322,-0.016591627,-0.017935071,-0.015250599,-0.0140113495,-0.01994117,-0.013318697,-0.01538038,-0.013166771,-0.0131603405,-0.01901839,-0.01346479,-0.01790127,-0.020024963,-0.016745182,-0.014324595,-0.018799806,-0.013534438,-0.015645644,-0.01536735,-0.014289208,-0.013192792,-0.013093282,-0.019956823,-0.015277044,-0.019761613,-0.014224646,-0.015075455,-0.01525369,-0.0126083465,-0.01752093,-0.014139781,-0.019796547,-0.0155602535,-0.014064428,-0.015159811,-0.019351242,-0.026888264,-0.019544275,-0.017536687,-0.021592913,-0.017446892,-0.019071745,-0.016310945,-0.014341304,-0.019646328,-0.018511487,-0.020211525,-0.017019076,-0.021590447,-0.013412903,-0.016562194,-0.021702215,-0.01311903,-0.019491823,-0.01660956,-0.012876079,-0.014536971,-0.01937986,-0.019368565,-0.016284885,-0.01653419,-0.013940177,-0.014848399,-0.014936108,-0.015243265,-0.019928573,-0.016682642,-0.017661827,-0.014630431,-0.013429258,-0.013787529,-0.020223489,-0.014601856,-0.014677571,-0.015453343,-0.013590575,-0.017163388,-0.014213283,-0.021139905,-0.017444305,-0.013570512,-0.01730803,-0.016383128,-0.0149367945,-0.020218845,-0.016757907,-0.014201901,-0.017477298,-0.015439134,-0.018241351,-0.014138704,-0.01523395,-0.020110495,-0.019954415,-0.014823752,-0.016766388,-0.020538518,-0.015796293,-0.014124353,-0.018650673,-0.012989429,-0.020194307,-0.019612033,-0.016418708,-0.013746181,-0.019919943,-0.022014689,-0.013966499,-0.026102168,-0.021794684,-0.03539144,-0.02718774,-0.042637903,-0.02148449,-0.020272803,-0.04380378,-0.02631075,-0.021910314,-0.036744677,-0.030816413,-0.023744,-0.028016258,-0.02414837,-0.019732714,-0.035475343,-0.047543384,-0.030521927,-0.024873093,-0.037092865,-0.021468932,-0.017521458,-0.037400004,-0.017558664,-0.018086145,-0.031254128,-0.028110595,-0.01962966,-0.017509066,-0.023178741,-0.029286532,-0.030643681,-0.023042863,-0.025967708,-0.017347887,-0.018239237,-0.01984076,-0.026080452,-0.02396639,-0.022455817,-0.02117473,-0.02492572,-0.017926168,-0.018486602,-0.020895774,-0.017265704,-0.023637837,-0.018686607,-0.019145822,-0.015424536,-0.023948153,-0.021429647;-0.020251345;0.006742691;0.0
data/model/LunarLander-v3_636576_1.pth;LunarLander-v3;qwen2.5-coder_llama3.2-vision;{'seed': 636576};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'model/LunarLanderDQN/', 'seed': 636576};400000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_pos, y_pos = observations[:2]
    angle = observations[4]
    
    # Reward for being close to the desired landing area along the red trajectory
    landing_area_x = 0.0  # Assuming the landing area is at x=0
    landing_area_y = -10.0  # Assuming the landing area is at y=-10
    proximity_reward = -np.sqrt((x_pos - landing_area_x)**2 + (y_pos - landing_area_y)**2)
    
    # Penalty for being off the red trajectory
    if x_pos < landing_area_x:
        off_trajectory_penalty = max(0, 5.0 * abs(x_pos - landing_area_x))
    else:
        off_trajectory_penalty = 0
    
    # Reward for landing successfully
    if is_success:
        landing_reward = 1000.0
    else:
        landing_reward = 0
    
    # Penalty for failure
    if is_failure:
        failure_penalty = -500.0
    else:
        failure_penalty = 0
    
    total_reward = proximity_reward - off_trajectory_penalty + landing_reward + failure_penalty
    
    return total_reward";-0.027165636,-0.028815066,-0.018324913,-0.019622114,-0.018115245,-0.02705739,-0.017999638,-0.018399024,-0.018584598,-0.020659165,-0.02403732,-0.01962542,-0.025563134,-0.020805122,-0.021321004,-0.022557104,-0.022725295,-0.027506014,-0.018580142,-0.024360647,-0.020175995,-0.021761427,-0.02432207,-0.028435165,-0.028389454,-0.027225347,-0.027568106,-0.026116246,-0.027957857,-0.01767787,-0.020625021,-0.020968363,-0.028229764,-0.019295787,-0.025622496,-0.02517196,-0.02154488,-0.028206503,-0.021126572,-0.022092424,-0.024390643,-0.020438476,-0.026956104,-0.024700187,-0.019588264,-0.024583122,-0.018557392,-0.025077442,-0.023199936,-0.020321023,-0.020184496,-0.017659321,-0.025887324,-0.02943765,-0.019975102,-0.024955561,-0.017337814,-0.0243928,-0.026056794,-0.025194405,-0.026008623,-0.027317898,-0.029172793,-0.021978738,-0.026428415,-0.020902343,-0.02449333,-0.023137981,-0.018187517,-0.021025639,-0.020565081,-0.018352572,-0.023201972,-0.023587512,-0.02591537,-0.018665463,-0.026892018,-0.021278318,-0.021280123,-0.026632173,-0.024239156,-0.025677564,-0.024271518,-0.020274216,-0.025793396,-0.029402329,-0.018906036,-0.020197412,-0.020882582,-0.021006042,-0.024999417,-0.020600846,-0.01818095,-0.039054662,-0.019500611,-0.028293947,-0.020812184,-0.024701398,-0.023543894,-0.021569146,-0.017216576,-0.023274818,-0.025252497,-0.024123594,-0.023963086,-0.028009376,-0.027534982,-0.022737809,-0.022124313,-0.022927402,-0.024116553,-0.018191442,-0.020929402,-0.024981137,-0.028978348,-0.025366792,-0.0224335,-0.021585865,-0.025438175,-0.025249327,-0.022531336,-0.023811784,-0.031056538,-0.019576926,-0.023258384,-0.030445136,-0.022984685,-0.020012017,-0.03169123,-0.031297028,-0.0262417,-0.02508245,-0.019196277,-0.024883984,-0.022533823,-0.027510207,-0.02279346,-0.030251963,-0.022556815,-0.019030038,-0.024031814,-0.026626104,-0.021998454,-0.023025598,-0.025484094,-0.026591077,-0.026977602,-0.026838409,-0.030329226,-0.023091717,-0.026854236,-0.021327956,-0.025826156,-0.03021893,-0.019799326,-0.023910532,-0.022486906,-0.022720655,-0.02798942,-0.024880713,-0.027577123,-0.020044353,-0.021646658,-0.020480206,-0.025113741,-0.03152319,-0.022526033,-0.022328785,-0.030421415,-0.020347634,-0.023451604,-0.023838572,-0.020764958,-0.01970454,-0.025945013,-0.025537178,-0.021191783,-0.02532257,-0.018482614,-0.02221668,-0.024262808,-0.025107339,-0.018958185,-0.019822437,-0.023054078,-0.022706011,-0.023005296,-0.02009808,-0.020362513,-0.021598307,-0.026440235,-0.02244526,-0.024836091,-0.02310717,-0.025921457,-0.023369925,-0.018810114,-0.022694573,-0.024869429,-0.018601853,-0.021174988,-0.016440772,-0.022087872,-0.01890374,-0.016443798,-0.021746315,-0.025465814,-0.018373972,-0.021513559,-0.021719852,-0.025226947,-0.021914596,-0.018885005,-0.019575728,-0.024150081,-0.01597113,-0.018153153,-0.021984613,-0.021573626,-0.019607391,-0.018537775,-0.025577936,-0.0193068,-0.017753627,-0.02366819,-0.017968992,-0.018843135,-0.018420732,-0.022797072,-0.023045424,-0.015053972,-0.015998624,-0.015996838,-0.021074064,-0.017255446,-0.019365966,-0.017821303,-0.015665801,-0.017452179,-0.025050415,-0.020113925,-0.021309434,-0.015126658,-0.01980441,-0.027238498,-0.019274361,-0.024164507,-0.015994338,-0.017246956,-0.018719176,-0.020203117,-0.020005569,-0.015134986,-0.021175466,-0.018628862,-0.016623287,-0.015203217,-0.015206339,-0.015979538,-0.021476964,-0.016113563,-0.020856734,-0.019524833,-0.016705323,-0.021321854,-0.018919053,-0.016451905,-0.016192894,-0.01824129,-0.015932623,-0.01793397,-0.02023628,-0.021924114,-0.025862694,-0.01573709,-0.024071682,-0.016643118,-0.02283028,-0.017991588,-0.022106078,-0.015525373,-0.018167451,-0.026097214,-0.016814802,-0.019897193,-0.015878245,-0.022097101,-0.020260766,-0.0199821,-0.01906829,-0.018264905,-0.01923076,-0.01781018,-0.017428301,-0.016165195,-0.023733467,-0.01640758,-0.016793776,-0.01811288,-0.01762464,-0.01622555,-0.017797481,-0.01976128,-0.018248009,-0.017526856,-0.019422898,-0.015988428,-0.018629298,-0.02105481,-0.019746767,-0.01703671,-0.015500287,-0.021197319,-0.019776428,-0.017657958,-0.019667005,-0.01897247,-0.021591054,-0.020803927,-0.018320566,-0.017531736,-0.01678796,-0.01945852,-0.01566791,-0.016515927,-0.019411163,-0.021231337,-0.01777891,-0.01705264,-0.017442847,-0.018129278,-0.018401727,-0.018414745,-0.021542704,-0.019452695,-0.015974844,-0.01858373,-0.0219419,-0.020261716,-0.021278499,-0.018377086,-0.019655045,-0.017479334,-0.020030648,-0.018409282,-0.01775719,-0.019392323,-0.019066261,-0.02097143,-0.015505357,-0.020592056,-0.020488251,-0.01636794,-0.020181308,-0.021481114,-0.020425178,-0.01613328,-0.022010067,-0.01615496,-0.016971309,-0.017948968,-0.016652301,-0.021945676,-0.016071383,-0.015832698,-0.021802042,-0.022066506,-0.015309982,-0.016094496,-0.01657847,-0.016309585,-0.016327163,-0.019735025,-0.01667656,-0.015983045,-0.018974325,-0.017769687,-0.015348622,-0.015558621,-0.02159922,-0.019293053,-0.022139478,-0.017178167,-0.018254241,-0.019729272,-0.021082867,-0.016456136,-0.015501648,-0.021612557,-0.017667606,-0.01647867,-0.01890073,-0.018276807,-0.017013058,-0.01779701,-0.016451724,-0.01720911,-0.01791295,-0.020479377,-0.016619,-0.015348358,-0.017506514,-0.021019118,-0.020322302,-0.0177529,-0.015508621,-0.018160315,-0.020728271,-0.019671014,-0.017481372,-0.015551501,-0.019115457,-0.016444128,-0.015812652,-0.0191243,-0.016552072,-0.019654285,-0.016259788,-0.015746823,-0.018681744,-0.021058835,-0.01636459,-0.02121803,-0.015662378,-0.019280417,-0.016020253,-0.016352758,-0.01654606,-0.018328626,-0.016463872,-0.016655734,-0.017372884,-0.019310713,-0.015704405,-0.019213364,-0.016993323,-0.01902613,-0.019599117,-0.016159145,-0.016786167,-0.018691681,-0.01617858,-0.019199148,-0.018727483,-0.020117218,-0.015212791,-0.014799069,-0.018654501,-0.016028015,-0.017134475,-0.016331457,-0.015931247,-0.020679304,-0.017772699,-0.01996032,-0.018846598,-0.016047213,-0.019690357,-0.018448036,-0.015437905,-0.017843226,-0.019568417,-0.016122745,-0.0150766075,-0.021234773,-0.017653462,-0.017384164,-0.015812693,-0.018026542,-0.019336764,-0.017700445,-0.017662404,-0.019056898,-0.016599886,-0.017481785,-0.018184952,-0.017054453,-0.018916799,-0.015561075,-0.016526908,-0.015600094,-0.0152346585,-0.015038287,-0.020218562,-0.018818771,-0.019505274,-0.017542081,-0.01852702,-0.018541843,-0.01619934,-0.015898008,-0.018797899,-0.016850028,-0.015542689,-0.016366743,-0.01584393,-0.016591774,-0.017549565,-0.018006345,-0.01762286,-0.020059768,-0.01964728,-0.017030869,-0.018005062,-0.01666443,-0.019354094,-0.020617813,-0.015753185,-0.0163157,-0.017026851,-0.015535352,-0.018295046,-0.015231362,-0.01675798,-0.01906602,-0.01864652,-0.015579484,-0.019783635,-0.0185472,-0.016281908,-0.019908376,-0.01574915,-0.016334705,-0.020415802,-0.019672807,-0.01522711,-0.01627015,-0.016217003,-0.015831837,-0.01934967,-0.019693654,-0.01735498,-0.02012873,-0.018444397,-0.01674336,-0.016785221,-0.019308273,-0.015576836,-0.019131,-0.016984211,-0.016876534,-0.018213611,-0.015288293,-0.015397424,-0.018346474,-0.016054915,-0.020576414,-0.019239064,-0.017600063,-0.016562758,-0.01789313,-0.020525154,-0.015265442,-0.014903882,-0.016886503,-0.015628684,-0.016946286,-0.019682366,-0.016683575,-0.016722845,-0.016193718,-0.0152639095,-0.017180013,-0.01601964,-0.017354207,-0.015289428,-0.019619169,-0.015054611,-0.015219769,-0.018215876,-0.01599287,-0.016398272,-0.016463038,-0.018637327,-0.017809525,-0.017872592,-0.018451033,-0.016220635,-0.019875336,-0.017510759,-0.016125845,-0.015486739,-0.018466897,-0.0154264765,-0.019182649,-0.017772295,-0.018341335,-0.019763134,-0.016484689,-0.017267143,-0.016394079,-0.016690316,-0.019334437,-0.016966807,-0.018917972,-0.017613227,-0.018132674,-0.017361207,-0.019017393,-0.02109097,-0.017212613,-0.019955836,-0.016564474,-0.017306078,-0.0161316,-0.015701355,-0.0179182,-0.016445369,-0.017206982,-0.016041119,-0.015608444,-0.016189717,-0.017624099,-0.020288652,-0.01729945,-0.017990865,-0.017397564,-0.016033355,-0.015061668,-0.018854065,-0.01694926,-0.019453961,-0.016584344,-0.018389596,-0.020289823,-0.0195815,-0.017353794,-0.019573178,-0.015696198,-0.01786792,-0.015999036,-0.022145879,-0.018618885,-0.015878754,-0.015198855,-0.015376722,-0.017324347,-0.015649118,-0.018599285,-0.017158346,-0.019878212,-0.017852861,-0.018830856,-0.020808358,-0.016794812,-0.01780204,-0.015581942,-0.017098205,-0.018519944,-0.01984015,-0.019541923,-0.01607021,-0.020359728,-0.016181067,-0.016630631,-0.019828267,-0.01754632,-0.019824373,-0.016704904,-0.016455289,-0.020788807,-0.015671851,-0.015766485,-0.02045642,-0.0164819,-0.01973893,-0.019817645,-0.018703546,-0.015527841,-0.017804315,-0.020640979,-0.02147189,-0.020383993,-0.019886198,-0.016597768,-0.017270537,-0.017125804,-0.017974406,-0.019440934,-0.017870987,-0.018443968,-0.019060766,-0.020412209,-0.01923652,-0.018427199,-0.020026553,-0.01680231,-0.016281141,-0.018177439,-0.02052924,-0.017122377,-0.01952272,-0.015077974,-0.020280888,-0.01870548,-0.019802423,-0.01933559,-0.020510962,-0.016105635,-0.019696893,-0.020662047,-0.015522629,-0.018755104,-0.01818856,-0.0206785,-0.019181082,-0.020538235,-0.020365162,-0.016884858,-0.016260928,-0.018260624,-0.02004916,-0.019298939,-0.02072051,-0.016378881,-0.017678916,-0.016309861,-0.0214738,-0.019200612,-0.015995836,-0.021928128,-0.019524341,-0.016129488,-0.020913158,-0.016958717,-0.020914266,-0.020932795,-0.015348288,-0.015366105,-0.015979141,-0.017907323,-0.017780151,-0.0220891,-0.01610841,-0.016627485,-0.016327256,-0.019666411,-0.016772298,-0.0208546,-0.016630176,-0.01957188,-0.01881583,-0.016999744,-0.01829022,-0.018109884,-0.020886375,-0.018022543,-0.017084667,-0.01696561,-0.015812246,-0.01603773,-0.021462856,-0.019555788,-0.01866125,-0.020993179,-0.018852878,-0.021061465,-0.02096943,-0.02092685,-0.02191904,-0.016480472,-0.019912273,-0.02031213,-0.01699126,-0.02520359,-0.016394507,-0.018564861,-0.016665928,-0.016976237,-0.01602955,-0.017726356,-0.017460844,-0.015452994,-0.017269913,-0.019005122,-0.018411115,-0.021228794,-0.015819607,-0.01759492,-0.01717195,-0.019873574,-0.017595638,-0.015503859,-0.01711835,-0.01788359,-0.016403807,-0.017749436,-0.015500446,-0.017398141,-0.01566018,-0.020235706,-0.020783497,-0.016936736,-0.016624462,-0.01623232,-0.01683047,-0.017827546,-0.017925078,-0.015456206,-0.019938765,-0.020412305,-0.019954259,-0.018895322,-0.018427301,-0.017579926,-0.017929252,-0.021022867,-0.019397287,-0.019489957,-0.017680347,-0.017807337,-0.016630799,-0.019929703,-0.01582749,-0.016291747,-0.01621669,-0.018284732,-0.018106727,-0.016288502,-0.021105964,-0.015427346,-0.015793966,-0.015672706,-0.016484046,-0.017625008,-0.01688053,-0.019736193,-0.018822601,-0.016610473,-0.019587932,-0.016381415,-0.016355518,-0.01843194,-0.016769161,-0.015823709,-0.018906863,-0.016041536,-0.020594684,-0.018942842,-0.018888105,-0.019317152,-0.019867541,-0.020081025,-0.020181673,-0.018516364,-0.017143177,-0.018888775,-0.016805885,-0.017104203,-0.020037705,-0.016871486,-0.019625371,-0.016274964,-0.02000648,-0.018372705,-0.016300062,-0.02160193,-0.017674742,-0.020342652,-0.01660654,-0.017525194,-0.014918925,-0.019495022,-0.019270718,-0.02090082,-0.019616561,-0.018863793,-0.019272735,-0.01905699,-0.020679208,-0.016969929,-0.020601023,-0.020267695,-0.01751782,-0.019968435,-0.019377764,-0.01713382,-0.016172502,-0.018105607,-0.018021122,-0.016073756,-0.018022785,-0.019250128,-0.01717138,-0.016769022,-0.01951816,-0.020679234,-0.020136911,-0.01800677,-0.017859677,-0.019371795,-0.017822621,-0.01687597,-0.019171575,-0.022285515,-0.016280873,-0.01821359,-0.018464135,-0.016031673,-0.016276347,-0.020912576,-0.01785986,-0.01814103,-0.016431263,-0.017559782,-0.016315924,-0.019713696,-0.017986946,-0.020374974,-0.01712613,-0.02035829,-0.016675444,-0.01686894,-0.019196035,-0.017135266,-0.017253578,-0.01802151,-0.016417433,-0.022599705,-0.01782084,-0.02120052,-0.021645969,-0.021657065,-0.02650034,-0.023008898,-0.018842649,-0.017744608,-0.026613524,-0.019945355,-0.01632431,-0.017556418,-0.019929016,-0.021563597,-0.016561931,-0.018062606,-0.02208989,-0.015275505,-0.021573465,-0.017563194,-0.01566364,-0.018099705,-0.027090881,-0.019634021,-0.021337267,-0.015501056,-0.018341286,-0.021584287,-0.019780466,-0.019972252,-0.016130358,-0.017177051,-0.016841527,-0.021193502,-0.018910434,-0.020963162,-0.015801461,-0.022530096,-0.02453567,-0.01732234,-0.015369319,-0.022480428,-0.021962853,-0.020211842,-0.018233547,-0.016777785,-0.016718931,-0.017912852,-0.017288351,-0.016992515,-0.018837782,-0.017069818,-0.019054623,-0.015189251,-0.018258763,-0.021619584,-0.021387642,-0.018575775,-0.017782738,-0.019639097,-0.017925303,-0.016128378,-0.02052867,-0.015544144,-0.020600142,-0.018777536,-0.015222966,-0.019156763,-0.016406132,-0.020783665,-0.01614004,-0.015969962,-0.016302722,-0.020398442,-0.01843326,-0.01686843,-0.01566225,-0.024887275,-0.018094338,-0.020633925,-0.019452298,-0.020618169,-0.015861467,-0.017442523,-0.015478188,-0.017399047,-0.020990416,-0.018113637,-0.024252048,-0.021915045,-0.018414445,-0.017338421,-0.022665286,-0.024379693,-0.027370878,-0.019263336,-0.021585984,-0.021217845,-0.01614033,-0.0172713,-0.019551817,-0.019704506,-0.019210555,-0.021402704,-0.015661117,-0.016148621,-0.018934656,-0.018872423,-0.015873838,-0.01826335,-0.01790754,-0.020428544,-0.021141788,-0.016347822,-0.016606035,-0.022680586,-0.021918599,-0.01923081,-0.022127546,-0.018703587,-0.015979517,-0.017181635,-0.016012099,-0.020739336,-0.021754732,-0.021129096,-0.020968983,-0.015489122,-0.021456154,-0.020683601,-0.020092357,-0.017624555,-0.015590653,-0.017809121,-0.02013475,-0.018870663,-0.021230098,-0.02177298,-0.015215552,-0.019510387,-0.018051405,-0.015820147,-0.021436365,-0.021237237,-0.018259518,-0.015908588,-0.01689533,-0.018446758,-0.017655017,-0.017522292,-0.019032229,-0.021481195,-0.018920515,-0.015473445,-0.016954066,-0.015686123,-0.017071271,-0.018265644,-0.01917517,-0.022070574,-0.016155548,-0.017507123,-0.020540059,-0.017520113,-0.018407604,-0.019437555,-0.020755876,-0.017925175,-0.02130523,-0.017009597,-0.023750026,-0.016608752,-0.015827885,-0.018733265,-0.021711128,-0.022264168,-0.018846711,-0.022882441,-0.01534981,-0.015684173,-0.019977871,-0.019955423,-0.017476302,-0.015602462,-0.015739648,-0.015824016,-0.01806122,-0.01870607,-0.016662193,-0.021063555,-0.016758393,-0.02141286,-0.019918174,-0.019698184,-0.016173491,-0.02171506,-0.020285418,-0.017978875,-0.017166402,-0.021382896,-0.015715513,-0.019233514,-0.016487254,-0.019024497,-0.019152943,-0.019083282,-0.015437945,-0.017595092,-0.022394283,-0.021084847,-0.019703032,-0.016922263,-0.015387777,-0.019083466,-0.01737784,-0.022924744,-0.017376335,-0.020693896,-0.016139459,-0.015975762,-0.016640674,-0.0182494,-0.021752235,-0.016236993,-0.021602355,-0.016496848,-0.016755562,-0.018416915,-0.018242968,-0.020870993,-0.023265013,-0.02203153,-0.014917581,-0.016036808,-0.01893437,-0.017591331,-0.018061321,-0.027345516,-0.021758355,-0.018392978,-0.025759362,-0.015986716,-0.02131041,-0.01647515,-0.016006172,-0.018252943,-0.01582337,-0.020379348,-0.016519029,-0.017920278,-0.0216758,-0.026690435,-0.018909402,-0.018617501,-0.017111007,-0.018496713,-0.021784505,-0.017048096,-0.01711473,-0.019086579,-0.020569017,-0.020055005,-0.018912673,-0.01840182,-0.021702614,-0.016727772,-0.016071657,-0.020454654,-0.028200343,-0.020101624,-0.02015498,-0.028801862,-0.01599896,-0.019697865,-0.017976098,-0.017997455,-0.021281121,-0.022929674,-0.01582268,-0.019245908,-0.016537316,-0.01816756,-0.016319338,-0.02277241,-0.024892235,-0.020871842,-0.017490664,-0.020834591,-0.021920254,-0.018557567,-0.01771796,-0.020081095,-0.01600276,-0.016641429,-0.020797972,-0.020735687,-0.018425329,-0.020825654,-0.0181227,-0.017485611,-0.021749286,-0.019735672,-0.022632556,-0.027389454,-0.0151985055,-0.015686283,-0.022044905,-0.0153745245,-0.01641834,-0.01838343,-0.01942145,-0.021331033,-0.018603347,-0.01565906,-0.023680195,-0.01567337,-0.020301562,-0.017514879,-0.015897611,-0.019491224,-0.01647036,-0.01629974,-0.01767532,-0.02367973,-0.017953008,-0.015829545,-0.022705879,-0.018769918,-0.016922873,-0.019897446,-0.01743984,-0.01934239,-0.019232983,-0.016151661,-0.019127123,-0.02288859,-0.020882621,-0.01806822,-0.024665039,-0.018294863,-0.018240215,-0.018407946,-0.019191269,-0.022587458,-0.022482472,-0.023495425,-0.020422522,-0.01797517,-0.017407117,-0.016527824,-0.020661607,-0.018147402,-0.021046106,-0.017246269,-0.016195038,-0.016461343,-0.019733375,-0.021253722,-0.019850316,-0.017718159,-0.019190565,-0.018330738,-0.017930625,-0.01748255,-0.021812057,-0.018583218,-0.01708945,-0.016449178,-0.01630007,-0.023000922,-0.017971048,-0.015959946,-0.016770193,-0.020836094,-0.024956891,-0.018425161,-0.017397773,-0.019992515,-0.023567522,-0.017874267,-0.018663622,-0.018914677,-0.017298078,-0.017569577,-0.015672931,-0.019897813,-0.023464747,-0.01649093,-0.020529995,-0.022060232,-0.01867783,-0.019485136,-0.021684572,-0.017447624,-0.023051172,-0.020426473,-0.017060805,-0.02358204,-0.022817176,-0.016568072,-0.018044053,-0.02040147,-0.024620982,-0.018631462,-0.018464508,-0.023200387,-0.016249444,-0.019797942,-0.020171246,-0.023686493,-0.020564193,-0.018890467,-0.01760797,-0.02042752,-0.017839368,-0.019322777,-0.018267825,-0.01703316,-0.018494423,-0.020529544,-0.023827396,-0.017637711,-0.021908056,-0.022098249,-0.024460582,-0.021460809,-0.019712409,-0.021910654,-0.02176808,-0.017558433,-0.022253595,-0.017826756,-0.019804006,-0.020205183,-0.019559605,-0.019682262,-0.02124968,-0.022377321,-0.018868314,-0.01758465,-0.021703454,-0.02540338,-0.01958427,-0.01809639,-0.026027743,-0.01740229,-0.01876495,-0.023315217,-0.0164488,-0.0200003,-0.017744558,-0.018678084,-0.024251157,-0.019462105,-0.020172812,-0.016966378,-0.018076802,-0.025780527,-0.017071506,-0.016439933,-0.022690814,-0.017303398,-0.021019166,-0.02155224,-0.019053562,-0.019157346,-0.022287853,-0.018020965,-0.02004999,-0.018457927,-0.020132426,-0.018516395,-0.01612645,-0.017410137,-0.02013909,-0.016105639,-0.022177666,-0.022637311,-0.020226635,-0.0224025,-0.017459435,-0.018949151,-0.018306542,-0.019493448,-0.020065527,-0.01677161,-0.020863328,-0.01770156,-0.01701531,-0.019133423,-0.017661247,-0.017671002,-0.017649809,-0.017702166,-0.023204224,-0.01647084,-0.017844232,-0.016846001,-0.01935017,-0.020622099,-0.02332767,-0.017033206,-0.01569151,-0.017736822,-0.016839448,-0.019272221,-0.015355847,-0.020760382,-0.018019995,-0.018336473,-0.017692227,-0.018330505,-0.018902045,-0.021617299,-0.019976696,-0.018376304,-0.016380858,-0.020998714,-0.017177396,-0.021235624,-0.02023848,-0.015505905,-0.022202311,-0.021198148,-0.015336559,-0.017938338,-0.01626572,-0.0180063,-0.019634977,-0.020157281,-0.017432969,-0.021146681,-0.020204753,-0.016227951,-0.01597126,-0.015488126,-0.019616624,-0.021472203,-0.015358868,-0.020004295,-0.020511657,-0.020416046,-0.015544849,-0.019022312,-0.017258737,-0.020864636,-0.017805196,-0.017633706,-0.018746149,-0.01658838,-0.020688035,-0.02104006,-0.022867355,-0.017028078,-0.018997386,-0.020284818,-0.017297814,-0.020842616,-0.017145103,-0.017601069,-0.021652224,-0.015850013,-0.017560313,-0.01871707,-0.020841993,-0.019296383,-0.016937569,-0.020087644,-0.020296482,-0.021778863,-0.019074915,-0.01536272,-0.020665959,-0.016865877,-0.01650629,-0.015989378,-0.016477365,-0.016476957,-0.01895568,-0.02164266,-0.016634006,-0.015373739,-0.016841391,-0.020116396,-0.019114234,-0.016501494,-0.017546294,-0.015470962,-0.021111846,-0.019561742,-0.017299974,-0.018557006,-0.019858463,-0.020726793,-0.02006444,-0.016258616,-0.016800517,-0.019149281,-0.016057663,-0.01843108,-0.020951556,-0.019695789,-0.016503092,-0.016340172,-0.01598416,-0.018248212,-0.01693562,-0.017299535,-0.018117677,-0.016638352,-0.01587424,-0.02118374,-0.020346085,-0.016400864,-0.018668322,-0.01893166,-0.017602684,-0.016953047,-0.017001873,-0.017947331,-0.018766776,-0.017487187,-0.020738976,-0.015884038,-0.023135532,-0.017112494,-0.017035004,-0.01668095,-0.019270845,-0.02152556,-0.02114127,-0.016897589,-0.016308768,-0.016975971,-0.016506752,-0.017590761,-0.017019033,-0.019712592,-0.021282768,-0.016822621,-0.018730193,-0.019590603,-0.0201133,-0.017785499,-0.019742515,-0.018261813,-0.016951831,-0.017895464,-0.020821689,-0.01760366,-0.015258032,-0.017438337,-0.01649972,-0.019781824,-0.018530773,-0.019558873,-0.016442863,-0.017824741,-0.018018441,-0.017605858,-0.01973231,-0.01726829,-0.016639786,-0.017258,-0.021451093,-0.0155339455,-0.019492919,-0.020226374,-0.022959659,-0.016264645,-0.018221183,-0.020096134,-0.015258509,-0.018445605,-0.015691563,-0.017702252,-0.017568149,-0.02151382,-0.017760308,-0.018263485,-0.018430887,-0.020758571,-0.021901336,-0.01841731,-0.018153595,-0.016575012,-0.015239526,-0.020463848,-0.0182154,-0.017274618,-0.01614544,-0.016673334,-0.018588517,-0.022265445,-0.019172734,-0.01942752,-0.017589945,-0.019516617,-0.017752625,-0.019485401,-0.015582016,-0.016661543,-0.01561913,-0.019868854,-0.016356818,-0.020304497,-0.015552327,-0.01687158,-0.017790323,-0.01712168,-0.016786879,-0.02131915,-0.016311174,-0.015903817,-0.018402925,-0.02137504,-0.019750142,-0.0164871,-0.017461145,-0.018837383,-0.02105458,-0.016012779,-0.017920574,-0.017286962,-0.01600145,-0.02127455,-0.021110382,-0.020798467,-0.018520366,-0.016473021,-0.021589693,-0.019915922,-0.021306297,-0.01810084,-0.021574056,-0.016152402,-0.019449715,-0.02112929,-0.017816031,-0.016148072,-0.022349207,-0.021969387,-0.01581341,-0.017641304,-0.017451257,-0.019050429,-0.022000639,-0.019048765,-0.019402642,-0.015975865,-0.026021643,-0.017447129,-0.02002879,-0.021065949,-0.024531787,-0.015524962,-0.017791372,-0.016801465,-0.018401293,-0.0186279,-0.021057023,-0.016311174,-0.015501842,-0.020596944,-0.015831575,-0.016274499,-0.016156686,-0.021153623,-0.016318843,-0.020492587,-0.02242329,-0.019698476,-0.022114633,-0.015683029,-0.017214129,-0.021725873,-0.01775247,-0.0181419,-0.021471357,-0.019708306,-0.02186362,-0.018060079,-0.020045327,-0.019099738,-0.016367137,-0.018468913,-0.020966029,-0.021225957,-0.017970895,-0.01632906,-0.02203011,-0.019429136,-0.019131016,-0.020107344,-0.018516475,-0.02065178,-0.016370453,-0.01982014,-0.021372326,-0.015906189,-0.021054087,-0.020358482,-0.017824119,-0.017002473,-0.01520838,-0.018372118,-0.019599555,-0.01766145,-0.017650796,-0.023406576,-0.020887394,-0.019826492,-0.01733438,-0.015784249,-0.016728064,-0.015435999,-0.020163722,-0.021358194,-0.018505871,-0.01871951,-0.025713028,-0.021495596,-0.01778839,-0.023272246,-0.018904116,-0.015758889,-0.021738654,-0.015919443,-0.019509334,-0.016937474,-0.018983293,-0.018293593,-0.020374063,-0.017910488,-0.01650206,-0.01833727,-0.017648302,-0.015299503,-0.018487746,-0.01716109,-0.015941938,-0.023813492,-0.020632852,-0.017805377,-0.02353714,-0.019762883,-0.01599928,-0.016859047,-0.022841293,-0.015715009,-0.02125524,-0.018874321,-0.020683162,-0.015544142,-0.019696366,-0.015746854,-0.022182051,-0.018468931,-0.020836325,-0.019296292,-0.017064301,-0.015626382,-0.021916809,-0.018626181,-0.022372939,-0.016859787,-0.015500518,-0.021025926,-0.0172741,-0.0189862,-0.01796592,-0.017493198,-0.016498309,-0.01597393,-0.017336562,-0.019137995,-0.021470709,-0.01860673,-0.01831783,-0.018298075,-0.024091015,-0.019079536,-0.017658645,-0.015963893,-0.021148965,-0.015017528,-0.015366967,-0.016492443,-0.018766664,-0.024844775,-0.016015802,-0.016297827,-0.017622547,-0.020734753,-0.019159433,-0.019940028,-0.02022115,-0.01797411,-0.021347458,-0.01968725,-0.0196204,-0.02023934,-0.019774403,-0.017250044,-0.015723655,-0.015569638,-0.021442557,-0.018159023,-0.021088379,-0.018881166,-0.02045368,-0.0183596,-0.017330406,-0.017660577,-0.017003391,-0.019369109,-0.016208706,-0.021389432,-0.019398304,-0.019925915,-0.017490415,-0.019988284,-0.015901946,-0.016593391,-0.015860029,-0.018983075,-0.023067461,-0.015384009,-0.01594895,-0.016183669,-0.016743997,-0.017183125,-0.020431409,-0.016088255,-0.017779933,-0.022261666,-0.015724214,-0.020156603,-0.016134206,-0.01632691,-0.015048985,-0.016340045,-0.016376244,-0.018010082,-0.018646307,-0.015543576,-0.02287724,-0.020644717,-0.018499892,-0.015197843,-0.016871778,-0.018736746,-0.018031424,-0.020631129,-0.019770088,-0.016023856,-0.017632853,-0.01774463,-0.022309136,-0.02132915,-0.022208191,-0.018717008,-0.01888992,-0.017947003,-0.015539078,-0.023228284,-0.022237552,-0.019418798,-0.022525989,-0.02392041,-0.019305576,-0.021488383,-0.021548484,-0.022536507,-0.021602448,-0.020844594,-0.02253041,-0.018015869,-0.020796612,-0.0178561,-0.021776693,-0.018564422,-0.022873051,-0.02020006,-0.01779127,-0.021061856,-0.022180809,-0.017228965,-0.022218626,-0.019988315,-0.023467397,-0.019973112,-0.018560063,-0.020766536,-0.019070536,-0.018519288,-0.02335977,-0.021349961,-0.02078719,-0.022611996,-0.019936947,-0.01896738,-0.019145383,-0.019819366,-0.019143414,-0.019846478,-0.023578351,-0.024716508,-0.02241623,-0.01873526,-0.018620692,-0.02107547,-0.02351657,-0.021522155,-0.019189678,-0.023675602,-0.020704657,-0.0163682,-0.0213525,-0.020347562,-0.02332496,-0.023413103,-0.016600907,-0.019640427,-0.02194085,-0.017037496,-0.02018664,-0.021383306,-0.017195325,-0.0165366,-0.020384176,-0.016096927,-0.01912343,-0.01815369,-0.02073817,-0.021831002,-0.017398965,-0.020718452,-0.017368367,-0.018981617,-0.017237293,-0.023847818,-0.01564351,-0.02143641,-0.022107983,-0.020407928,-0.015956532,-0.017981902,-0.020532103,-0.016805297,-0.021926655,-0.016599376,-0.015490691,-0.022702992,-0.020589294,-0.018637866,-0.01569475,-0.015054001,-0.019990444,-0.019847399,-0.01895221,-0.019042615,-0.018656353,-0.0202684,-0.02070072,-0.01785229,-0.018493645,-0.019353628,-0.024811449,-0.019453505,-0.016503623,-0.018008998,-0.017970407,-0.019263735,-0.015234081,-0.01818915,-0.018061858,-0.019278325,-0.020300405,-0.0208246,-0.019651953,-0.022687232,-0.020871524,-0.01504302,-0.018884746,-0.020725545,-0.020033391,-0.019842362,-0.020103164,-0.020235332,-0.015050602,-0.017303161,-0.018339368,-0.017471854,-0.018845195,-0.017956957,-0.0212687,-0.019150086,-0.015743064,-0.020692501,-0.01715562,-0.018139029,-0.016330147,-0.021959206,-0.01571511,-0.018301055,-0.01947601,-0.01602428,-0.015695443,-0.019502912,-0.017181467,-0.01845196,-0.01904497,-0.019508922,-0.021371452,-0.01888931,-0.016388094,-0.017644309,-0.019152386,-0.01883157,-0.019679155,-0.022575598,-0.019502481,-0.017714707,-0.01723194,-0.017458787,-0.016969454,-0.022717405,-0.015056255,-0.014913088,-0.017523644,-0.02207124,-0.019503225,-0.01638609,-0.017454574,-0.01624704,-0.017178956,-0.019009229,-0.015988372,-0.01765819,-0.019518452,-0.018085118,-0.020797689,-0.016640157,-0.015069552,-0.01666348,-0.019227983,-0.018617673,-0.016826876,-0.015052355,-0.015060434,-0.019118862,-0.018008186,-0.01719615,-0.016277766,-0.015438383,-0.017289592,-0.020635711,-0.017382683,-0.018047586,-0.018099451,-0.017334027,-0.019260036,-0.01714242,-0.02046373,-0.01613015,-0.016825346,-0.017646424,-0.016890328,-0.018962363,-0.016478812,-0.017446568,-0.018142326,-0.018723875,-0.020630792,-0.021327097,-0.021068346,-0.017569724,-0.016976114,-0.019939464,-0.015686244,-0.019421244,-0.01699794,-0.017248863,-0.019801447,-0.017723177,-0.016336918,-0.01516694,-0.017759701,-0.022123149,-0.017087266,-0.016076814,-0.020245835,-0.01553518,-0.020367285,-0.0186614,-0.020978283,-0.015335446,-0.019764274,-0.030885525,-0.015862485,-0.016523201,-0.02003535,-0.01763335,-0.017810712,-0.016838668,-0.01793879,-0.020232754,-0.01923897,-0.015212256,-0.017428322,-0.016759524,-0.017468518,-0.01683192,-0.021100659,-0.016817663,-0.0155355325,-0.015049006,-0.015052696,-0.019817702,-0.01616515,-0.015351004,-0.018471353,-0.014903936,-0.022100894,-0.020789726,-0.015516247,-0.0149092935,-0.017572952,-0.017391114,-0.017093401,-0.016988378,-0.015699517,-0.019997861,-0.017469011,-0.014763695,-0.01895946,-0.023082446,-0.017808845,-0.018857019,-0.018645419,-0.019409059,-0.020447006,-0.017756892,-0.02224004,-0.01979656,-0.017167263,-0.023401758,-0.019316455,-0.015054604,-0.020804657,-0.015859216,-0.01936651,-0.02020372,-0.01849521,-0.01681784,-0.02097737,-0.019116301,-0.021227175,-0.01930002,-0.017400017,-0.016217055,-0.018450724,-0.016673038,-0.019278137,-0.018481797,-0.016498685,-0.019433247,-0.022525135,-0.019116076,-0.01570477,-0.021236798,-0.016973788,-0.016470863,-0.02381133,-0.019497382,-0.016768102,-0.022839328,-0.02145165,-0.016028112,-0.020189112,-0.016410302,-0.01763061,-0.028366987,-0.01899122,-0.018186472,-0.018495383,-0.016709685,-0.01856505,-0.020315228,-0.0153814815,-0.021636713,-0.01699038,-0.019961009,-0.016027281,-0.016975619,-0.016430609,-0.018797353,-0.017493753,-0.016468057,-0.020640232,-0.016531862,-0.017158225,-0.015378704,-0.017799726,-0.015545249,-0.017201731,-0.015551505,-0.02005341,-0.021518381,-0.015205522,-0.019239306,-0.021704849,-0.01996581,-0.018203054,-0.020494016,-0.019777035,-0.017318472,-0.015716277,-0.015698928,-0.020089775,-0.018043162,-0.01726436,-0.018456755,-0.015059487,-0.015653998,-0.015864568,-0.019042157,-0.017922342,-0.016321925,-0.017683081,-0.019519472,-0.01650763,-0.018830847,-0.016461661,-0.018858653,-0.017492669,-0.020042483,-0.019250875,-0.020281872,-0.020450715,-0.023295334,-0.020074448,-0.01554157,-0.020975351,-0.014898189,-0.018441366,-0.015804734,-0.020363696,-0.018201226,-0.01604812,-0.015709525,-0.01649825,-0.015065335,-0.02148723,-0.019826157,-0.0148961805,-0.017663797,-0.016946534,-0.01794225,-0.019192573,-0.01846709,-0.020829698,-0.017126,-0.019932944,-0.016197253,-0.025565801,-0.015989212,-0.017934898,-0.018559726,-0.017139336,-0.015377466,-0.0152156325,-0.022025526,-0.018973377,-0.018352982,-0.020136964,-0.017265273,-0.015555272,-0.020038635,-0.015367068,-0.017496571,-0.019910833,-0.019696202,-0.019601678,-0.016889872,-0.01557888,-0.017821947,-0.01741119,-0.019445503,-0.017182602,-0.017999863,-0.016005982,-0.015699822,-0.020606631,-0.019497467,-0.015229011,-0.015541508,-0.017958034,-0.018919496,-0.020077374,-0.01586292,-0.016858565,-0.020252915,-0.019817416,-0.018673098,-0.016037544,-0.018825874,-0.016950449,-0.017495122,-0.018485736,-0.016153075,-0.01638733,-0.020507386,-0.02127011,-0.016992306,-0.019261736,-0.016014855,-0.019035125,-0.019801872,-0.015699042,-0.017257877,-0.018616384,-0.01764595,-0.01554876,-0.019323774,-0.020333907,-0.017062979,-0.016488625,-0.021880908,-0.017492412,-0.031758398,-0.018689666,-0.020290542,-0.01916719,-0.032477092,-0.016326241,-0.01904504,-0.021323135,-0.017160567,-0.02223226,-0.018717976,-0.017649079,-0.01659567,-0.029014492,-0.01626173,-0.016399097,-0.014907224,-0.024991652,-0.015381854,-0.017130932,-0.019856257,-0.01865564,-0.025421226,-0.017469535,-0.021716801,-0.015204888,-0.016176954,-0.02196178,-0.022969441,-0.022661027,-0.020961724,-0.023430772,-0.01778075,-0.01581093,-0.020867893,-0.018788677,-0.015519083,-0.021060895,-0.022740811,-0.022162553,-0.020065043,-0.019809162,-0.020307165,-0.019149296,-0.022051878,-0.018829316,-0.020057512,-0.017444132,-0.02189405,-0.018813357,-0.016422505,-0.021761982,-0.016731821,-0.020792328,-0.021066155,-0.019695863,-0.016923701,-0.017191036,-0.015922368,-0.017497517,-0.016661895,-0.017220577,-0.022463663,-0.023398682,-0.020535957,-0.014640569,-0.018611638,-0.019136941,-0.019279744,-0.016885092,-0.018003544,-0.021436596,-0.015459799,-0.015756436,-0.017884223,-0.019097636,-0.022362038,-0.017200267,-0.022510216,-0.018836167,-0.020043176,-0.022413062,-0.016119827,-0.0159758,-0.0173553,-0.015855765,-0.015675597,-0.0221003,-0.016144825,-0.023681091,-0.017267525,-0.018912565,-0.018117117,-0.015694752,-0.016002158,-0.018387623,-0.015743282,-0.022546051,-0.020246789,-0.017654981,-0.01718228,-0.018645981,-0.016767109,-0.015513167,-0.018982008,-0.016404262,-0.022558143,-0.019388529,-0.020938607,-0.01649519,-0.021235585,-0.015367343,-0.020537883,-0.017462593,-0.01852419,-0.020277318,-0.016623644,-0.017347047,-0.020379558,-0.019402761,-0.023703706,-0.016809873,-0.015678134,-0.018221145,-0.014615384,-0.01699521,-0.020386774,-0.02102098,-0.015525446,-0.020070191,-0.020095259,-0.019292759,-0.01537558,-0.022332825,-0.01897399,-0.017048718,-0.016764501,-0.021336716,-0.021543382,-0.016992703,-0.016446805,-0.023076253,-0.023904527,-0.021370484,-0.022571636,-0.017118359,-0.018688459,-0.02127159,-0.018754812,-0.021451008,-0.020088619,-0.015675608,-0.018751461,-0.01961715,-0.019310417,-0.02117685,-0.016180158,-0.01699578,-0.015525644,-0.020540426,-0.01664116,-0.020255212,-0.02172294,-0.02190418,-0.017474016,-0.016524103,-0.0205312,-0.016200727,-0.016748546,-0.020785026,-0.015201462,-0.016177459,-0.020123765,-0.01820384,-0.02006226,-0.016278062,-0.018369367,-0.015212428,-0.016377341,-0.01667695,-0.023205604,-0.019336872,-0.018643681,-0.016348857,-0.014898762,-0.016783934,-0.019926477,-0.019701973,-0.01565668,-0.018215032,-0.017293707,-0.019237652,-0.020678675,-0.017286452,-0.018385438,-0.024183951,-0.016589906,-0.015051965,-0.016039142,-0.017185513,-0.021916693,-0.016908068,-0.017725302,-0.015060936,-0.017436046,-0.019115608,-0.018383821,-0.022715637,-0.018818257,-0.019685479,-0.018853322,-0.01866369,-0.015364641,-0.016034199,-0.01987516,-0.017334847,-0.022673024,-0.017660117,-0.020115113,-0.018533265,-0.025085554,-0.023096792,-0.019293768,-0.021913707,-0.01890144,-0.01769973,-0.017263034,-0.02081431,-0.023781087,-0.018489765,-0.021301512,-0.015847333,-0.018654194,-0.016856203,-0.021384291,-0.018783987,-0.020367617,-0.018654617,-0.016213365,-0.019573975,-0.018613303,-0.020470668,-0.01777996,-0.02023762,-0.01552186,-0.020882798,-0.014899874,-0.016224546,-0.015594066,-0.017007284,-0.016849078,-0.018553227,-0.017881723,-0.016340788,-0.01847612,-0.015045757,-0.017650522,-0.017781302,-0.016184703,-0.022120226,-0.018736433,-0.018173823,-0.019088726,-0.020051656,-0.016821802,-0.018820625,-0.016834097,-0.015541385,-0.016814698,-0.017275142,-0.01585638,-0.020174934,-0.017149879,-0.02113701,-0.015229321,-0.018174756,-0.020215195,-0.015358968,-0.02050905,-0.020684319,-0.015761532,-0.016254552,-0.020645557,-0.021326818,-0.017531954,-0.019028453,-0.018104903,-0.016950943,-0.020720916,-0.015072407,-0.016017666,-0.017878221,-0.0158478,-0.017794099,-0.017116688,-0.021823723,-0.018241541,-0.015696399,-0.02202028,-0.019934898,-0.016990246,-0.020203788,-0.021065496,-0.01915341,-0.02213243,-0.015808104,-0.019423079,-0.015650177,-0.017764643,-0.022037303,-0.018632201,-0.020106202,-0.016650625,-0.017519847,-0.018237412,-0.018489907,-0.020957893,-0.020042561,-0.015836062,-0.01924043,-0.0190708,-0.020079086,-0.01926221,-0.017807506,-0.016002422,-0.019090984,-0.015890762,-0.017619232,-0.017259574,-0.01767976,-0.016548123,-0.017446555,-0.017284447,-0.015562752,-0.019506933,-0.018269608,-0.016153425,-0.016148603,-0.020795504,-0.02141131,-0.01764077,-0.022493802,-0.016371874,-0.020627894,-0.015991064,-0.023503741,-0.015900813,-0.019571543,-0.019279528,-0.017909145,-0.016635375,-0.018555986,-0.018323602,-0.015262427,-0.017622862,-0.02190081,-0.018014692,-0.020752685,-0.018732488,-0.016653907,-0.0152129205,-0.020240605,-0.020669296;-0.018995956;0.0027837497;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 4107};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'model/LunarLanderDQN/', 'seed': 4107};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_vel, y_vel = observations[3], observations[4]
    angle, ang_vel = observations[5], observations[6]
    leg1_contact, leg2_contact = observations[7] > 0.9, observations[7] > 0.9

    if leg1_contact and leg2_contact:
        reward = -abs(x_vel) - abs(y_vel) - abs(ang_vel)
    else:
        reward = -0.1 * (x_vel**2 + y_vel**2 + ang_vel**2)

    return reward";-0.24122311871639676,-0.2258829245430513,-0.13263305308249898,-0.21201863380177766,-0.16284910170129951,-0.20971391035811077,-0.1267071572505102,-0.08838605408154536,-0.22422576609190564,-0.10820333328333305,-0.22690449951241431,-0.10170574640021436,-0.13806721524780702,-0.12772686137720252,-0.2009435810978248,-0.12865302807105372,-0.08454672867590005,-0.1382239563973877,-0.10840140412824044,-0.1615177416815161,-0.30401965675960074,-0.11673756542369577,-0.1903390327508808,-0.07554577165034769,-0.1418955100430053,-0.12337262215091582,-0.06834183663306072,-0.06301511847489938,-0.16141249113324518,-0.024040419971419993,-0.06313689051353753,-0.06861688015709441,-0.15981604987640263,-0.15563025463598862,-0.13306435259798557,-0.12030037304332997,-0.12044564235956155,-0.060686333368456906,-0.026152284916183894,-0.08222884681987294,-0.015343675861858752,-0.017976884773600772,-0.012174392479376031,-0.026174180898999144,-0.01954055421228989,-0.02265677519560676,-0.014969425621038583,-0.05142085292759363,-0.26838623691016616,-0.016969240540294337,-0.00905560223999691,-0.010635914680551478,-0.0073948432660618365,-0.014463636111039149,-0.014331667876344123,-0.026282219345458217,-0.011271780694177875,-0.016269084892595227,-0.010709772002120782,-0.011699552754368014,-0.0070256722223418794,-0.013827237191272811,-0.007967057417691522,-0.012425714077784658,-0.014746630044054016,-0.010029773068103685,-0.010118361872845694,-0.0150406804924773,-0.007176557652416413,-0.002711760118199292,-0.005655621306991157,-0.0024314494743480635,-0.012532962270886799,-0.009432479356352864,-0.0061660234626504185,-0.012194195115581417,-0.0063427054689564125,-0.007862771929781177,-0.007385782704091446,-0.004901240675633746,-0.0046512451925132,-0.00575344251581889,-0.015554290212724479,-0.006250810265308213,-0.012788879602480418,-0.007863756424335717,-0.00725596114152539,-0.006279728540378063,-0.010458781040676716,-0.007731587657687865,-0.007136368029247123,-0.006004883384270099,-0.008346100162572291,-0.00538740948462595,-0.0032297161497958507,-0.006119177276406578,-0.00633889789494312,-0.007404901772800201,-0.00781458142878175,-0.005657535266203968,-0.00557162877612423,-0.01601223994002633,-0.0060920853320176535,-0.012472590832938285,-0.00397682826400963,-0.009008481672786511,-0.008427343785515158,-0.008660553035020842,-0.004966663954136316,-0.006864259261562747,-0.009764583433254233,-0.007565317167597914,-0.009576810733766953,-0.004990535180775714,-0.006237936814278095,-0.004879746347478499,-0.003589672763988417,-0.004542967599347062,-0.007590557962676811,-0.002731477931402039,-0.003865128706984248,-0.004841174240748936,-0.007424887860304949,-0.0038603110280779457,-0.0069375424027035585,-0.003864961037378299,-0.009878467526860852,-0.002317195421773641,-0.0044620557372997,-0.006314235548325608,-0.005277132407654002,-0.00724103170144283,-0.004513411171616453,-0.006301071019276497,-0.005102070602033887,-0.005758510024970234,-0.0034710297640331515,-0.005529695259391253,-0.008776745650562221,-0.00857093188585383,-0.003553199420624411,-0.005029761666449693,-0.009128411105882665,-0.0031164264039322473,-0.0418223357598581,-0.0022812197856622693,-0.005543038057661681,-0.00583394328122716,-0.0061294751596246986,-0.004087982064668045,-0.0019068346509448614,-0.02120812760127242,-0.007934710552810987,-0.0018340219485317554,-0.003436219693694341,-0.00741270942035898,-0.022355013207429855,-0.01125835156101589,-0.0055325118073952335,-0.003704516924238296,-0.006154769546962405,-0.011288053929478228,-0.12934316198423723,-0.0026899655094597746,-0.011970909283530956,-0.0133341620883999,-0.009202997203428754,-0.0022766166446214447,-0.0062633345019692,-0.0023755910036108063,-0.005967720128333977,-0.0035687000753777116,-0.0025464396342553194,-0.009971486649586143,-0.006607955442501229,-0.007362882456098193,-0.007791173490351171,-0.010384075675726237,-0.0038350787485964583,-0.00922231150599342,-0.01683307369121748,-0.03735557084024565,-0.09447229102575469,-0.004294996568018202,-0.003901679734688,-0.014538163288088083,-0.007895124985274731,-0.005566543579371336,-0.004871795810899224,-0.01432769670617441,-0.005130048667188729,-0.0015674982983990967,-0.004275776481695144,-0.009366978510788928,-0.013680298717469822,-0.013656560510771703,-0.00569100431552249,-0.002919396358536124,-0.011778649283899911,-0.002370328741382216,-0.0054680460902162935,-0.0059213906961290644,-0.01353626096654075,-0.007784615481589147,-0.0016630875818461422,-0.020471027985814752,-0.012482075000492048,-0.0043918019912894185,-0.0036934062762060253,-0.005464856737454744,-0.003958946305944861,-0.013240684230411286,-0.008588487490775594,-0.006283442475173864,-0.005524101726272555;-0.03448894206484609;0.058836006543148085;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 917922};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'model/LunarLanderDQN/', 'seed': 917922};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x_pos, y_pos, x_vel, y_vel, angle, ang_vel, leg_0_contact, leg_1_contact = observations

    # Reward for being close to the landing pad (centered at origin)
    position_reward = -np.sqrt(x_pos**2 + y_pos**2)

    # Penalty for moving once touching down
    movement_penalty = 0
    if leg_0_contact or leg_1_contact:
        movement_penalty = -(abs(x_vel) + abs(y_vel))

    # Reward for a stable angle and angular velocity when landing
    stability_reward = -abs(angle) - abs(ang_vel)

    # Penalty for failing
    failure_penalty = -10.0 if is_failure else 0.0

    return position_reward + movement_penalty + stability_reward + failure_penalty";-0.06506094594073569,-0.08675844369648929,-0.11475791385974728,-0.034483167043663415,-0.10420331142858646,-0.03676904259101066,-0.08542958967868389,-0.0722848889305045,-0.13544563610296806,-0.045530639158069895,-0.06402528817515056,-0.0730574596286085,-0.07903952749043072,-0.07928689893243272,-0.04200965185693183,-0.07723926513179621,-0.043576334589432504,-0.03731664088830357,-0.06973997700808655,-0.06296812057241162,-0.030427962142418635,-0.07272223910793875,-0.03404387296661622,-0.03586519705260786,-0.025318033508631467,-0.02971056408165609,-0.04760275713186965,-0.05979575997662169,-0.048745051257785194,-0.0529922546187739,-0.06492281984285696,-0.02668147523440997,-0.03725583523173111,-0.06748600894277272,-0.03395796053579115,-0.03850048158706656,-0.034359786841869085,-0.03959231331301235,-0.033083477131684476,-0.032805781231301,-0.02512010848650041,-0.05903332304872142,-0.02497724166783137,-0.0316875611165335,-0.05687841801534708,-0.026959776456827636,-0.05804513463894662,-0.04881727640925433,-0.028228492748619383,-0.04377614698516276,-0.04527328372917092,-0.03422817432182552,-0.03659893996574202,-0.029077583104803628,-0.0513065605807886,-0.035252094122873945,-0.050383468596110585,-0.05010546412935964,-0.04020692136892146,-0.030648347763112833,-0.02992684756252744,-0.02520491467985163,-0.029943530407627397,-0.0452996508587313,-0.03564646244976972,-0.03808794699105823,-0.03806783280078915,-0.05710052849439833,-0.05445608373398697,-0.030566789122711217,-0.04620674535555709,-0.041383374190916526,-0.041144553932462274,-0.04303168639259113,-0.04269955433473206,-0.026078480179918415,-0.043126892061480564,-0.04708530731351724,-0.050259932209609705,-0.03302189492153855,-0.0377369987861839,-0.054563758467504796,-0.03171524698169539,-0.030382870883012437,-0.03400283543792322,-0.03487422017182111,-0.03636535296973092,-0.03588858323216638,-0.05388285986560087,-0.045084381822567667,-0.030730669422024876,-0.033425264024021684,-0.0404238631073877,-0.05438538355657562,-0.041660534853963996,-0.029134151052424825,-0.04587665837367882,-0.03245355171893578,-0.029552426670617044,-0.05706835945258641,-0.04643698762017292,-0.04806713737349667,-0.02849383092385032,-0.02767859078595838,-0.043010882705423706,-0.029034843787004782,-0.044519900199435136,-0.049550188380538124,-0.03894372107593782,-0.03518677334761131,-0.03221735878629263,-0.045116925139580606,-0.03251188533679045,-0.04944015203835439,-0.03879545783294762,-0.0416300356916972,-0.027543786624822496,-0.03921549926014903,-0.03379564827235017,-0.02945102853912944,-0.029706819711579974,-0.030941945957100602,-0.036994868503921224,-0.03802215449936083,-0.0407652237987781,-0.04595998378270906,-0.04104121921809085,-0.03952575439246469,-0.04094884216478517,-0.0340923859986186,-0.026223986459893555,-0.028894696718785452,-0.04627760399714023,-0.03235466654433869,-0.02875709312040198,-0.028519598356222742,-0.031830356480463076,-0.028856439136731145,-0.02998089126222823,-0.03262839858458355,-0.03126333327720681,-0.02936825686889791,-0.04029605137713767,-0.03340447587973643,-0.03831696760403261,-0.030561388738852637,-0.03610703053970909,-0.03126008658939103,-0.05014389648616346,-0.027829626416738803,-0.031889945977369924,-0.03413819886821844,-0.03878980454360148,-0.02475744778096016,-0.027231102645521633,-0.038234835376949695,-0.03452897966523854,-0.03476607125047939,-0.027576357903669423,-0.034219626138195756,-0.024049868747037396,-0.02881857695922147,-0.03355778986555326,-0.027194826225841087,-0.02663841075030378,-0.026346580080829483,-0.046306595511647224,-0.05033004628099698,-0.03457770344147952,-0.04190780804865191,-0.027335754335700166,-0.027653011288408764,-0.03513524398074766,-0.03139155618519231,-0.042924469902451204,-0.036514699528577506,-0.03865097742158049,-0.028735461432248678,-0.03808361977471144,-0.035069483558055434,-0.033737703769842,-0.04482481181641627,-0.03019613973005653,-0.026112586941394112,-0.029362465031174095,-0.03220886247526051,-0.04078648702259516,-0.040344630041204046,-0.042454710548037636,-0.03872306424612259,-0.030530964491860622,-0.027281501849384417,-0.04419052687324356,-0.03571742405704189,-0.0311782901966309,-0.029212048475988867,-0.024418663180561052,-0.028091475530858785,-0.03587755820286362,-0.046063604658548654,-0.04119703674176434,-0.04048521047356017,-0.02996435956457096,-0.02522214208683583,-0.02406049810014941,-0.03423867038527436,-0.03319134324579705,-0.04156289533035225,-0.04000707735594533,-0.0401617088962936,-0.03185273480568489,-0.023313584426511,-0.023425642062353258,-0.03008159910550055,-0.02317998753601208,-0.028308274480905785,-0.037749525073657364,-0.029348533246691504,-0.04587336956004619,-0.028074258567486715,-0.028908028372036834,-0.041242318803040946,-0.05014672967839375,-0.03811539573278143,-0.03787383235640606,-0.03212209371548384,-0.025503283032801295,-0.04598123756387088,-0.02802086765702637,-0.05351215004349586,-0.0280047445859932,-0.032015017884884346,-0.024320789991093245,-0.03570272445890437,-0.03283889601497445,-0.03654766719816258,-0.04514734998301301,-0.04606257722207013,-0.02493271800117585,-0.036900052635398924,-0.027344012141441602,-0.02640817922161492,-0.032319048010215956,-0.037719176344285864,-0.0280808710067924,-0.04071049887557484,-0.023299760944677828,-0.05377441175558807,-0.047293017182320145,-0.03661664814501577,-0.03504212995743203,-0.03278702662541826,-0.03298292197124594,-0.025712049888455973,-0.024594172337158007,-0.037339663144740264,-0.026696450340763584,-0.03156572511661776,-0.025683726942285615,-0.04930264490386919,-0.043752246644463706,-0.02969688306197155,-0.039962932310828696,-0.03342257048594592,-0.03315156585686653,-0.043735604357310075,-0.041108297053586096,-0.029681321223626714,-0.03323096962310794,-0.04966928935286275,-0.02791348363209649,-0.03518311479408675,-0.03585897916747635,-0.053793690952936436,-0.03831370265392082,-0.03660410689928983,-0.0319194243880148,-0.038724020109754655,-0.025915898809661136,-0.027947167325413753,-0.045447930616033805,-0.039001644543587975,-0.04276523301556448,-0.03935151351615569,-0.04389224982291595,-0.046478581571646374,-0.052973799926444,-0.03451561466447363,-0.04756795984301197,-0.03596078379375658,-0.02574733316993293,-0.04587661327156538,-0.03195922595344974,-0.038214614689592065,-0.02770044041697239,-0.03446323886602559,-0.036657258631249544,-0.03592500024052315,-0.024397389929459074,-0.04293550622278387,-0.03125103658975568,-0.030555840555885033,-0.028510025697647663,-0.031006305170068065,-0.03594897598664106,-0.02956735822501169,-0.030761256491337253,-0.050524382031174,-0.024592963957791508,-0.030004704493104002,-0.05123163886918065,-0.039609906473776976,-0.025499460092038524,-0.04807101883037623,-0.030547327636055,-0.023895229318617373,-0.03503147775061409,-0.046866440708382306,-0.027688122765527446,-0.0492033097061419,-0.023061818469313072,-0.035600362462034955,-0.03487206497877199,-0.024192587778408114,-0.04644873783831164,-0.030916757452798888,-0.039450849540632035,-0.02628067901040753,-0.03930096995895582,-0.023462763330984286,-0.025026880684799233,-0.05177110082197851,-0.022639559963943352,-0.03384874036027116,-0.027664311229487232,-0.040898818420146144,-0.04510993890340729,-0.02758980827217927,-0.0436355917450313,-0.04820294748744644,-0.04690866473711869,-0.03035123269676655,-0.0441453304749794,-0.043063167165817595,-0.043567660869864605,-0.027139722120090658,-0.05479976038568493,-0.03827841154785463,-0.026881024139312135,-0.03194689476694175,-0.029097654924183817,-0.02574010603680203,-0.048646771546950685,-0.05269649346029593,-0.035727047510488164,-0.024129825626110383,-0.025803086037474852,-0.02694247892380781,-0.05335892305530066,-0.027706620625968546,-0.027623420150530698,-0.026512101748656692,-0.04321272402600151,-0.0247888833310135,-0.039138088053607585,-0.02434957731925321,-0.03221878489297455,-0.02891486204348338,-0.034105496862630404,-0.041145015258433074,-0.026077190356912305,-0.03081403524136769,-0.03480731336708323,-0.044202955226386516,-0.0494835676309721,-0.027650260528964268,-0.04371055700269288,-0.03468367126300006,-0.03888348233300074,-0.033216310748266566,-0.04843029894132843,-0.04605010459061011,-0.036759623639847645,-0.049947284264756794,-0.02659006611527251,-0.033675129803344465,-0.04802334535022506,-0.026621217677026625,-0.03761263989067299,-0.026921515597303873,-0.02707623056844215,-0.027300436513828904,-0.040546885580772754,-0.027282489280066876,-0.034345067573009494,-0.04096646166341244,-0.04530865919907248,-0.028363867744543296,-0.026601187956889212,-0.033426642356419116,-0.029259963396389862,-0.03377563477421022,-0.03166978209077137,-0.035023499344714645,-0.035644467775954314,-0.033865543585938386,-0.04671939084068502,-0.04188546044306272,-0.034255252420138174,-0.025656413016758663,-0.02427208969157265,-0.047385047296291664,-0.026085635917363362,-0.043529586468826056,-0.031242648015935678,-0.02567576006363009,-0.03284482492473834,-0.05108700226424894,-0.049890168625415655,-0.03680936324855368,-0.04724485796347975,-0.029089255378222836,-0.029769851401784578,-0.036958126287919654,-0.04124550828277503,-0.029175724896180276,-0.029277005316318983,-0.028576887663060192,-0.04413680828670197,-0.046581061244432585,-0.025930225350391613,-0.0289622703025388,-0.027924680365366564,-0.024982516196862897,-0.04373718484166133,-0.0257766720489593,-0.02434013482345828,-0.02498846313270879,-0.034045872441481474,-0.026435185593542,-0.03355541763906739,-0.049753107592908005,-0.03786100764205172,-0.024986216873251636,-0.05336344432146057,-0.024347720595898757,-0.037196232010790004,-0.02731587191862235,-0.04613485027774145,-0.04177783319446721,-0.033004098675774744,-0.03407901405316165,-0.031101178379542446,-0.034374527883755494,-0.02853082918403317,-0.03601885416290251,-0.04094003004742604,-0.027764265668159524,-0.050751863190171484,-0.040763435658686495,-0.031164513268151024,-0.03222484508162981,-0.0279418779385207,-0.03896667394450769,-0.03499275139594218,-0.03530905466999835,-0.036701471517031216,-0.026577655587429645,-0.03296417970016379,-0.047193428385226624,-0.042444509740296524,-0.03258123277559286,-0.037148615700335744,-0.024075668709032324,-0.04748974111523973,-0.039695758052919174,-0.03128113167251814,-0.0351309670661753,-0.03740085716077436,-0.036950938271829596,-0.025209324290599446,-0.027465768974230302,-0.03338789937228056,-0.05107746169830044,-0.025359142837526924,-0.02798700729924748,-0.02879619218535706,-0.034839648237038855,-0.042161692944476706,-0.03577258974378596,-0.03264499709832757,-0.025801654864002325,-0.027196195847846726,-0.023481480504327374,-0.04719861547964059,-0.03364324398213622,-0.05302644768399256,-0.02894378941407466,-0.04519658699915988,-0.03046954969839764,-0.033788896767948655,-0.03972660967897539,-0.03392403322314978,-0.0519850891411863,-0.038473550484735275,-0.04291974085063323,-0.039741376544958955,-0.03515924591118911,-0.024867605262548678,-0.028692221010038953,-0.04710680355655449,-0.04473475025099012,-0.04026052477750947,-0.03427324160550922,-0.024514277886496443,-0.027046943987198646,-0.030439927870413712,-0.02640075087548091,-0.042874832196471126,-0.02988955279470258,-0.0313127581189275,-0.040604811333793504,-0.04262895083971694,-0.030719980838248666,-0.026492688316789095,-0.05371245759104382,-0.04403416983085504,-0.04192471833241596,-0.04125820535298115,-0.04953988448900098,-0.030489810790162497,-0.027670660786215908,-0.029140888998141896,-0.02903179495500043,-0.03446812236342443,-0.04509320229009223,-0.027810376434635048,-0.03237235069474179,-0.04352170726395478,-0.028703387289417178,-0.02882886230795846,-0.03162490623492521,-0.04356693804316879,-0.03695886283864973,-0.047895644203566026,-0.04441613518580375,-0.03872826472206049,-0.04776695535162575,-0.027796865080095608,-0.02441626415559521,-0.03508981340581463,-0.05136142448641279,-0.04656855957045946,-0.04662693499819472,-0.033786235498183645,-0.0467829620791314,-0.02805172393945135,-0.04781094920796225,-0.029218148779689184,-0.034662780430577245,-0.026183519302418582,-0.05524684820242019,-0.03285251982362462,-0.024761063042361166,-0.03572824783200408,-0.05521794557524695,-0.03283191454441888,-0.030499199080746393,-0.034462678232730325,-0.041163580168222254,-0.025698057916642425,-0.027018722376840613,-0.04151150113105318,-0.05098365499510263,-0.04217641696714335,-0.05092691161723803,-0.02985744179067408,-0.051564788300801224,-0.04096219291003429,-0.027900841422595288,-0.04277647936558836,-0.025884426292114487,-0.025845782813129645,-0.023719344491680384,-0.026238924356634497,-0.03700229297024005,-0.04374607698832866,-0.040146906958434196,-0.043436814628084866,-0.044684747204604136,-0.03502592465439498,-0.042084457315812424,-0.09928680839466146,-0.029707373125584417,-0.054145844469347754,-0.03576596081674205,-0.0379693409107159,-0.0434374929284389,-0.027552850014839814,-0.04386742089539818,-0.037626622954265505,-0.041397030597100724,-0.04930761172871441,-0.02659691046949787,-0.026910065370963875,-0.04211648830529611,-0.04984811011774476,-0.03892839740037334,-0.04870016407547703,-0.04610509089643139,-0.049558385278495855,-0.03086672998778913,-0.02982298925617093,-0.030828865418612558,-0.02765697097937002,-0.03616907054442629,-0.04558260554448222,-0.030854782489610644,-0.02881423719991049,-0.03865608996094605,-0.042337576364463975,-0.028367055275511758,-0.024673096323208722,-0.027239382667191156,-0.0478428094590034,-0.025858247035370735,-0.03099462351304712,-0.043453334255205985,-0.04559241760300857,-0.028364601413462392,-0.033618618210481836,-0.03386712516868481,-0.04494547758848157,-0.03695907913982303,-0.06953242213849112,-0.04262776693507504,-0.03750550266214571,-0.04803589190486099,-0.03557510153451632,-0.042012294347682666,-0.04523543331511918,-0.03276634174651857,-0.030757107592950188,-0.02486989766936629,-0.031299497383028695,-0.040533623209091894,-0.028478988817797708,-0.02440058881051094,-0.045164577236458094;-0.03747525933853735;0.011680624418925367;0.09
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 7301};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'seed': 7301};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    contact_reward = 5 if leg1_contact and leg2_contact else -0.1
    stability_reward = -abs(angular_velocity) * 0.1
    position_penalty = -np.sqrt(vx**2 + vy**2) * 0.1 if y < 3 else 0
    return contact_reward + stability_reward + position_penalty";-0.033229327660581946,-0.028512018922155435,-0.02350821895942884,-0.01971339800115731,-0.010438516836664018,-0.025470427168569405,-0.024762904654990783,-0.026439502247533116,-0.023490672046447572,-0.02509024708946153,-0.026001355929945385,-0.04070992007704089,-0.019628583536969425,-0.03105033759289352,-0.02169346370304765,-0.022520049142384178,-0.021180422876878494,-0.036131893574307926,-0.013483363760137217,-0.007676360914209354,-0.03321628942507447,-0.021842609163434164,-0.025176567262640694,-0.04429214840047341,-0.030209163748112503,-0.015100404334105824,-0.029277195416673875,-0.01603335243358699,-0.0225750331318493,-0.03898835341655174,-0.04290277857393607,-0.02926077896796179,-0.07546574397460583,-0.028583774027085767,-0.0475892950702666,-0.035178165920589394,-0.03435889076430352,-0.06008587187106708,-0.1123362646530919,-0.09218011991511256,-0.024532682623474616,-0.04288802304829658,-0.054998036334428235,-0.027104365448897834,-0.024949139023945976,-0.04223438586682371,-0.02711379468665079,-0.0399984274203308,-0.0319554171288955,-0.028411048629838974,-0.032576562414955636,-0.028031561308663116,-0.04349615532606464,-0.029138713306183686,-0.04495812236745233,-0.014221838621708945,-0.031161834708974216,-0.035741306025677294,-0.02233077494450793,-0.07199891586016632,-0.02778441575736239,-0.06448876436369137,-0.0314571235708999,-0.06383371044565399,-0.09457891211311373,-0.19682974712140167,-0.04491538363398095,-0.02924211052535013,-0.03270149625749805,-0.0446163460543385,-0.05424683021900509,-0.023073644192947763,-0.07841518816932465,-0.03677690726275514,-0.03540573139291022,-0.03948423732065855,-0.032967107887906084,-0.03381827799657734,-0.021711583089870173,-0.023335783260769852,-0.03875060756007503,-0.026855336366584086,-0.022694898952144296,-0.0301977091166881,-0.024141599161962943,-0.041153527925050955,-0.026555020153210183,-0.02471972418246632,-0.04242699729378659,-0.032808586595458204,-0.022274837091388527,-0.03985639250732553,-0.030707715147250812,-0.03040544096438574,-0.026698716666460898,-0.03371342046932171,-0.04957322854090346,-0.0268627669337255,-0.023085197570323488,-0.029680239115159088,-0.02699613655091548,-0.02179913798161615,-0.026693259714535594,-0.03814379258564024,-0.02959768438687678,-0.024979698460080555,-0.03841756194554528,-0.024850745829139147,-0.03798666566283872,-0.024147148825926276,-0.04824073968733773,-0.0284197652998273,-0.025385597270904788,-0.0329181638759755,-0.02179159027367884,-0.02777820248422074,-0.02369121635120028,-0.030672364652564232,-0.03327856646505729,-0.021467872078405253,-0.028706055242078192,-0.029554401924035547,-0.026034109284827398,-0.03470830470784482,-0.03192541283299864,-0.035677016397664824,-0.028897882502881445,-0.024293906473775155,-0.02745754180521875,-0.025508442762914873,-0.026311588864667362,-0.02109543337866962,-0.031174033987963604,-0.030900615504665135,-0.033184111747970924,-0.03598148111341309,-0.02606064594027529,-0.031581154832997546,-0.028789648672655054,-0.03374890117322946,-0.03025213547957937,-0.02326165870782528,-0.021874951646216556,-0.0286683636799947,-0.033875857761394276,-0.02269463717935624,-0.03556668240175594,-0.030044592027432673,-0.028369206928037814,-0.02861172593336072,-0.02992212877422844,-0.03461097002516515,-0.027733568364157947,-0.026998427416558016,-0.03134329178518966,-0.02292406997096993,-0.022006678522930298,-0.023033008687597285,-0.02748925440607355,-0.02781929042189109,-0.035688076793206173,-0.029327108937983678,-0.026097155815522424,-0.035674529758319404,-0.025108167316716924,-0.02980740132130074,-0.030937655626467483,-0.031362049270977486,-0.024743310173454013,-0.027792834056907616,-0.0240540346887265,-0.03142760435311849,-0.033937170102957215,-0.027220120425714544,-0.023081381165642956,-0.03592829812072982,-0.029417144243127684,-0.03515513551454995,-0.026789441606456164,-0.024078824834539273,-0.021177421202099332,-0.028974658702991433,-0.029030750324882944,-0.027598118431546317,-0.022598921536103076,-0.026003422075272484,-0.020292860589644156,-0.029757944032564414,-0.02792550781329894,-0.024462325405446638,-0.02510040878566818,-0.03052066497704616,-0.026915187692563815,-0.021324884928981953,-0.02999663135133591,-0.023238010073295484,-0.019703678428071934,-0.02892141498710698,-0.020398242006115865,-0.02644295012868476,-0.029020613330324713,-0.0206905853480736,-0.029311766950335414,-0.024503458703590844,-0.02657661927862945,-0.009496593953161263,-0.029552850187504625,-0.021437157337225836,-0.026835691986504668,-0.015009936446902787,-0.020152249387073037,-0.02260355332764372,-0.03431365023090054,-0.0201225820604717,-0.030773026841341266,-0.02533666503369614,-0.02999329673997715,0.025047382189591957,-0.019178311358057656,-0.033891454042608085,-0.04802907164611461,0.014664860422099593,-0.0056541325912295775,-0.027451858616919393,-0.03171354572317191,-0.03219844027424421,-0.016684808592917735,-0.032854666995014443,0.33575991263563204,-0.06872499074108315,-0.03987551185609139,-0.03434979866766606,-0.04648296272478438,-0.08200622213517225,-0.013717693259374482,-0.03716676476851881,-0.045564029990911234,-0.02159800117083431,-0.05345402326306697,-0.047473056420215425,-0.08706295731606863,-0.06277011277060605,-0.05113576568566771,-0.14168173587070285,-0.12974290218823684,-0.177170453270144,-0.11319835692307972,-0.14766358065299307,-0.18121729049198804,-0.19577831111698235,-0.17409089911565587,-0.18555736324617952,-0.18995881448251795,-0.1819044141639695,-0.1913682185890901,-0.19206789546899886,-0.12297873893770381,-0.09145330028984158,-0.03282331508471901,-0.05495243208845571,-0.16683115976134374,-0.16704857426104588,-0.1634107735051562,-0.0727042668623439,-0.03470942901691601,-0.059379948213121224,-0.06780752607751932,-0.06285812405663843,-0.04169718939569463,0.0393249433436683,-0.060736221449105406,-0.05078692567138394,-0.04555851879440857,-0.049840623389779286,-0.02986901475210524,-0.024624539412405933,-0.16063160189666006,-0.018043227496557068,-0.05057015718447309,-0.03840620763677317,-0.02779861031099201;-0.04027373929092963;0.044008462649088254;0.01
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 599066};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 599066};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, theta, omega, leg_contact_left, leg_contact_right = observations
    contact_reward = 10 * (leg_contact_left + leg_contact_right)
    movement_penalty = -np.abs(vx) - np.abs(vy) - 5 * np.abs(omega)
    position_reward = -np.abs(y) if y < 0 else 0
    return contact_reward + movement_penalty + position_reward";-0.027786001274878073,-0.030177529789139734,-0.03563464382167816,-0.023921582410967254,-0.023935533217290098,-0.02842668184377012,-0.027330931714165146,-0.03836979144132444,-0.03803336081216823,-0.04767654261067537,-0.03616134018909673,-0.03591504324710804,-0.02578564675306665,-0.017386439554585822,-0.026212542030367582,-0.03358529079106703,-0.02813246979571371,-0.025056933226760947,-0.03914791490737601,-0.012295529623698837,-0.013688676177514365,-0.006619120222449697,-0.005895093221968297,-0.027908971238044675,-0.02940984325131787,-0.028489334532487018,-0.014044097713401413,-0.016477662275950905,-0.023769392524299417,-0.027520387915030795,-0.04050937933493408,-0.017749941826512915,-0.03045894868706113,-0.042582919882019156,-0.05217081598366591,-0.030993463858987855,-0.030880097564654155,-0.0537620985945527,-0.026685467687012042,-0.035587045365161156,-0.033762616843915794,-0.026530410611965403,-0.04374627321513425,-0.03994798471509069,-0.04015853626968261,-0.0447440101254268,-0.07767667428801094,-0.06743192971789785,-0.049085319136957656,-0.1347858528314762,-0.044562176864704275,-0.03879888830253836,-0.03172722852209242,-0.02896118731651004,-0.04845601955344923,-0.03040456389949399,-0.06627569269730813,-0.040368193484553415,-0.09958502839325531,-0.03170058069537744,-0.030992086755726997,-0.013926223757658902,-0.017395738906975378,-0.022753973312258747,-0.013337570384537416,-0.019851277791440112,-0.01739107995578464,-0.03989252069835402,-0.02963578704336646,-0.018056273023339894,-0.02344574813936212,-0.012684941549667815,-0.016540952836635685,-0.025417742595543708,-0.018650682412152283,-0.010683086577921181,-0.023654964483996423,-0.021630291664182108,-0.017422432333463248,-0.018707038942769354,-0.008299342457449777,-0.010624354355707645,-0.02538663930035173,-0.018845464655199665,-0.00695057869899371,-0.02659532103193667,-0.011271230526811194,-0.023554954338367108,-0.01780135918888468,-0.026936467736155417,-0.00963813072262535,-0.009357321742792338,-0.012188265056879841,-0.03362930852971724,-0.010924768917834778,-0.020521228949009564,-0.02292721432704287,-0.024122799743530723,-0.028508775119029012,-0.0161727053787136,-0.023370351736572984,-0.01431281392155689,-0.016930562928817915,-0.011273622844311512,-0.023648012591854,-0.024965934612232846,-0.0163639872732014,-0.009251945946996937,-0.009393079280730968,-0.020532748112146375,-0.018987023395148097,-0.008748412904716242,-0.016114795730150618,-0.007394080648180834,-0.01731410086798197,-0.017545423442283437,-0.016859923073800954,-0.020103021694516623,-0.02185861305334295,-0.026073832165045413,-0.018766370770256384,-0.014597974209470734,-0.020784234856023712,-0.0249493383408227,-0.009063671308556209,-0.025392110497520305,-0.011677391605245077,-0.02106670851673763,-0.018773933116854602,-0.023859267346589694,-0.015001214548960435,-0.0026374804843461307,-0.018591666355004297,-0.004712744122871375,0.590933316408079,0.006301543213740504,-0.002700951270422979,-0.01517112600883105,0.0021535587401640384,-0.012537514284650168,-0.02947905574797371,-0.01868982811614429,-0.015634112566432268,-0.001449104567906125,-0.0040625644782766816,-0.023015142334738517,-0.0219100288229561,-0.04259364669826037,-0.010366790664192676,-0.013535661550925391,-0.006379797019546263,-0.030489783162634506,-0.026542653163870056,0.4401460695544069,-0.0271957309872906,-0.01366771216378545,-0.04066996475627938,-0.08056024293221803,-0.0489657224950221,-0.04516932444790769,-0.009772170341839796,-0.03266366597003605,-0.05244873682113245,-0.07905440646194202,-0.04906603629369297,-0.050683306423642806,-0.07381377064048264,-0.040145272250066553,-0.03428206976264692,-0.05332322160334325,-0.11657278469505108,-0.03403790190266697,-0.05929190387683237,-0.030413815072421146,-0.03588268635226532,-0.055258287640078736,-0.05201356726700422,-0.0446626363963313,-0.03253282740915361,0.4456648985189681,-0.07456669719340137,-0.050328428986802926,-0.2068544636219713;-0.02095837398595352;0.07088883857266845;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 391065};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 391065};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    contact_reward = 1.0 if (leg0_contact and leg1_contact) else 0.0
    stability_reward = -abs(vx) - abs(vy) - abs(angular_velocity)
    landing_penalty = -1.0 if is_failure else 0.0
    return contact_reward + stability_reward + landing_penalty";-0.06643438063466107,-0.07472733242419352,-0.1243015963943638,-0.10332117370840906,-0.11270091724532035,-0.07890459725139673,-0.1534701740227972,-0.1626599603111154,-0.07531013532381148,-0.09888020477807245,-0.09559297739581078,-0.08340274132456206,-0.14593344112090695,-0.10394813178686095,-0.10928801729299936,-0.09800634704031062,-0.080510047894602,-0.10832171354181061,-0.08271533103463655,-0.06313033207293674,-0.11980483377214567,-0.13299308029630488,-0.12125308103809017,-0.0823477499258197,-0.12059772310214749,-0.08311854641812538,-0.14504142344337534,-0.123501756687538,-0.16991460981287732,-0.12858276946748884,-0.1357087752214721,-0.09268102462855964,-0.10264197949898597,-0.1202126135567704,-0.1223495648380832,-0.11490084851895904,-0.08854164820657799,-0.1468898046105934,-0.09702237222246606,-0.09040549471509896,-0.10127315332472497,-0.07867561047467901,-0.07427034911265556,-0.18229405896730663,-0.1373938617454179,-0.09739186519285431,-0.13098989704356184,-0.13923949932868201,-0.10177466972057651,-0.1286700009164461,-0.08254893932202709,-0.13250354021418975,-0.10264604260549347,-0.13997989938768657,-0.12018676630613001,-0.09117456874510041,-0.13440225240850315,-0.08095263841164176,-0.12398082403537566,-0.22584365780166965,-0.08965101573218011,-0.09547287228945962,-0.10827056992719158,-0.09104444498499792,-0.07773911716530969,-0.09484384578527476,-0.10104341424575593,-0.1032703496881556,-0.13826659334865812,-0.06786491965846352,-0.07988459291839071,-0.10895894051879704,-0.0989906243102702,-0.12689723769847502,-0.08744645634804721,-0.06505593350302943,-0.09363169000138087,-0.07561805244464188,-0.11947059529720248;-0.10873015966470202;0.028913322662566205;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 391065};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 391065};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    
    # New goal: Land safely on the ground in the middle of the screen and don't move if you touch the ground
    # Define target position for stationary flight in the middle of the screen
    target_x = 0.0
    target_y = -5.0  # Assuming y=0 is the ground level
    
    # Distance from the target position
    distance_reward = -np.sqrt((x - target_x)**2 + (y - target_y)**2)
    
    # Reward for being stationary when legs are in contact with the ground
    stationarity_reward = -abs(vx) - abs(vy) if (leg0_contact and leg1_contact) else 0.0
    
    # Penalize angular movement to maintain upright position
    angle_reward = -abs(angle)
    
    # Penalize angular velocity to prevent spinning
    angular_velocity_penalty = -abs(angular_velocity)
    
    # Reward for touching the ground safely with both legs
    contact_reward = 1.0 if (leg0_contact and leg1_contact) else 0.0
    
    # Penalty for failing to land safely
    landing_penalty = -1.0 if is_failure else 0.0
    
    # Total reward
    return distance_reward + stationarity_reward + angle_reward + angular_velocity_penalty + contact_reward + landing_penalty

# Explanation of improvements:
# 1. Added a distance_reward term to encourage the lander to move towards the target position in the middle of the screen.
# 2. Modified stationarity_reward to only penalize movement when both legs are in contact with the ground, aligning with the new goal.
# 3. Included angle_reward to maintain an upright position, which is important for a stable landing.
# 4. Added angular_velocity_penalty to prevent spinning, contributing to a more controlled descent and landing.
# These changes ensure that the reward function better aligns with the new goal of landing safely in the middle of the screen without moving once on the ground.";-0.03797176014714462,-0.04625693496813744,-0.03427660737007377,-0.05882860682230987,-0.07388944347564627,-0.031656253874841805,-0.031153973070851798,-0.05849820279621287,-0.03573154887649649,-0.03665022346643146,-0.053110809668698016,-0.04177905915309053,-0.03526984421942562,-0.07906183075760538,-0.05697082571467412,-0.049539427621633006,-0.06082735268216546,-0.06571843653761454,-0.0831733918402001,-0.05048265466167953,-0.0692630043550547,-0.06136349286798078,-0.032626492618677394,-0.08237978022279376,-0.06506991887495682,-0.07531532735913676,-0.062352995778775296,-0.06155775662704845,-0.06622096417444598,-0.10301575340648791,-0.09214438626627068,-0.06447069198680547,-0.04808788235519188,-0.05189068628889375,-0.07371221327377243,-0.04196624666912028,-0.046580457384573566,-0.09774555750636066,-0.06474113725398126,-0.055335524090193884,-0.09071830680247409,-0.03002045164053227,-0.046397689778293776,-0.057543093690331455,-0.05421080251107691,-0.0452380014627275,-0.03492154378648495,-0.04774474848556436,-0.041522605236229,-0.0553018348399562,-0.03319452813708312,-0.05035420874563152,-0.044245755061716206,-0.04655292033243353,-0.03617410051240676,-0.03040831934639024,-0.03237010064675849,-0.04842207820088495,-0.02909815090413121,-0.033792481090006814,-0.04626093357336681,-0.0364210768135916,-0.04544043366859213,-0.03342054731997269,-0.02993025676600927,-0.028508103901378177,-0.032865342216854644,-0.02915999424915713,-0.040761223099004824,-0.03042058882457647,-0.039114973593661985,-0.04418399847906534,-0.02924941816560443,-0.04200881732482574,-0.02701940685968364,-0.03865104235127453,-0.043357561644732465,-0.045754921671606656,-0.04110388460885331,-0.02743974034397942,-0.043164851993527834,-0.025583863471226348,-0.039237448135607284,-0.037670953177900576,-0.04713651125177167,-0.030413337952037885,-0.028316859149428133,-0.03584470717525895,-0.04363150964195362,-0.028910517818523725,-0.03046880041559836,-0.039026898538204145,-0.039477062970830507,-0.043726453444619284,-0.036970840783424705,-0.04340949206290211,-0.04242319849196612,-0.03770297437314509,-0.03821765982944453,-0.029954559700313726,-0.027928547215475264,-0.0390327126037169,-0.03107162433214723,-0.030330938986637797,-0.027310679989338112,-0.04235401021278174,-0.03443283377794079,-0.03517721258079027,-0.025937209576203598,-0.04337324148792542,-0.0327595359542186,-0.03931360230113881,-0.028008842854157973,-0.03428913468915175,-0.026842271705814123,-0.047175706460479465,-0.037001479738430425,-0.02781530546858946,-0.03437555676157062,-0.04422829574154412,-0.03340205892464551,-0.03210382178853245,-0.027994870758067916,-0.03955430282998378,-0.02826030010256172,-0.04197226771754323,-0.03219680280453527,-0.03989896003227992,-0.025179845258977623,-0.033634671653485076,-0.03629643451429752,-0.03699988309767047,-0.0268345796432447,-0.030583796703664734,-0.04183924967289898,-0.03482106889227373,-0.03740359411035024,-0.0266642628126106,-0.030316961998080934,-0.03662118561064334,-0.029396105170673655,-0.02551249177090833,-0.04244408956195951,-0.036844973631392545,-0.04295022089514726,-0.0419727519139355,-0.026771819157969567,-0.028600491232316252,-0.028943112734411983,-0.029874042440775787,-0.030154604145644817,-0.04666567504213988,-0.03718953144559283,-0.04487568237635137,-0.046003006984541336,-0.04163727455758231,-0.027663056991334024,-0.03030900708378683,-0.03414463465620013,-0.03533785345356516,-0.02534867793613293,-0.04157210512423593,-0.04094899341041514,-0.038946809606243984,-0.03721725121558592,-0.03240489484484213,-0.048555996853975256,-0.027028130877650703,-0.029130967874883857,-0.03325530650256045,-0.03071589453054032,-0.044208557478769554,-0.04647091098888593,-0.03493778101579538,-0.049157975478517274,-0.03759717785598728,-0.03695162159559609,-0.03294963642131135,-0.02615696198257936,-0.028455797749648914,-0.0418844167686294,-0.038795671206033576,-0.030892712581541137,-0.03684476578046405,-0.03734069284828831,-0.0344241285407334,-0.028038793786291427,-0.03298885494814723,-0.027371896940791368,-0.033476452512323715,-0.04319908032258784,-0.038429325737842336,-0.04502899855557644,-0.045569004697642086,-0.03157209851385841,-0.03051218598267002,-0.03726837185158843,-0.04674583341556438,-0.03453058392323953,-0.02667825420238024,-0.04622454600931956,-0.03724399391261141,-0.025965810739873914,-0.03883494153778007,-0.027803786984057933,-0.034872375047461095,-0.03011849304542747,-0.04498528191843246,-0.032344600320658674,-0.03366549553584498,-0.03657802304536512,-0.04139265173020798,-0.026762014693945953,-0.044360352850470165,-0.040220267226548166,-0.038057020061420206,-0.043335159591603604,-0.04468616233731653,-0.026320015196587953,-0.043045790736287184,-0.03406813454591898,-0.0393811271416092,-0.028304689493346892,-0.026817183293855056,-0.03835756011503569,-0.03811971426166119,-0.03318996271590105,-0.027689624664305076,-0.033300320787613934,-0.03756604255233302,-0.02638552923320112,-0.03532489476884534,-0.02734139895984934,-0.0255142930667112,-0.052351536381944064,-0.046387715103771765,-0.03735365524181361,-0.04641684220762372,-0.02817287191801745,-0.03251994341128365,-0.045990913398427855,-0.049053709948371306,-0.02699223946497509,-0.04775871647829517,-0.03958708945955115,-0.0423299259401792,-0.04093243170008043,-0.02850786231610195,-0.036929901331389854,-0.03758447851146354,-0.02631562811371204,-0.027833608976017825,-0.028001186143606763,-0.041045585698206745,-0.03138059450062303,-0.04589140212290051,-0.026701919182686436,-0.030219078177963335,-0.03966448765313421,-0.028214554748819152,-0.032235983059655006,-0.032972695248653525,-0.040126057412269524,-0.02851212089281345,-0.041624450455155025,-0.03397383702233622,-0.044678142440015736,-0.033562397450862876,-0.028878683917956043,-0.04518257928310742,-0.04048079151797068,-0.04534305882284385,-0.03104371288793041,-0.046604644280612895,-0.03767064905585106,-0.03936695571695217,-0.04101930462909761,-0.03503466846926581,-0.03301222298728261,-0.0309136423967152,-0.04706012741648791,-0.041376091045713076,-0.03326010814308741,-0.036219364944553384,-0.02611412350377166,-0.029887682598775216,-0.029323667267690347,-0.027951359959628178,-0.02997095554024157,-0.040976281420212604,-0.036342489119288675,-0.026212765458967283,-0.04749850076737982,-0.03909703228659877,-0.025822853135993605,-0.04618136415036176,-0.03996778729476048,-0.03791986811905725,-0.02653223217824284,-0.03892820363389196,-0.03850338348134754,-0.02727136373153225,-0.048293538578315455,-0.026473924824145498,-0.042412478229176126,-0.04635410618468261,-0.027178347600243485,-0.026625255924419455,-0.033640608780320144,-0.028453485269975584,-0.04166755774344941,-0.04336354710440494,-0.03903919247872441,-0.03533206953196079,-0.027936479127284305,-0.032707374209170866,-0.03330632427839391,-0.026541893182513987,-0.035023062630528574,-0.03449367787607698,-0.043544288558685675,-0.04015700364575495,-0.04600943868453296,-0.02570827479874074,-0.037027269864277734,-0.02915051505526535,-0.03948984461927163,-0.036180011401415815,-0.02746662362051483,-0.037780312239456,-0.026302959465471978,-0.026501221514126008,-0.027815971475361103,-0.03789700629241477,-0.04280882181813227,-0.038185142877382144,-0.036733520554588825,-0.025892777770887655,-0.043809731752016974,-0.0370242279335858,-0.029845276116895397,-0.04572796339039868,-0.039470491835534915,-0.04206840646577085,-0.03334404642058398,-0.02992472658193739,-0.031131441959183243,-0.03882268338328717,-0.025882208898380995,-0.031012270739805597,-0.03976667199102956,-0.04748702860346144,-0.02763767542592038,-0.04071187795498831,-0.03681367304916208,-0.03413019521116398,-0.035157272977224485,-0.04558984206886675,-0.04754549669876658,-0.02747355028821677,-0.02524455436643509,-0.02870737466621252,-0.025246749190172814,-0.03281463270588533,-0.04200106584245786,-0.02815824383682163,-0.042461437381234875,-0.039255468077237794,-0.03737285411012283,-0.02765094809653408,-0.0413765408370162,-0.0380837972424456,-0.027026613502744084,-0.04374725889644357,-0.02882657326762213,-0.03706351893995009,-0.04802129872275097,-0.025951096093579932,-0.031622558548475996,-0.033577872047182246,-0.037992957745965554,-0.047978647104610944,-0.039226523651783515,-0.02812238122657157,-0.037580668266206194,-0.027232344059798803,-0.026953604483171946,-0.03366255520275002,-0.04578729993801725,-0.04741315006628069,-0.026701832459766765,-0.031264700287076265,-0.026667555521681718,-0.04955350845674336,-0.0419570742407883,-0.03414612946263084,-0.03616898386014611,-0.03557417250219782,-0.027838842455651155,-0.031535207104640896,-0.026344841979939037,-0.0324378896804364,-0.04223949094022894,-0.03455975135048725,-0.035804089521282716,-0.035133016402988555,-0.047673516496737955,-0.04310434101714359,-0.040601530102218196,-0.029212304977710178,-0.045596426895178316,-0.036919887004213496,-0.038382224697330006,-0.026716596109639563,-0.03044857472109057,-0.04002848177810532,-0.03527328149299977,-0.03934172546291111,-0.03660373469446666,-0.04472943825789421,-0.044104763282562805,-0.045968855238368994,-0.02569812040497437,-0.037065087922490435,-0.04284798593600262,-0.025171317689334966,-0.033117911554527674,-0.028628144796185945,-0.034582071888806264,-0.04086863124996602,-0.0472874368691314,-0.028904847883504857,-0.033915635408650495,-0.0400161544977911,-0.030645192348522535,-0.03832586916130057,-0.04407385125688964,-0.02718113117712377,-0.04645098558925603,-0.03914923841894615,-0.04769960920587506,-0.025191929691443536,-0.03018812701255572,-0.02640493536060817,-0.029254947560568758,-0.03801006855678847,-0.042333213441140494,-0.02912130095230609,-0.03823016584261867,-0.04343105486069688,-0.04796931058136408,-0.03599426179716246,-0.03402038801543129,-0.04855983680913183,-0.03762204220085771,-0.027391464440692258,-0.027654017330347225,-0.04956952284208185,-0.04183679862593999,-0.024985993690238347,-0.026778709724001128,-0.03340723436541859,-0.03566391277186165,-0.026641397908448678,-0.035178057399332587,-0.03837784116543806,-0.044551877341046445,-0.026112353377716988,-0.026190428033746712,-0.042907367304929986,-0.025420502071264364,-0.03769603555318689,-0.04869057188672509,-0.040457215391174535,-0.0329807976471486,-0.0399203315898601,-0.03294248813275418,-0.03327230202477041,-0.029341277899235015,-0.031965497982003356,-0.03078653232138208,-0.03890695817569816,-0.048256559144150814,-0.049063672431181676,-0.02606219142847616,-0.04931232179819262,-0.0286385424323544,-0.037757581365211325,-0.030028182882291515,-0.03137072402775291,-0.04741829776992341,-0.028781445824546066,-0.03632965586321382,-0.034454438240614164,-0.027746155816219618,-0.036145877923083235,-0.03495168943090621,-0.03670505503850624,-0.03877037975670206,-0.043468687991555385,-0.036445496890911755,-0.04526457939409669,-0.032645930468207934,-0.030079600498920223,-0.02620737348708267,-0.04057814233539408,-0.04259598526868502,-0.03834586550169915,-0.04560798073172806,-0.027295244887851587,-0.04503155798645733,-0.03042783855290911,-0.037821649835704865,-0.04763157322098959,-0.027703656061827467,-0.02829203777146376,-0.03933116077267447,-0.03457360863142888,-0.035577273971054355,-0.04284110641747675,-0.04401765492330828,-0.03451004984550146,-0.028675613600271644,-0.02654047685282906,-0.043387146115320005,-0.029210091254846648,-0.043971603750934965,-0.02864531439552129,-0.02722665305560837,-0.03415770780096999,-0.029155753308999353,-0.043074950627557805,-0.04036352011447344,-0.04657062036986354,-0.027248784997223094,-0.03666083305688766,-0.038922334015207734,-0.028846433486968446,-0.026119224176604436,-0.027193075424633544,-0.03411344447011582,-0.03483774742998112,-0.04497004973595224,-0.028174772838648422,-0.03038640799979093,-0.028150635301286305,-0.04035017879150294,-0.03230561209486107,-0.032911346674061044,-0.03765349539648821,-0.04279115512049622,-0.046979961349264805,-0.02903678220729622,-0.025220929196604756,-0.03254573566772134,-0.03662057922094705,-0.0265827637060044,-0.02962123475316748,-0.04063518123856124,-0.042447224291699254,-0.04828462833096674,-0.026574190052480864,-0.02678161024662022,-0.04328065423658972,-0.025626599563329525,-0.027796794465331,-0.03292305517569045,-0.025398931895314013,-0.025673486913517497,-0.047907381302526045,-0.04677735297513978,-0.028264760493528968,-0.027214432304813307,-0.04545514563192044,-0.034710916659265095,-0.047541901643137936,-0.029179915545427766,-0.044050247511329264,-0.03553411681116285,-0.02891667980155498,-0.031074310651522056,-0.03453454551932485,-0.035053168227741696,-0.041342057310574734,-0.04739679766672344,-0.042783674025830117,-0.044854497758349626,-0.03834238115785967,-0.048524229909183134,-0.029256428084152825,-0.02767699827277428,-0.03928476018347831,-0.027170691876076715,-0.037312361717221375,-0.026710357977729794,-0.029600808940985178,-0.02924786729308234,-0.0266732096745496,-0.037335081070495824,-0.03947035097983736,-0.03610603974954424,-0.04543467282838357,-0.04201785726200018,-0.025968957898057553,-0.03446993213061311,-0.0258071360863797,-0.030906006479147916,-0.041158990671989124,-0.0420253757998195,-0.02876121160767674,-0.02612623425297434,-0.04693387853367876,-0.03454071697164669,-0.02921430686465209,-0.032526442856158376,-0.045371416112826045,-0.03249943217820913,-0.03509918826982219,-0.04395250415235545,-0.03135273166543125,-0.025050425939312126,-0.043671113016541314,-0.028304221158016358,-0.026116880763915173,-0.03643142741895011,-0.038913553142041736,-0.04129343558090408,-0.028390150748413688,-0.03660988807622562,-0.03623927018248539,-0.04434588290642723,-0.026730458440869506,-0.029990502760078443,-0.030746438713729365,-0.02590230371940173,-0.040677364284638466,-0.03825818622313268,-0.030684817818121605,-0.03930695308365122,-0.0428872568201244,-0.04439179010612817,-0.03599200297680248,-0.02666535750205842,-0.04039744029703543,-0.026792541950778063,-0.028368969365752894,-0.037938356198741405,-0.04117753493613079,-0.031883816157544105,-0.03611233734070785,-0.03715068289183146,-0.026878603282680755,-0.03440204544487598,-0.03205656695095875,-0.027353175916558652,-0.038470537944901614,-0.03841272567688073,-0.031054230389535607,-0.025696794270282333,-0.028593347678404376,-0.040020752075105796,-0.027171888202576884,-0.03454463264167263,-0.026736874437620895,-0.03790094354453218,-0.04228041543867573,-0.02770154740863413,-0.037162867028036235,-0.027624862883918695,-0.03345760925533161,-0.027512995959660724,-0.0325627126459039,-0.028210986246659544,-0.030231193227802163,-0.04806815285151111,-0.03202895118534067,-0.02913990120362838,-0.0282451785924153;-0.0370942149636095;0.009947133754044196;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 391065};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 391065};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    
    # New goal: Land safely on the ground in the middle of the screen and don't move if you touch the ground
    # Define target position for stationary flight in the middle of the screen
    target_x = 0.0
    target_y = -5.0  # Assuming y=0 is the ground level
    
    # Distance from the target position
    distance_reward = -np.sqrt((x - target_x)**2 + (y - target_y)**2)
    
    # Reward for being stationary when legs are in contact with the ground
    stationarity_reward = -abs(vx) - abs(vy) if (leg0_contact or leg1_contact) else 0.0
    
    # Penalize angular movement to maintain upright position
    angle_reward = -abs(angle)
    
    # Penalize angular velocity to prevent spinning
    angular_velocity_penalty = -abs(angular_velocity)
    
    # Reward for touching the ground safely with both legs
    contact_reward = 1.0 if (leg0_contact and leg1_contact) else 0.0
    
    # Penalty for crashing (not terminated, but in a bad state)
    crash_penalty = -2.0 if (leg0_contact or leg1_contact) and (abs(vx) > 1.0 or abs(vy) > 1.0 or abs(angle) > 0.2) else 0.0
    
    # Total reward
    return distance_reward + stationarity_reward + angle_reward + angular_velocity_penalty + contact_reward + crash_penalty

# Explanation of improvements:
# 1. Added a distance_reward term to encourage the lander to move towards the target position in the middle of the screen.
# 2. Modified stationarity_reward to penalize movement when either leg is in contact with the ground, ensuring the lander stops once it touches down.
# 3. Included angle_reward to maintain an upright position, which is important for a stable landing.
# 4. Added angular_velocity_penalty to prevent spinning, contributing to a more controlled descent and landing.
# 5. Added crash_penalty to penalize situations where the lander crashes (not terminated but in a bad state) by checking if either leg is in contact with the ground and if there are excessive velocities or angles.
# These changes ensure that the reward function better aligns with the new goal of landing safely in the middle of the screen without moving once on the ground, even if the lander does not get terminated upon crashing.";-0.03587368887822295,-0.042298887754685086,-0.05229202478345455,-0.06922315883572137,-0.042709650211814755,-0.05156739288935379,-0.05851431192321831,-0.06384654404046933,-0.041303946717504716,-0.056555922806519034,-0.05762897377456386,-0.05431420955145978,-0.06287048351240136,-0.04193773373545235,-0.039190235353950054,-0.035106098865340114,-0.06419910482751338,-0.08324464479363407,-0.08571396499649846,-0.06215567935881321,-0.05781976867918458,-0.04286278188358174,-0.05052037304508334,-0.09695142653822658,-0.06265750339178935,-0.1122163816886821,-0.0821444778508028,-0.03401402661380382,-0.10074390048313711,-0.0473301460041492,-0.07916793692258217,-0.06891652716119716,-0.030863585716990573,-0.06931667838852144,-0.3440837323387401,-0.05300483550457344,-0.04826447458715541,-0.05777823362085502,-0.05371200223685045,-0.05677567121013094,-0.06635885200844699,-0.044796725681060835,-0.049344176386089005,-0.044830129218651926,-0.04669091521062225,-0.05055275319936384,-0.0496709356165102,-0.03953316035225103,-0.04523624453111783,-0.04780902966218242,-0.033764359980835136,-0.04403550392676083,-0.04562260224538691,-0.05609700110896935,-0.05414508041231711,-0.04280426064724792,-0.034870723628325336,-0.04348314280558244,-0.031526446683573385,-0.04607164959444338,-0.03173385782677584,-0.051342305367926076,-0.04018992952782537,-0.0308196497079425,-0.04410758578246795,-0.03646147952193757,-0.03148940298958653,-0.032510018005466365,-0.043370751882489685,-0.04416242769342466,-0.029349244795625788,-0.0336357514910324,-0.0360515053793975,-0.04415152829835567,-0.03185148350236312,-0.036481468716103894,-0.04006723231906387,-0.039196860376811915,-0.03185692139254253,-0.03060437523180527,-0.03403676856669284,-0.03830911623281047,-0.026351290662349074,-0.023521202409164263,-0.04205586595753943,-0.039788533337367406,-0.03195616908443653,-0.028025437298971716,-0.028595435318674155,-0.03134875593255827,-0.028450260195803163,-0.03467122743411148,-0.025385573377336837,-0.02740030752150613,-0.039737347319854024,-0.026491897618236372,-0.02679428127690955,-0.030871098704132325,-0.027950544378872053,-0.04375639380784252,-0.030340434859082395,-0.044813600584796096,-0.03417829338907818,-0.024192492712342792,-0.025151039752508292,-0.033505452977575303,-0.027772258946579708,-0.027433084629560258,-0.029203290570095485,-0.04067429940211672,-0.03340152361455662,-0.032455129212364466,-0.028366817434630872,-0.04318763537764776,-0.024947804008095334,-0.03321145356456131,-0.026527374406748225,-0.025854932009122075,-0.029142937585291,-0.03137875728861928,-0.040575413095709986,-0.027203485090057253,-0.023679369314713514,-0.044218286535685235,-0.02773715429080711,-0.027371974840816597,-0.04017405199831977,-0.031189063867662535,-0.042233210895616095,-0.027478396158920622,-0.0412709500218902,-0.030740493784327447,-0.0425058003935491,-0.04122008192563746,-0.04606983089620728,-0.03280148698896397,-0.04303797517794203,-0.03785189691459941,-0.03412027935723917,-0.037174321479542284,-0.029151866760492827,-0.04025078492838313,-0.03007008780817856,-0.02459081156975667,-0.030429686765846658,-0.025646442558302472,-0.04264950047436098,-0.03752680105903424,-0.035032816936381814,-0.04049877246772585,-0.042520231686555374,-0.024088965768111936,-0.03458255587895512,-0.0376799041811284,-0.03516822825392301,-0.03969430647647579,-0.04186982941701854,-0.024291522571329785,-0.025393856894924995,-0.02797058193567237,-0.025747954776614096,-0.045202602561720075,-0.037138670980345075,-0.04078217962312422,-0.032381781392515935,-0.027755870301164443,-0.03753639846473446,-0.030284247860083085,-0.03469176539612474,-0.04025454324971796,-0.033469802149380584,-0.04409427118012168,-0.042929262191125785,-0.02867500762519358,-0.030676882371627173,-0.02854588860436565,-0.046379260767665874,-0.04196906588644191,-0.032912645304607316,-0.0359696718181579,-0.02646864553643023,-0.025050574276330485,-0.02859811679460298,-0.030273345833034013,-0.02654635621053848,-0.03830249131961444,-0.04263519961058984,-0.04071231224965791,-0.044357703324801934,-0.04433379056116249,-0.03579710385081803,-0.031043543443627003,-0.0339304398979432,-0.04281677297088805,-0.037140669128445325,-0.031868149456124165,-0.035920305705204825,-0.03230508754004571,-0.024984123523729432,-0.024552498859262615,-0.02644490598997988,-0.024485512919100748,-0.02718234042008,-0.028710650502615138,-0.04126128041951414,-0.03859104008465669,-0.02975487057807423,-0.02350858986922701,-0.02867222240538322,-0.024020177268869604,-0.03460653756757294,-0.042902046895646556,-0.045750374313853016,-0.02550292951257511,-0.04047182260012676,-0.03652584631292115,-0.03639341143585426,-0.03728436257447408,-0.028263005377502197,-0.0458317138304982,-0.030381354692067982,-0.0435701045789562,-0.03541920276166037,-0.038174313304776095,-0.033048177272846535,-0.02887249355323223,-0.041511982078649756,-0.03848368834331632,-0.032233291729396034,-0.02855739757698803,-0.035617890426215396,-0.02771728715471705,-0.02802929007914723,-0.044084267023833085,-0.03018727251743641,-0.02921372231348144,-0.028853093118387952,-0.02683217170082169,-0.024461805614406393,-0.030597577302474185,-0.026143696815862653,-0.03133065543998715,-0.03047181727311431,-0.030606831344439644,-0.034450646374356665,-0.026760014212242514,-0.03663717424505861,-0.025941347189688,-0.038269596284230566,-0.03208450077766739,-0.03261196559714975,-0.04289509704257634,-0.03929707864791612,-0.037449919458651566,-0.026337011146860816,-0.02465906078724695,-0.042148541814502366,-0.04170103735410265,-0.04038352010706622,-0.028485777122011252,-0.030264579255712756,-0.030838715332987286,-0.03724473573825866,-0.02928125493783934,-0.042479826954004846,-0.03357907761227335,-0.04388733529210028,-0.03483141054606876,-0.03629185403521791,-0.035768119060508106,-0.02698910022318746,-0.04474849830160094,-0.04073791585944549,-0.041975860854795405,-0.032887335489596305,-0.033736027227035045,-0.024670016879553523,-0.0250194855652208,-0.0301029314468403,-0.040766229476557066,-0.03023889993994257,-0.031141450616888253,-0.039889351224711496,-0.03285984347065576,-0.0423440813567157,-0.026124198924644813,-0.027865768062847653,-0.023973586249914632,-0.02852372044141197,-0.02851354425598084,-0.04506516443673997,-0.02920643567662667,-0.028881285902025114,-0.03473840346172366,-0.028727201709355693,-0.032537203325616895,-0.029222561270254927,-0.03025640816388487,-0.030176622429369554,-0.03771197134911091,-0.0387977018080863,-0.03225396465349901,-0.027539815077380347,-0.03809810256687189,-0.03327415975889005,-0.03384696471223852,-0.024504990375917676,-0.044041928663249574,-0.04234336704828825,-0.02414255617254004,-0.03696692974719293,-0.03308037496145238,-0.025047993272585733,-0.04708343036918071,-0.031756997281767674,-0.03263404279229188,-0.0331913844605553,-0.024522487340834072,-0.04076785459631373,-0.03641420649114406,-0.040437028006229836,-0.02713051629361805,-0.025631750224049538,-0.04017967677736258,-0.028622123048368222,-0.03175348753632941,-0.027427158360854673,-0.025105023071817844,-0.02507833693227841,-0.044510288933812626,-0.03324598145114334,-0.03669627872086736,-0.044832905244809644,-0.03654414212034746,-0.03782849751501928,-0.04278176758097533,-0.028891424910737595,-0.03205329649704344,-0.032088993001059156,-0.040319165159993016,-0.03906568683964366,-0.027163454281454644,-0.043485815398578494,-0.025310806847113985,-0.03260128860439762,-0.04232135236267305,-0.02479271869428017,-0.03991929663291814,-0.02484992430612618,-0.030322479161971016,-0.04555034269446903,-0.028320948784542353,-0.027850853344555494,-0.04311766616117443,-0.04502853239174887,-0.027600122331530922,-0.025678716117389682,-0.033915785800512,-0.03250825430464738,-0.04551284626335294,-0.026605961055004887,-0.02768879099882025,-0.029575548255295733,-0.030693909162546287,-0.025528413897320534,-0.04168068452629941,-0.027788681734625467,-0.03873955720079105,-0.03577757759270376,-0.03276686771418468,-0.036481081412923895,-0.03494033284841201,-0.040077678282453316,-0.02592913337645541,-0.037342827917786446,-0.03334976298461413,-0.02483343639485105,-0.036078075254872374,-0.029208034421749598,-0.0423958550551704,-0.03218883418618382,-0.0469278216203269,-0.036832881630835035,-0.04356042728169393,-0.02671684946474643,-0.02390695438418424,-0.024001456908434082,-0.031032406914463753,-0.03003570764147859,-0.037558726611866274,-0.026375192733569437,-0.03813617896576546,-0.025017579499868114,-0.026668406939192542,-0.04687250633678601,-0.025680860047942206,-0.033166562037077935,-0.03295646086401139,-0.04135411558438255,-0.025313646004238372,-0.042778647752419505,-0.024603975637464408,-0.03273168252713266,-0.03145780489894294,-0.037717949014538635,-0.04431198634256559,-0.04458893918825459,-0.02625018691272394,-0.02736060837894903,-0.037548783795335675,-0.028608799380312785,-0.030388044819881575,-0.0337294156930711,-0.028007653265450076,-0.029072379865382563,-0.03169211780299745,-0.029439328371540428,-0.02728089063725248,-0.03224038871746384,-0.03673305303900396,-0.027649281724381785,-0.038321066756646746,-0.030224673612385122,-0.03853168761783585,-0.023491263946460613,-0.03932851563944558,-0.029327847199673792,-0.024118515575090264,-0.028507047286260984,-0.0236908271465007,-0.03316036153067,-0.029712979069220057,-0.03500376013217244,-0.031917714722236715,-0.03976481972688744,-0.03514865893369019,-0.0315430353960301,-0.030100294495241178,-0.03067942683837066,-0.0360748256367988,-0.02832340522617424,-0.02907969337036733,-0.03897288110177478,-0.03500261470906322,-0.029343194165861366,-0.032326273974429116,-0.025367152185303877,-0.041276961354729795,-0.03853819807645362,-0.033084045038343925,-0.024023149505486844,-0.027362033157499646,-0.03495553271615727,-0.03018854690756961,-0.026261481689689573,-0.025257495597073246,-0.03996305043217851,-0.026927082510981623,-0.04228852093347447,-0.04007703637175574,-0.03503226968557896,-0.02746397256080056,-0.03703620702706951,-0.040004306829616976,-0.03336879198126945,-0.029983780867793474,-0.037482583793670275,-0.026232299848148705,-0.028680524712384737,-0.03462031967538113,-0.03751930125007053,-0.02789872993955901,-0.02914537574928343,-0.025008111426744663,-0.034291543818166195,-0.025499182468543834,-0.032049260830807565,-0.04216814600847126,-0.0328000986925817,-0.03664821510905696,-0.04330277255262356,-0.042672233727093625,-0.03116524079239989,-0.0320346498320502,-0.031138862064478405,-0.03552968836878365,-0.03607116044003699,-0.0267114570127787,-0.031049518330853534,-0.03463649260809557,-0.03772042347792302,-0.026945577069459346,-0.03016045117819794,-0.024342176874033845,-0.028594288214022105,-0.0262471057596532,-0.036739736714810824,-0.026708597933027312,-0.03905984066355416,-0.024185391045199282,-0.032877321646158794,-0.04315410526740346,-0.026217660646993657,-0.024290597905549875,-0.027207912299885485,-0.03155679385257284,-0.04426231418881752,-0.024046811481635354,-0.037325085374506364,-0.023896914184390643,-0.029742196570435496,-0.04257963598876171,-0.03048545257492242,-0.02996459643809225,-0.04164607298296161,-0.03587177517281697,-0.033689388558274025,-0.028416374622026785,-0.04593826157503433,-0.04407894183357854,-0.03572163595273647,-0.03929123492103031,-0.026710845644016646,-0.026733564164971888,-0.030553090588149402,-0.02805270753703514,-0.03065482177258167,-0.026792986653429475,-0.040037762549868704,-0.03839203098953425,-0.032356900370926485,-0.029994490961350654,-0.02676513228028678,-0.02354985734291499,-0.02341204350277829,-0.026235166257233513,-0.03667727681167371,-0.027499166703895912,-0.0412226287319188,-0.02684753219246246,-0.04138802290854988,-0.027455491516762832,-0.030008715260090125,-0.03138541133637259,-0.032361624519285266,-0.03126814247686271,-0.02449693929507044,-0.047525811058912654,-0.027644173416596987,-0.033665885469645274,-0.03847660407648557,-0.03264463311247773,-0.0273900887126198,-0.04243242576040349,-0.02664828289260233,-0.03422655831080951,-0.04185337672675464,-0.04072011460838748,-0.027263651094610136,-0.037916813058314375,-0.030442695985392954,-0.03511940498686168,-0.032867746849898585,-0.03723017291935888,-0.04106843944282253,-0.030790810955971804,-0.03018264659311205,-0.03283704540541362,-0.033051165941061646,-0.04082700271912549,-0.025021293004430997,-0.03895664971716936,-0.032891541978650504,-0.03284904584548324,-0.025393355009223264,-0.038672118962163285,-0.04171696708454654,-0.03827450620651674,-0.02726213741362122,-0.026427500888479373,-0.03196076912762342,-0.04325177293047732,-0.04484992891025241,-0.030259853224757112,-0.040996415015458566,-0.02967476736096162,-0.03214373878990998,-0.024368282150191475,-0.02898886143478294,-0.03403835720428115,-0.042181396054194985,-0.030988040850837,-0.03876514224049694,-0.02960023599084797,-0.040850613773770486,-0.040562357706846436,-0.03240594677141025,-0.031012209976647404,-0.04171337008165752,-0.042400260770494635,-0.029183678790906217,-0.023592732408103386,-0.04146819693323773,-0.03462644199004748,-0.03388646614556966,-0.0281989892795868,-0.04011393638521885,-0.029716470427353033,-0.026597039666077467,-0.0244873258050475,-0.03998700061014591,-0.028674382676145416,-0.0351168984644977,-0.0372638473498443,-0.027701164997285005,-0.04244693447749049,-0.034412585127626204,-0.0316448784761711,-0.03427535792660538,-0.028336827739703835,-0.0298516804349733,-0.04176540271943035,-0.039894210846933904,-0.04595042713529876,-0.026868977822050936,-0.03783526148449626,-0.04015149574624759,-0.04011848676805936,-0.04468358237721765,-0.034605504332614674,-0.02588175046049351,-0.028341093155867633,-0.025434385677814492,-0.039393544592751246,-0.028988141222677944,-0.03723022563207106,-0.02479983310093838,-0.041985096582566134,-0.037424994058953526,-0.03685215573063542,-0.024968687618548282,-0.03351478279863394,-0.03552106104879739,-0.03399520232671037,-0.045278823352325984,-0.028606738832351444,-0.03753077650044812,-0.04092505863581661,-0.040459702697405675,-0.03497477515908612,-0.028160996336394968,-0.02482796408787655,-0.02851489413276498;-0.03587172045334314;0.015640116363512663;0.0
;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'seed': 982835};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 982835};50000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    altitude_reward = max(0, 5 - abs(y))  # Reward for maintaining a safe altitude
    horizontal_stability_reward = -abs(vx)  # Penalize horizontal movement
    vertical_stability_reward = -abs(vy)  # Penalize vertical movement
    angle_reward = -abs(angle)  # Penalize tilting
    angular_velocity_reward = -abs(angular_velocity)  # Penalize spinning
    no_contact_penalty = -10 * (leg0_contact + leg1_contact)  # Penalize contact with ground

    reward = altitude_reward + horizontal_stability_reward + vertical_stability_reward + angle_reward + angular_velocity_reward + no_contact_penalty
    return reward";0.003784478612233492,0.004325414283816432,0.010308874318651948,0.0071441139966313865,0.003422612406882261,0.009642757288335156,0.010907253063539893,0.010022605578863445,0.007192884410185355,0.006111668434752207,0.006729516514689435,0.003936889796872718,0.009119067771711235,0.01188598831758733,0.008016831249930937,0.006651363190727039,0.0031550155432283856,0.008054511061436278,0.0096370900259137,0.00809799767754888,0.008506188945863491,0.007555257616523964,0.01252225478607152,0.004807109053239518,0.010341591548030533,0.00773921497486366,0.015340980584857633,0.004532377307429255,0.012368611105819402,0.005377208629867023,0.00761716651692134,0.01441979820032451,0.005227810202113914,0.034822958547433766,0.03439802733648788,0.027073755986884357,0.045644180668082714,0.04749700056435074,0.01512532471508052,0.09619491480248078,0.055126913400787986,0.05036000716251746,0.020083916940772613,0.01249858378246626,0.004608328625270027,0.13740823980696987,0.13803605796073665,0.13795075542629767,0.025623833422697976,0.14447638509814828,0.13936585482159206,0.14237898180701572,0.12051017863822922,0.14650354260274276,0.13991704434841626,0.15169007736943058,0.15269782468324639,0.14455870840156224,0.15325466520322628,0.15609057088427636,0.09587320410696884,0.13853740022007296,0.13538260119100723,0.10706309897263795,0.1372003058470149,0.15712458971979296,0.038828258603193465,0.15860631325133448,0.15778274893679978,0.08781091468875123,0.1673001408501705,0.16533953688534678,0.1689208191304708,0.13518248028343952,0.022680264122490346,0.15756566120788515,0.12445917758505581,0.15394923400628713,0.09203792107619425,0.168046216588107,0.14861294192956773,0.11652173047864792,0.16881035363840277,0.1738053900542462,0.17261479885872932,0.17379201351018933,0.17084577576624177,0.16874909404449748,0.17125852589184212,0.14637798089848622,0.1709601005901473,0.01891130968408398,0.017201246314319366,0.16832816328128197,0.017028626592114966;0.07696745341924721;0.0678404518235963;0.0
data/model/LunarLander-v3_580150_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 580150};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 580150};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    if is_failure:
        return -1.0
    if leg0_contact or leg1_contact:
        return -0.5
    reward = 1.0 - (np.abs(vx) + np.abs(vy) + np.abs(angle) + np.abs(angular_velocity))
    return reward";-0.050878625,-0.03961942,-0.025812803,-0.025570234,-0.02122629,-0.027977867,-0.01476391,-0.020366529,0.017477674,-0.0076314392,0.013703661,-0.0006759866,0.03542515,-0.005568757,0.12183831,0.15959896,0.10981641,0.22660753,0.2453727,0.26037422,0.00011891763,0.2683726,0.28722957,0.2884434,0.078541785,0.08319545,0.2821042,-0.01334144,-0.007773227,-0.020614294,-0.007982591,-0.010233901,-0.01158625,0.016168749,-0.016841834,-0.011633977,-0.017204864,-0.009013281,-0.0022199398,-0.0120168105,0.0012171847,-0.0121022845,-0.0011635029,0.005351866,-0.006413379,-0.013884404,-0.0024542103,-0.025721718,-0.010402015,-0.016574722,-0.0028721173,-0.019918451,0.002932068,0.004817684,-0.01754394,-0.011063697,-0.00914544,-0.013490129,-0.0005562435,-0.012754652,0.016355196,-0.006578305,0.24830799,0.2743584,-0.023999223,-0.0055827526,0.074264295,0.007457664,0.0058017666,0.05159303,0.1036233,0.032747183,0.061470192,0.29290995,0.07121707,0.019001914,0.030319592,0.27657682,0.20963721,0.22241019;0.048924807;0.100530416;0.0
data/model/LunarLander-v3_609116_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 609116};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 609116};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    position_penalty = abs(vx) + abs(vy)
    angle_penalty = abs(angle)
    angular_velocity_penalty = abs(angular_velocity)
    contact_penalty = 10 * (leg0_contact or leg1_contact)
    reward = -position_penalty - angle_penalty - angular_velocity_penalty - contact_penalty
    if is_failure:
        reward -= 20
    return reward";-0.12005948,-0.09230402,-0.1335866,-0.14721051,-0.13955095,-0.15175574,-0.12177614,-0.15127394,-0.10546012,-0.1303346,-0.21739659,-0.12505268,-0.14659563,-0.19599032,-0.4717454,-0.109612316,-0.10895393,-0.096118316,-0.09520665,-0.13588394,-0.09761093,-0.08812622,-0.16850136,-0.14738888,-0.117566876,-0.10925085,-0.12169029,-0.13994142,-0.14285725,-0.12384187,-0.125751,-0.103371575,-0.1073907,-0.14543813,-0.10779703,-0.10880036,-0.08460072,-0.12611836,-0.08460626,-0.09970236,-0.10271057,-0.13928904,-0.111791894,-0.11283682,-0.12027449,-0.111105196,-0.102154076,-0.114874914,-0.099602886,-0.12019726,-0.08440727;-0.1287346;0.05509306;0.0
data/model/LunarLander-v3_32885_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 32885};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 32885};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_vel, y_vel = observations[3], observations[4]
    angular_velocity = observations[5]
    leg_contact_1, leg_contact_2 = observations[6], observations[7]

    if is_failure:
        return -10.0

    reward = 0.0
    reward -= abs(x_vel) * 0.1
    reward -= abs(y_vel) * 0.1
    reward -= abs(angular_velocity) * 0.2
    reward -= (leg_contact_1 + leg_contact_2) * 5.0

    return reward";-0.08726188,-0.124176204,-0.067264505,-0.080536656,-0.08349154,-0.116658345,-0.0825867,-0.06042244,-0.09736171,-0.08628009,-0.082984075,-0.085715845,-0.090001285,-0.11068832,-0.08326136,-0.096696936,-0.109976426,-0.08752883,-0.09787848,-0.21035258,-0.10277676,-0.1433077,-0.08796174,-0.048457228,-0.05709273,-0.05687466,-0.06656035,-0.041507505,-0.046170793,-0.053498283,-0.05254135,-0.06291205,-0.048040785,-0.050616298,-0.04326751,-0.047427073,-0.039921083,-0.0663848,-0.043396406,-0.039776225,-0.043959063,-0.038952187,-0.041452337,-0.052790247,-0.29371235,-0.03941894,-0.15316576,-0.062580295,-0.03714668,-0.043327734,-0.061701197,-0.04621319,-0.041336697,-0.040698096,-0.042927336,-0.044642024,-0.042709265,-0.06259403,-0.08301225,-0.04411635,-0.045957427,-0.040858492,-0.104371116,-0.08890933,-0.13281575,-0.24936979,-0.19556154,-0.12818879,-0.34550425,-0.22902577,-0.17009753,-0.2606327,-0.22331843,-0.1232765,-0.16289875,-0.09011181,-0.10648819,-0.0766806,-0.08075618,-0.07846559;-0.09236701;0.06299473;0.0
data/model/LunarLander-v3_546059_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 546059};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 546059};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_pos, y_pos, x_vel, y_vel, angle, ang_vel, leg1_contact, leg2_contact = observations
    position_reward = -abs(x_vel) - abs(y_vel)
    orientation_reward = -abs(angle) - abs(ang_vel)
    contact_penalty = -10 if (leg1_contact or leg2_contact) else 0
    return position_reward + orientation_reward + contact_penalty";-0.062472668,-0.110993296,-0.055317465,-0.06699372,-0.04889675,-0.06230317,-0.05667163,-0.079380736,-0.053359043,-0.08903052,-0.084200464,-0.05065241,-0.08074422,-0.0536007,-0.08717237,-0.79360694,-0.13895306,-0.09912417,-0.042954795,-0.072216116,-0.11322513,-0.045404114,-0.06740492,-0.12177368,-0.06844467,-0.06350942,-0.07058608,-0.06280021,-0.083660595,-0.065993086,-0.05501227,-0.08652446,-0.032445543,-0.06128046,-0.08417787,-0.051720276,-0.05061331,-0.06444119,-0.042607125,-0.0660616,-0.056685124,-0.07234696,-0.04438577,-0.10374746,-0.06188184,-0.087055326,-0.058436703,-0.054542143,-0.053262554,-0.073094584,-0.061843883,-0.09662496,-0.11755907,-0.118033655,-0.0698591,-0.057869937,-0.07880667,-0.07384152,-0.073557414,-0.059149936,-0.10610221,-0.04834391,-0.122895874,-0.04953526,-0.049671903,-0.045606263,-0.056720424;-0.082056575;0.090510175;0.05
data/model/LunarLander-v3_248479_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 248479};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 248479};50000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_pos, y_pos, x_vel, y_vel, angle, ang_vel, leg1_contact, leg2_contact = observations
    
    hover_height = 1.0  # Desired hover height above ground
    hover_reward = -abs(y_pos - hover_height) * 5.0  # Reward for being close to desired height
    
    velocity_penalty = -(abs(x_vel) + abs(y_vel)) * 0.5  # Penalize horizontal and vertical movement
    angle_penalty = -abs(angle) * 2.0  # Penalize non-upright orientation
    angular_velocity_penalty = -abs(ang_vel) * 1.0  # Penalize rotation
    
    contact_penalty = -20.0 if leg1_contact or leg2_contact else 0.0  # Penalize ground contact
    
    failure_penalty = -50.0 if is_failure else 0.0  # Heavy penalty for crashing
    success_reward = 50.0 if is_success else 0.0  # Reward for successful landing (though not desired here)
    
    reward = hover_reward + velocity_penalty + angle_penalty + angular_velocity_penalty + contact_penalty + failure_penalty
    
    return reward";-0.07404625,-0.16925105,-0.07444504,-0.06686292,-0.12678763,-0.10839042,-0.07312193,-0.11928256,-0.07895245,-0.20881411,-0.09859006,-0.078606024,-0.10266791,-0.08032353,-0.12734708,-0.10975998,-0.11207292,-0.105986826,-0.09835105,-0.16019659,-0.15417238,-0.17893337,-0.17866084,-0.2687491,-0.43188566,-0.1405644,-0.13131155,-0.09212856,-0.07706866,-0.2438401,-0.11309988,-0.21734247,-0.07279483,-0.09549323,-0.13972326,-0.11944447,-0.099895425,-0.09943971,-0.089985125,-0.05984648,-0.08209387,-0.058647446,-0.08772725,-0.15213414,-0.10579038,-0.099026635,-0.1172036,-0.068428524,-0.08580144,-0.09375521,-0.07499825,-0.058543876,-0.0647212,-0.05396028,-0.077468924,-0.05036702,-0.045425277,-0.067317545,-0.09027639,-0.072014615;-0.11306562;0.06231236;0.0
data/model/LunarLander-v3_422849_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 422849};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 422849};50;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x_vel = observations[3]
    y_vel = observations[4]
    ang_vel = observations[5]
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    if is_failure:
        return -10.0
    elif leg_contact_1 or leg_contact_2:
        return -5.0
    else:
        reward = -abs(x_vel) - abs(y_vel) - abs(ang_vel)
        return max(reward, -3.0)";;nan;0;0.0
data/model/LunarLander-v3_141546_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 141546};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 141546};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_v, c1, c2 = observations
    hover_bonus = 0.5 * (1 - np.abs(vx)) + 0.5 * (1 - np.abs(vy))
    angle_penalty = 1 - np.abs(angle) / 6.2831855
    angular_v_penalty = 1 - np.abs(angular_v) / 10.
    ground_contact_penalty = -10 * (c1 + c2)
    reward = hover_bonus + angle_penalty + angular_v_penalty + ground_contact_penalty
    if is_failure:
        return -100
    return reward";;nan;0;0.0
data/model/LunarLander-v3_508057_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 508057};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 508057};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, angular_velocity, left_leg_contact, right_leg_contact = observations
    if is_failure:
        return -10.0
    if left_leg_contact or right_leg_contact:
        return -5.0
    position_penalty = abs(vx) + abs(vy)
    angle_penalty = abs(theta) + abs(angular_velocity)
    height_reward = y / 10.0  # Encourage higher altitude to avoid ground contact
    reward = height_reward - position_penalty - angle_penalty
    return reward";;nan;0;0.0
data/model/LunarLander-v3_270043_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 270043};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 270043};50;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]
    leg_contact = observations[6] + observations[7]

    if is_failure:
        return -10.0
    elif leg_contact > 0:
        return -5.0
    else:
        reward = 1.0
        reward -= abs(x_velocity) * 0.1
        reward -= abs(y_velocity) * 0.2
        reward -= abs(angle) * 0.1
        reward -= abs(angular_velocity) * 0.1
        return reward";;nan;0;0.0
data/model/LunarLander-v3_584414_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 584414};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 584414};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 10.0
    elif is_failure:
        return -5.0
    else:
        return np.cos(observations[3]) * 2.0";;nan;0;0.0
data/model/LunarLander-v3_74143_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 74143};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 74143};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.sum(np.abs(observations[:2]))";;nan;0;0.0
data/model/LunarLander-v3_119847_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 119847};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 119847};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return 0.1 * np.exp(-np.linalg.norm(observations[:2]))";;nan;0;0.0
data/model/LunarLander-v3_30767_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 30767};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 30767};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        reward = np.clip(-observations[3] * 20 + observations[6] * 10, -10, 10)
        return reward";;nan;0;0.0
data/model/LunarLander-v3_729714_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 729714};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 729714};50;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -20.0
    else:
        return -0.5 * np.abs(observations[7])  # Penalize high angular velocity";;nan;0;0.0
data/model/LunarLander-v3_153150_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 153150};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 153150};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    else:
        return -0.1 * np.sum(np.abs(observations[:4]))";;nan;0;0.0
data/model/LunarLander-v3_163294_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 163294};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 163294};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -20.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";;nan;0;0.0
data/model/LunarLander-v3_893679_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 893679};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 893679};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -150.0
    else:
        position_x = observations[0]
        position_y = observations[1]
        distance_from_landing_pad = np.abs(position_x) + np.abs(position_y)
        reward = -distance_from_landing_pad * 0.1
        return reward";;nan;0;0.0
data/model/LunarLander-v3_357644_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 357644};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 357644};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return np.clip(-abs(observations[7]) + 0.2 * observations[6], -1, 0)";;nan;0;0.0
data/model/LunarLander-v3_715022_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 715022};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 715022};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";;nan;0;0.0
data/model/LunarLander-v3_757037_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 757037};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 757037};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";;nan;0;0.0
data/model/LunarLander-v3_599959_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 599959};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 599959};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -10.0
    else:
        return np.clip(-np.linalg.norm(observations[:2]), -5, 0)";;nan;0;0.0
data/model/LunarLander-v3_579266_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 579266};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 579266};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -1.0 * np.sum(np.abs(observations[:2])) / 100.0";;nan;0;0.0
data/model/LunarLander-v3_248692_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 248692};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 248692};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 10.0
    elif is_failure:
        return -5.0
    else:
        return np.sin(observations[3]) * 2 - 1";;nan;0;0.0
data/model/LunarLander-v3_145084_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 145084};PPO;{'policy': 'MlpPolicy', 'seed': 145084};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";-0.20843919,-0.20968875,-0.21250671,-0.22355202,-0.2117728,-0.20622817,-0.2142152,-0.20930512,-0.20896791,-0.2251088,-0.21604836,-0.22489755,-0.21644035,-0.20778768,-0.20889293,-0.20889893,-0.22118095,-0.2159421,-0.21380898,-0.21021196,-0.20636109,-0.20842196;-0.21312171;0.0058035324;0.0
data/model/LunarLander-v3_259675_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 259675};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 259675};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    else:
        return -0.5 * (observations[3] ** 2 + observations[4] ** 2) - 0.1 * abs(observations[0])";;nan;0;0.0
data/model/LunarLander-v3_555195_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 555195};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 555195};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";;nan;0;0.0
data/model/LunarLander-v3_311888_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 311888};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 311888};50;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return np.clip(10 * (observations[3] ** 2), -10, 10)";;nan;0;0.0
data/model/LunarLander-v3_801822_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 801822};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 801822};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -150.0
    else:
        reward = 0.0
        pos_x, pos_y, vel_x, vel_y = observations[0], observations[1], observations[3], observations[4]
        if abs(vel_x) < 0.2 and abs(vel_y) < 0.2:
            reward += 5.0
        if pos_y > 0.7:
            reward += (pos_y - 0.7) * 10.0
        return reward";0.2480448,-0.0022410657,0.0014942904,0.86482465,0.04175115,0.4345131;0.26473114;0.31077978;0.0
data/model/LunarLander-v3_727272_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 727272};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 727272};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    reward = 0.0
    if is_success:
        reward += 1000.0
    elif is_failure:
        reward -= 500.0
    else:
        reward -= np.linalg.norm(observations[:2]) * 0.1
    return reward";-0.40688026876738337,-0.40702273683021656,-0.4127347608656521,-0.40695860583731613,-0.4097253613134317,-0.4061290154565676;-0.40824179151176127;0.0023035472502926794;0.0
data/model/LunarLander-v3_839553_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 839553};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 839553};500;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        altitude = observations[1]
        velocity_y = observations[5]
        reward = 0.1 * altitude - 0.05 * abs(velocity_y)
        return reward";-0.37910262066132744,-0.37381401191817903,-0.39885251418221246,-0.4323346584713205,-0.42863880827220996,-0.43222271407151114;-0.40749422126279344;0.024801739940903154;0.0
data/model/LunarLander-v3_934282_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 934282};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 934282};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return np.clip(-0.01 * (abs(observations[0]) + abs(observations[1])), -2.0, 0.0)";-0.4979505971967805,-0.48885286839983255,-0.504007564701703,-0.5089640955235293;-0.49994378145546137;0.0074976919124419466;0.0
data/model/LunarLander-v3_88055_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 88055};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 88055};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return 1.0 - np.abs(observations[2]) * 0.1";0.22707736824662228,0.8919458959444635,0.1064637252175204,0.20944015972959582,0.31251989095618504;0.3494894080188774;0.27902894775025516;0.0
data/model/LunarLander-v3_669177_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 669177};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 669177};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.abs(observations[3]) + 0.1 * observations[7]";-0.4500265067976048,-0.43391815863318217,-0.4480837083505816,-0.4526252912407413,-0.4511568583408202;-0.44716210467258605;0.00678617305874365;0.0
data/model/LunarLander-v3_466082_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 466082};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 466082};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return np.clip(-observations[2], -1, 0) * 10  # Penalize based on vertical speed";-0.9259394487037569,-0.07054020041574421,-0.07054020041574421,-0.07054020041574421,-0.3422274332483971,-0.07054020041574421,-0.07491890127079663;-0.23217808355513253;0.2982456711736296;0.0
data/model/LunarLander-v3_492783_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 492783};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 492783};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -20.0
    else:
        return -0.5 * np.sum(np.square(observations[:4]))";-0.5074583445554082,-0.3279467703489059,-0.510637637194545,-0.6117075672567559;-0.4894375798389037;0.10222942551651482;0.0
data/model/LunarLander-v3_99343_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 99343};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 99343};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";-0.3681029011535331,-0.4002844200457502,-0.36974226823012474,-0.39141774225978415,-0.37511816551651866,-0.36699460028872805,-0.37276905533818655;-0.3777755932618036;0.01194755175068062;0.0
data/model/LunarLander-v3_163225_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 163225};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 163225};500;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -150.0
    else:
        position = observations[0]
        velocity = abs(observations[3])
        reward = -velocity * 0.1 - abs(position) * 0.05
        return reward";-0.447894114114506,-0.4433869469688524,-0.4477502823568704,-0.45241733897889114,-0.444563959222769;-0.4472025283283777;0.0031462130739110133;0.0
data/model/LunarLander-v3_734389_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 734389};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 734389};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 200.0
    elif is_failure:
        return -150.0
    else:
        return -0.1 * np.sum(np.abs(observations[:4]))";-0.4499909126214436,-0.45365044620716705,-0.4696477393770181,-0.429984006173758,-0.43157178608776176;-0.4469689780934297;0.01478961196634936;0.0
data/model/LunarLander-v3_696079_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 696079};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 696079};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 10.0
    elif is_failure:
        return -5.0
    else:
        return -0.1 * np.linalg.norm(observations[:2])";-0.41190440956500707,-0.5556603597998991,-0.5711216244771844,-0.2736117504850444,-0.3471786600282355;-0.4318953608710741;0.11604480711365174;0.0
data/model/LunarLander-v3_683587_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 683587};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 683587};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3""""""
    if is_success:
        return 100.0
    elif is_failure:
        return -20.0
    else:
        return -0.1 * np.abs(observations[7])  # penalize high angular velocity";-0.4472135954999579,-0.4472135954999579,-0.4472135954999579,-0.4472135954999579,-0.4472135954999579;-0.447213595499958;5.551115123125783e-17;0.0
data/model/LunarLander-v3_398005_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 398005};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 398005};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 10.0
    elif is_failure:
        return -5.0
    else:
        return 0.1 * (observations[7] ** 2)  # Reward based on vertical velocity squared";-0.504063768145119,-0.44105579614896673,-0.5250664254771698,-0.5250664254771698;-0.4988131038121063;0.03443090857547588;0.0
data/model/LunarLander-v3_276473_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 276473};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 276473};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 50.0
    elif is_failure:
        return -20.0
    else:
        return -0.05 * np.sum(np.abs(observations[:4]))";-0.40196360987525587,-0.46806462551082384,-0.3699148980909356,-0.4140516790785288,-0.3898041390043325,-0.3988955641758632;-0.4071157526226233;0.030388001467383026;0.0
data/model/LunarLander-v3_224812_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 224812};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 224812};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 10.0
    elif is_failure:
        return -2.0
    else:
        return np.clip(observations[7], -1, 0) * 5";-0.4082482904638631,-0.4082482904638631,-0.4082482904638631,-0.4082482904638631,-0.4082482904638631,-0.4082482904638631;-0.4082482904638631;0.0;0.0
data/model/LunarLander-v3_263623_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 263623};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 263623};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        altitude_reward = observations[2] * 10
        velocity_reward = -abs(observations[3]) * 5
        angle_reward = -abs(observations[4]) * 2
        angular_velocity_reward = -abs(observations[5]) * 3
        return altitude_reward + velocity_reward + angle_reward + angular_velocity_reward";0.14404453474768575,-0.6430121241923538,0.38830138072305165,0.5136695781823815,0.3887829501527372;0.15835726392270044;0.4182379429976627;0.0
data/model/LunarLander-v3_5033_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 5033};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 5033};500;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * abs(observations[7])  # Penalize based on angular velocity";-0.37860955001736446,-0.3801179546214944,-0.37785534771529955,-0.3771011454132346,-0.3771011454132346,-0.37785534771529955,-0.3771011454132346;-0.3779630909013088;0.0010221416104575234;0.0
data/model/LunarLander-v3_404270_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 404270};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 404270};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -20.0
    else:
        return -0.5 * np.linalg.norm(observations[:2])";-0.4915425368556327,-0.532390194854615,-0.38559591764983076,-0.3616782436451201,-0.44209868949111386;-0.44266111649926254;0.06364853446566077;0.0
data/model/LunarLander-v3_393411_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 393411};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 393411};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        return -0.1 * np.sum(np.abs(observations[:4]))";-0.4759059882926075,-0.4577280025434964,-0.4141148974682837,-0.6265041242399052;-0.4935632531360732;0.07997071435054572;0.0
data/model/LunarLander-v3_133198_1.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 133198};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 133198};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    if is_success:
        return 150.0
    elif is_failure:
        return -200.0
    else:
        return -0.2 * np.sum(np.abs(observations[:4]))  # penalize based on position and velocity";-0.43545289668730697,-0.4528756991227786,-0.4229847875154936,-0.4287032874543097,-0.4925258742107144;-0.44650850899812067;0.025102816421175497;0.0
data/model/LunarLander-v3_133198_2.pth;LunarLander-v3;qwen2.5-coder:32b;{'temperature': 0.9, 'seed': 133198};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 133198};500;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    # If the goal is to maintain stationary flight without crashing or landing,
    # we need a reward function that encourages stability and penalizes movement towards the ground.

    if is_success:
        return 150.0  # This should be rare as success is defined as not crashing or landing, but keep it for completeness
    elif is_failure:
        return -200.0  # Severe penalty for crashing or landing

    # Penalize vertical velocity to encourage stationary flight
    vertical_velocity = observations[5]  # Assuming the 6th element is vertical velocity
    vertical_position = observations[1]   # Assuming the 2nd element is vertical position

    # Reward for being at a safe height above the ground
    height_reward = np.clip(0.1 * (1 - vertical_position), 0, None) if vertical_position < 1 else 0

    # Penalize significant vertical movement
    velocity_penalty = -0.5 * abs(vertical_velocity)

    # Encourage stability by penalizing angular velocity and horizontal velocity
    angular_velocity = np.linalg.norm(observations[6:])  # Assuming the last elements are angular velocities
    horizontal_velocity = np.linalg.norm(observations[3:5])  # Assuming the 4th and 5th elements are horizontal velocities

    stability_penalty = -0.1 * (angular_velocity + horizontal_velocity)

    return height_reward + velocity_penalty + stability_penalty";-0.4457741330134729,-0.44022383882688176,-0.4844394963602113,-0.6105790435569133;-0.49525412793936985;0.06872662336397965;0.0
data/model/LunarLander-v3_507564_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 507564};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 507564};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    reward = 0.0

    if is_success:
        return 100.0

    if is_failure:
        return -100.0

    if leg1_contact == 1 and leg2_contact == 1:
        reward += 1.0
        reward -= 0.5 * (abs(omega) > 0.1)
        reward -= 0.5 * (abs(vx) > 0.1 or abs(vy) > 0.1)
    else:
        reward += 0.5 * leg1_contact
        reward += 0.5 * leg2_contact

    return reward";-0.04408239151689252,-0.04430391107225379,-0.04363935240616998,-0.043860871961531246,-0.043860871961531246,-0.043860871961531246,-0.04297479374008617,-0.04408239151689252,-0.043860871961531246,-0.04408239151689252,-0.04408239151689252,-0.043860871961531246,-0.043860871961531246,-0.04363935240616998,-0.042531754629363636,-0.043860871961531246,-0.040538078631112216,-0.043860871961531246,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04297479374008617,-0.04408239151689252,-0.04408239151689252,-0.04430391107225379,-0.04408239151689252,-0.04408239151689252,-0.04408239151689252,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04408239151689252,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.043196313295447444,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04363935240616998,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04408239151689252,-0.043860871961531246,-0.043860871961531246,-0.04430391107225379,-0.04363935240616998,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04363935240616998,-0.04408239151689252,-0.04408239151689252,-0.04430391107225379,-0.043860871961531246,-0.04341783285080871,-0.03987351996502841,-0.043196313295447444,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.043860871961531246,-0.04363935240616998,-0.04408239151689252,-0.043860871961531246,-0.04430391107225379,-0.04408239151689252,-0.04408239151689252,-0.04341783285080871,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.043860871961531246,-0.043860871961531246,-0.04341783285080871,-0.04408239151689252,-0.043860871961531246,-0.04363935240616998,-0.04408239151689252,-0.04408239151689252,-0.043860871961531246,-0.043860871961531246,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04363935240616998,-0.043860871961531246,-0.04430391107225379,-0.04297479374008617,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04408239151689252,-0.04430391107225379,-0.043860871961531246,-0.04341783285080871,-0.043860871961531246,-0.043196313295447444,-0.04363935240616998,-0.04430391107225379,-0.043196313295447444,-0.04341783285080871,-0.04430391107225379,-0.04341783285080871,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043196313295447444,-0.04408239151689252,-0.04430391107225379,-0.04408239151689252,-0.04408239151689252,-0.04341783285080871,-0.04430391107225379,-0.042531754629363636,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04408239151689252,-0.0392089612989446,-0.04430391107225379,-0.04408239151689252,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04186719596327983,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04297479374008617,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04341783285080871,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043196313295447444,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04363935240616998,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04408239151689252,-0.04430391107225379,-0.04363935240616998,-0.04408239151689252,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.043860871961531246,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379,-0.04430391107225379;-0.04414889056470078;0.00043954601294734396;0.0
data/model/LunarLander-v3_185450_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 185450};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 185450};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    if is_success:
        return 100.0
    
    if is_failure:
        return -100.0
    
    reward = 0.0
    
    # Distance from the landing pad (assuming center of the environment)
    distance_from_landing_pad = np.sqrt(x**2 + y**2)
    reward -= distance_from_landing_pad
    
    # Penalize for high velocities
    velocity_penalty = abs(vx) + abs(vy)
    reward -= velocity_penalty
    
    # Penalize for angle not being close to vertical (0 radians is perpendicular)
    angle_penalty = abs(theta)
    reward -= angle_penalty
    
    # Reward for leg contact
    if leg1_contact or leg2_contact:
        reward += 5.0
    if leg1_contact and leg2_contact:
        reward += 10.0
    
    return reward";-0.0363792024419745,-0.04186204244224933,-0.052720292060707476,-0.06706204330015748,-0.04270224637308788,-0.048709029832412744,-0.04399535732983756,-0.03936682123958031,-0.04975915857931744,-0.032422619981357544,-0.05112298393339543,-0.05381063289305544,-0.05236874957437645,-0.039607024245312476,-0.04628523173838189,-0.04043375216042947,-0.05178341563151475,-0.07076243431582135,-0.06636118102291776,-0.21818488788906953,-0.10757578729680319,-0.05726722342450057,-0.2702611871378598,-0.27056562403467954,-0.24197868991668925,-0.21634085226781896,-0.22505046920908872,-0.24271685788323843,-0.1783458509205746,-0.16097829845717151,-0.1256418022601403,-0.18283049914460014,-0.17741667690740057,-0.0632244075552917,-0.09246117193496937,-0.09236487364933747,-0.08130151536116252,-0.036488093314692896,-0.09547158022879938,-0.09075164160461514,-0.1610636804568153,-0.07315069988671019,-0.08239654528940016,-0.07593702494846728,-0.052150941320913344,-0.08810806679449089,-0.03384610404280502,-0.03929307708163491,-0.1068394489266312,-0.03391893564601237,-0.08599703931802816,-0.03397699731799957,-0.03243249166336545,-0.09787629162723832,-0.033082177724145546,-0.03715185987409468,-0.028868142680707882,-0.03452031848499709,-0.030593794696606315,-0.04797352712443296,-0.03489764904377588,-0.03750890600542009,-0.05150377658853813,-0.03501743695445159,-0.03410030607674663,-0.06364466673449273,-0.04945577844675504,-0.033368334365653084,-0.03055207807344152,-0.035572492857820666,-0.03526540467609275,-0.033705859927842675,-0.041770485080090694,-0.031282535270240525,-0.03552996585380481,-0.09558903312511867,-0.0332637671432141,-0.03842411270011594,-0.0432122578969875,-0.04229186688514246,-0.014724108247077058,-0.042146712326242314,-0.04081583723256636,-0.037496208953629526,-0.041160277152472065,-0.15611780801650707,-0.04806584092128385,-0.03485803707866872,-0.032885842642738625,-0.04153517944513716,-0.03637750241455627,-0.03495297796044271,-0.048459917439099706,-0.036062719481573594,-0.03606402318041134,-0.03348017004067813,-0.0334019828516019,-0.03781727632130158,-0.038637824697037984,-0.04765859036222159,-0.039358146156405226,-0.0352843793245698,-0.041139765348504526,-0.04165650051529161,-0.040828664981500284,-0.035435835077294864,-0.046898661123225015,-0.044840786752248236,-0.04154384372874598,-0.0506718666901495,-0.03727509720413147,-0.034640499417209064,-0.03895941245912125,-0.033497366412247986,-0.031132890942373682,-0.06671425117421136,-0.0462606996020968,-0.060588764096489396,-0.03560982334134968,-0.05466048230063256,-0.04154947259359173,-0.03682191999959742,-0.030956894716856226,-0.03429066589765016,-0.042658506458932564,-0.042428082460461355,-0.03308421169413302,-0.045890788896522164,-0.03814355231806508,-0.0387530634239083,-0.05489190373033736,-0.05858275278233031,-0.07241625552276885,-0.07898558509570973,-0.03555553752154656,-0.19870935672532505,-0.0332835558240702,-0.042443379537974675,-0.03886999675257743,-0.04113222372028672,-0.03734627125476977,-0.033320085003895564,-0.045764263537771806,-0.039619832978742144,-0.03601349187202258,-0.040076412890637694,-0.0596365893162699,-0.033445207263015565,-0.03499868391238552,-0.04096816868026579,-0.10813369937541628,-0.039682322834609575,-0.03287346286050271,-0.04995780525879634,-0.025712644186158564,-0.033056692039553456,-0.03667616709822039,-0.03868604763689014;-0.06161391275437498;0.05032732537247434;0.1
data/model/LunarLander-v3_12864_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 12864};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 12864};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    reward = 0.0
    
    if leg1_contact and leg2_contact:
        reward += 1.0
    
    if abs(x) < 0.5 and abs(y) < 0.5 and abs(vx) < 1.0 and abs(vy) < 1.0:
        reward += 10.0
    
    if y > 0:
        reward -= y
    
    if omega != 0:
        reward -= 0.1 * abs(omega)
    
    if is_success:
        reward += 50.0
    
    if is_failure:
        reward -= 20.0
    
    return reward";-0.024910894724491567,-0.007142488746183969,-0.012373140173151644,-0.021572793186719067,-0.03212129137204855,-0.027677125540583943,-0.03148117763172224,-0.022603372022527872,-0.02092698226303569,0.01413609148901918,-0.032357936070144,0.04259580752891941,-0.012583830682446806,-0.03200139907021511,-0.01332207816346125,-0.029161605728645554,-0.0315008746825428,-0.021600733754758145,-0.02827630577355614,-0.014542989828672895,-0.030257303095996554,-0.015785474175793103,0.027382977066295458,-0.012134244079585708,-0.014300316939592873,-0.013273620107117846,-0.05051693212092674,-0.013256937126688711,-0.02586950322394325,-0.02424370912074506,-0.01453115381676165,-0.023645379860319615,-0.01690363148130647,-0.01920838056085145,-0.017017935537465684,0.013373585434759173,-0.01857381135808275,-0.02312547996117565,-0.012122747398864289,-0.01359602078096441,-0.021048612357604257,-0.01564334321175072,-0.017014163008181853,-0.029222163983722127,-0.012040854551414215,-0.012494049164403926,-0.027929244868527655,-0.026843472453910316,-0.012422574296892724,-0.029530263607057846,-0.01518590588906739,-0.024191444497689688,-0.0351039788651326,-0.012855060639162473,0.012663424207431481,-0.02342126677210241,-0.01831586349363647,-0.022007739138703616,-0.009106283534329618,0.0543444173301992,-0.009157667058716993,-0.02600394633974547,-0.017417379540185317,-0.019652877859530384,-0.011622759677915801,-0.013337168356929656,-0.011161459833932056,-0.012430034102201257,-0.016141208829177574,-0.022620110834801865,-0.0011957822855159202,-0.014895801530231524,-0.0018359084231482283,-0.012355677074980925,-0.02038105253857874,-0.019409639135254637,-0.014597636393529066,-0.013572255679895014,0.03739899606190922,-0.01718405461261485,-0.012181631953714456,-0.01316497323903998,-0.004032451952165434,-0.016616730196411623,-0.018717337890265133,-0.017448573182570263,-0.013410818949201427,-0.02338050688809878,-0.012517635347406146,-0.01272413391425463,-0.0025291776835152835,-0.014798420581671674,0.0010165630674528361,-0.014668334573808962,-0.010576367964311608,-0.013414336970570338,-0.012606910660966428,-0.01172657273737467,-0.018727611431329925,-0.013912062128620882,-0.019886216295612907,-0.01459580373282392,-0.013369080679106563,-0.016552937403510156,-0.019790592563401304,-0.015739750065563177,-0.012899936838005605,-0.022994016038469317,-0.021802293600958617,-0.020511049554998852,-0.013167004613269284,-0.026002578050401143,-0.022611920098140656,-0.01996025492698224,-0.02048182002854732,-0.025638906680552905,-0.017047882777943085,-0.014286816725452829,-0.022869036750333062,0.0005610120609108021,-0.012500566674714473,-0.014115879901146397,-0.01206453836773029,-0.01564702191811526,-0.012906969646968934,0.004165857919248492,-0.02049368578784052,-0.021245967130185846,-0.019306179828517588,-0.011526807793671679,-0.021601716263649783,-0.014075189599526425,-0.024258288612338606,-0.019669452436811757,-0.017211393996195243,-0.017286313466496558,-0.027496393809663504,-0.017012083720799372,0.04796190288382804,0.011173594440156117,-0.023260971002706236,0.06571121173068022,0.04832058753178671,-0.020450513219219917,-0.02902782392028716,-0.016921465296589364,-0.025751303073771267,-0.020958831002405275,-0.014836528977401876,-0.02266377534669798,-0.01540600487599804,-0.01813932075265016,-0.017319524828242797,-0.024375122976687653,-0.021560882858068592,-0.013513310533272831,-0.01629886699314979,-0.01537744812048835,0.07169171129338103,-0.01966535668193045,-0.012778968659408156,-0.022666054036230756,-0.01713176211170181,-0.0006888264578805364,0.06645916473105362,-0.012719971653518021,-0.01756211840641566,-0.01594495285882938,-0.015968638572276875,-0.015295645496700304,-0.01640554938082924,-0.01625784243651509,-0.022829397549490375,-0.018012087974667326,-0.013113477446812027,-0.020344662875926664,0.020452260687325283,-0.014181904352430727,-0.014241137395666582,-0.023157922406601427,-0.022918881073172984,-0.017406530602010965,-0.016167004778083374,-0.024744614786236265,-0.020073661184831657,-0.016960654497528732,-0.012857096291300994,-0.016497249027383233,-0.02517283095193201,-0.02214830367308803,-0.01738714126916342,-0.015410586738236642,-0.013260091814415028,-0.021227177022174214,-0.017773735153180856,-0.02577720567403158,-0.015492778196614697,-0.015226896832278758,-0.014820148504755219,-0.023341931866026875,-0.013866672592579727,-0.021862061276590895,-0.008853882348838212,-0.0142159525885132,-0.02254341007860276,-0.014931333549029428,-0.023045958768193858,-0.016768711201940976,-0.01720285285651121,-0.019902679276377674,-0.01746570842650924,-0.016901268408711645,-0.02276384301195895,-0.018466169867879426,-0.011227896177688218,-0.017279976927053197,-0.017048597139929074,-0.02627500067664446,-0.020374700812313396,-0.017664177543960127,0.005192366351307015,-0.02035917448359842,-0.01950047819210833,-0.003828157855536945,-0.01714312464894753,-0.019006187222166366,-0.016344923054967497,-0.018296143768431465,-0.02668984267813055,-0.020845368773479468,-0.02557365676736753,0.004257394941743135,-0.026280334485240853,-0.018108508827355523,-0.019346621599407938,-0.023182378918030634,-0.027537041112352046,-0.0176508683748215,0.022490154534139946,-0.02690688993376134,-0.025102182110096516,-0.018549497058230204,0.01962272193785379,-0.019576929425858473,-0.016959241663864377,-0.028498819838909076,-0.02480761299047665,-0.024565132074531933,-0.014040775137286608,-0.021262786958927835,-0.022274921943335062,-0.028437651768850748,-0.022170288706739108,-0.02158440316038341,-0.02151140952599493,-0.012471010354857422,-0.019058874870516697,-0.02460247380892256,-0.021687103495269772,-0.02679923785137663,-0.022419422238877513,-0.022584680102873348,0.00037806041102415096,-0.02341009514327279,-0.021096312416514156,-0.019263574438682093,-0.026279205136748956,-0.0190186734865326,-0.02489342541321545,0.014346993353817459,-0.025592295857204468,-0.02285567275776042,-0.021760016883441896,0.023146503204971417,-0.023822858253494176,-0.021176633886294406,-0.024256952595398104,0.03508773550867701,0.039033597645758256,0.11329128321103957,-0.02388885006271903,-0.019752097210671244,0.3702237827895764,0.25411477088825724,-0.02790888073337597,0.06618663360450326,0.21157957255076457,-0.020702683187545003,0.1793900286695274,0.03796230258358082,0.10891732687834263,-0.019373046529615245,-0.028786517620181275,0.08545850642888712,0.10176658313525952,-0.021188079988515136,0.09723532636103933,0.08434254650800128,-0.027983688002602702,0.1312518339480783,-0.027544116243325072,0.07274762814639679,0.14074220880541097,0.14010464434112824,-0.037883026379473855,0.18222758000724124,0.1830194913505632,0.10748900934519155,0.12772362472416998,0.1889340821348862,0.168283798951893,0.17278566889092892,0.12584642560804377,0.10788676943207992,0.036506076591136374,0.20036733178814975,0.05702218614503117,-0.03038119995198588,0.19137369441497465,0.008393831153600706,0.16816419609450448,0.13463714295743756,-0.030993918919211674,0.18078655039978925,0.15472457551043106,0.23297232508838545,-0.03286179304435966;0.0015638644637465148;0.05527800922133683;0.14
data/model/LunarLander-v3_358758_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 358758};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 358758};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    reward_distance = -abs(x)
    reward_height = -y if y > 0 else 0
    reward_velocity = -(np.abs(vx) + np.abs(vy))
    reward_contact = 2 * (leg1_contact and leg2_contact)
    reward_angle = -np.abs(theta)
    return reward_distance + reward_height + reward_velocity + reward_contact + reward_angle if not is_success and not is_failure else (100 if is_success else -100)";-0.03639299454106099,-0.04375312166613293,-0.03880903852267179,-0.05924454504065856,-0.048450751240957525,-0.04319599973610962,-0.03665869170885498,-0.03473932735091721,-0.06247215582207933,-0.054865027686089106,-0.044496252158161276,-0.038184161368855433,-0.063726728197588,-0.03480645357998595,-0.04847859718084694,-0.03704849878720531,-0.036583217641794986,-0.05777693859854005,-0.06469233445593216,-0.09640658106713816,-0.06671516322020968,-0.04565642974704052,-0.0526924526310366,-0.2575958692827592,-0.22411337004034962,-0.2218981283775793,-0.2055530963872896,-0.21786858431080372,-0.21036992727181886,-0.20365022935560842,-0.25393681113144917,-0.231590715334284,-0.19795476366065884,-0.29175766511910833,-0.1695122995980609,-0.21303327335311067,-0.1901336159926428,-0.15679066891163795,-0.1424899389736437,-0.16365930148220767,-0.12544218786759584,-0.16310397376318483,-0.12023870650287577,-0.11605584890695653,-0.12814318516185227,-0.13296572873964568,-0.08322820326138984,-0.12783726360066294,-0.08328926811437055,-0.09333931035143492,-0.08160407315630097,-0.06403256767812618,-0.06022816040362656,-0.04329391320146152,-0.06383799947537573,-0.05301119851992148,-0.07810977172376021;-0.11079851019230565;0.07257788773647485;0.0
data/model/LunarLander-v3_717003_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 717003};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 717003};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_v, left_contact, right_contact = observations
    reward = 0.0

    if is_success:
        reward += 100.0
    elif is_failure:
        reward -= 100.0
    else:
        # Penalize height and vertical speed
        reward -= abs(y) + abs(vy)
        
        # Reward horizontal movement
        reward += abs(vx)
        
        # Encourage both legs to touch the ground simultaneously
        if left_contact and right_contact:
            reward += 20.0

    return reward";-0.13317391057832584,-0.09638189302409207,-0.08830733760445418,-0.06740857633322675,-0.07884389550487826,-0.06267406553747416,-0.10747111370236537,-0.06743840682110182,-0.07260842873366699,-0.10118982923184508,-0.062192703581328675,-0.07710898547033547,-0.06711010286725101,-0.06998871438582577,-0.09259849629945513,-0.10420562875283192,-0.06929079629090992,-0.09882065437760389,-0.06936832519295667,-0.09606102998031041,-0.05433454800194193,-0.06347926280025847,-0.10185969519721905,-0.06993313165645522,-0.04999345368205773,-0.07491851356813174,-0.074484139773509,-0.06197120987511258,-0.07325166144617329,-0.049706631142990565,-0.048765718918543186,-0.0782093098709948,-0.05589586925885573,-0.060225856093935645,-0.07125854810860482,-0.039590812077898864,-0.06140739020949582,-0.03815181506617579,-0.052812141177485006,-0.05478680934037357,-0.052561906063776746,-0.04232154651748141,-0.04316188432155866,-0.062066252379105236,-0.04640673831072652,-0.05477418257177875,-0.060016109280043535,-0.04951700627054168,-0.06142685384151444,-0.05679890497764052,-0.054101189673652066,-0.056334695019636,-0.053859084871343825,-0.05912111005406545,-0.048399152154432655,-0.03854581745174423,-0.05590051068823246,-0.042174273435782325,-0.05034446899026806,-0.04469266612110648,-0.06291762906838408,-0.05513581438411185,-0.05457080007368762,-0.0517832181797574,-0.05979834981047285,-0.04007022059866762,-0.061711298812121805,-0.05039038613432485,-0.04255694499301989,-0.04374190370932099,-0.05833431251255525,-0.053493653455333835,-0.04620308032847555,-0.07165710526103033,-0.05965173997342158,-0.045863243004733135,-0.06305619264088667,-0.043947429599530366,-0.04686469117065439,-0.04048714361673599,-0.04977784244112405,-0.048562017777765205,-0.04949090572566781,-0.05094083827901837,-0.04651929078927602,-0.04303705547526259,-0.048713085601946315,-0.05176229463468353,-0.046104680786947794,-0.041606801803691154,-0.04776891800556205,-0.049746311398709775,-0.049812151347953075,-0.04176506868732778,-0.0430052232114994,-0.04836347258806021,-0.04995285174872705,-0.04344861336282202,-0.0497519655852424,-0.05304448085102724,-0.042004608481398524,-0.037883284043613755,-0.043485139147242974,-0.052300494594224235,-0.04019162232725894,-0.036625820976020795,-0.04372947829783333,-0.05338791652004385,-0.05373878989123452,-0.04740183454825706,-0.05353975670665805,-0.04959877220977495,-0.04544123105592304,-0.05478963460760729,-0.042950770401483845,-0.05887143106598514,-0.0461267857257548,-0.045466260756063775,-0.03939108976342882,-0.04186108254195355,-0.0423430368729415,-0.05024675075630509,-0.04055998398270042,-0.0409821457402112,-0.052206406167583444,-0.04524282755647654,-0.04733191376164198,-0.040987833387557224,-0.04180717347015568,-0.04223507824821694,-0.04847557613402998,-0.04959701734310426,-0.03778843796150504,-0.04496959109469267,-0.04261777569070027,-0.049536259489318536,-0.04071895712145519,-0.041490332880055165,-0.05480991553726637,-0.04666008397224643,-0.043119801747235224,-0.04570186791751589,-0.04089977392829998,-0.05230916462163501,-0.04180442171307174,-0.0405326829694557,-0.0507082908325788,-0.03756933310073379,-0.05299694394203527,-0.04793410404746958,-0.03883176302632226,-0.038063788475505164,-0.0451902661460819,-0.046390730568764,-0.049381339550685535,-0.052429300465471756,-0.04868084549133666,-0.03878789449342189,-0.042896330669809815,-0.04725484580944349,-0.036641366904471,-0.047690149720909396,-0.048520836671314176,-0.05037122253920157,-0.045465447949476434,-0.04397982065394204,-0.04959581808386309,-0.04488989306333859,-0.04244525139136645,-0.04178350719945635,-0.04422065732596915,-0.04534970151784296,-0.04785778911162918,-0.04191227289798691,-0.03913664228865011,-0.04945144824592452,-0.05592658426211146,-0.048259451136359655,-0.04796404819353529,-0.03932478726038972,-0.04991354903758377,-0.05622919050868331,-0.055817431979624084,-0.04182968447912879,-0.04122802386613271,-0.0373704876273723,-0.04493157845089771,-0.05391069015626895,-0.04327819667523816,-0.04589827344119615,-0.04213085089900387,-0.04336018869704689,-0.039110358301529355,-0.05012645301247078,-0.04966589610668979,-0.040341174272953535,-0.03951446891258168,-0.04732492765706817,-0.04966590350952461,-0.038135963573380255,-0.041654287213628884,-0.04743172159379017,-0.052446790353670114,-0.05299019781269027,-0.04285573628737066,-0.04560666459927479,-0.03983997898721842,-0.04912060669900117,-0.03666405861664212,-0.056992676622043326,-0.04490304091747654,-0.04631801003001922,-0.04499729548840684,-0.051020964934508646,-0.04941680246075886,-0.05012706559705231,-0.03763702551068685,-0.04820168997478601,-0.03791320642534508,-0.03902895482976509,-0.040650350214640446,-0.03924679748252306,-0.038517188962159214,-0.0441182747138415,-0.04613798900324169,-0.04220092423336851,-0.04213063451414202,-0.04139579993785943,-0.043623676711119226,-0.05082644145820132,-0.042678555382848725,-0.04153122964362069,-0.04653655814825962,-0.03935637350327565,-0.04411840179583928,-0.045117522436464136,-0.04986044495004445,-0.041339652643629224,-0.04178279711954022,-0.04639299003733227,-0.05317904437576208,-0.05097921425394641,-0.04623056855941293,-0.04997166353646347,-0.05524990472756728,-0.049241889241951844,-0.047814601146010126,-0.04720103398621906,-0.04665889211584008,-0.03759260208596434,-0.049282867189939246,-0.040918794870796235,-0.05139746563669525,-0.0459187374676365,-0.03853711499991693,-0.03908851603997795,-0.044711438525761635,-0.05888911513054088,-0.037204784670185266,-0.04617697062876263,-0.03953946423889273,-0.04766098753628594,-0.043333638405281476,-0.04599318920865665,-0.04417521847907021,-0.05253041879679238,-0.04197820819574272,-0.04615280202636839,-0.04776611872227856,-0.046579804300160385,-0.047378675889941484,-0.04366832671193953,-0.03979560711090238,-0.047149423988155754,-0.047720770905571815,-0.058092822959849064,-0.045220664653472874,-0.057910847263888995,-0.04344982856283418,-0.05558682698768958,-0.044515481416462666,-0.04710009329825805,-0.0469300608918298,-0.05186886821368899,-0.046108547855126025,-0.04579913023555828,-0.042399265376269694,-0.053424844303071754,-0.04437546674027825,-0.04317048752604711,-0.043958260391045126,-0.045868965346698355,-0.05341299423990646,-0.036751985096309836,-0.039375974309823515,-0.04492708557173974,-0.046110741463140495,-0.04025129665278788,-0.04155110583562393,-0.06287126392943998,-0.04336719932968008,-0.04239980941060077,-0.044026268013704906,-0.041128638217654424,-0.04957412832070902,-0.042795852708377415,-0.04096318495808594,-0.05146365006451893,-0.05204922108487548,-0.03599325651345268,-0.04291024390304001,-0.04465363181207772,-0.04853441216254367,-0.03889347525357325,-0.05110148618577105,-0.04897999303477518,-0.043920316297500615,-0.056404614301007995,-0.0471852360405954,-0.050487837668825294,-0.0526204905686393,-0.049957325084401094,-0.042661520497554645,-0.04824632771157662,-0.05440002600191467,-0.045103776112483056,-0.04772792317911126,-0.05799542941422139,-0.04852429463416402,-0.04991639357686414,-0.04335320575101594,-0.047763951024185965,-0.055847722060161024,-0.05187054791691011,-0.03937780646208974,-0.043688237105039655,-0.04639226831028936,-0.04324970205358284,-0.039466872188684346,-0.043565513180796885,-0.04701144055114206,-0.04050040614078533,-0.05149505728218276,-0.05562520826798257,-0.04834972315488851,-0.0510019292603711,-0.0496185609002706,-0.04391810845136717,-0.04565534924377757,-0.042615105192066564,-0.048482842213816754,-0.03950036293420883,-0.04445345535836745,-0.051690517069038384,-0.04504375619794851,-0.047235661905876684,-0.03898135090044186,-0.04048120104043482,-0.05091919490696253,-0.047126959172871935,-0.05269594465349436,-0.047329457328315214,-0.06532606428955338,-0.04112768367145635,-0.04056943950023806,-0.05226999442123504,-0.044165236669328964,-0.04097439092526947,-0.04462643303198189,-0.053460902475093115,-0.04305664490612095,-0.04254032905882451,-0.053752502729726086,-0.042549111165154495,-0.05080878239055116,-0.04339647467897185,-0.0489365882648003,-0.045628673498638035,-0.038839125441666185,-0.0542318129408484,-0.04353142379269645,-0.04380795054312145,-0.047903257964685274,-0.050924046502819856,-0.042998687273311124,-0.060845244892383;-0.049540553139460604;0.01167934800259901;0.0
data/model/LunarLander-v3_173353_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 173353};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 173353};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    if is_success:
        return 50.0 - abs(vx) - abs(vy) - abs(theta)
    elif is_failure:
        return -100.0
    else:
        reward = -abs(vy) * 1.0 - abs(omega) * 0.25 - abs(theta) * 0.1
        if leg1_contact or leg2_contact:
            reward += 3.0
        return reward";-0.049148018370676276,-0.04955380942417841,-0.05160073096035419,-0.05408203846162783,-0.05261346708297321,-0.05200544544828498,-0.048616581407383376,-0.05049082962940748,-0.04890352859375294,-0.051861551181515815,-0.04650467473515822,-0.048536723982026915,-0.04918897987862333,-0.05104049178522223,-0.05450934622047708,-0.04742847551978536,-0.04718088175561873,-0.04903656431357743,-0.04094750206371473,-0.04984902614947703,-0.0558893804553601,-0.03639508343630093,-0.049945336166118855,-0.05519665062463439,-0.034945146169894484,-0.03820906295491632,-0.042474452733853904,-0.0358910018785964,-0.03626015283379947,-0.033398846846641815,-0.03946325866545374,-0.034179516985062754,-0.03399091561690598,-0.06820501414284187,-0.03645611749226391,-0.039961634599342905,-0.03704051927467606,-0.03633164220722855,-0.0353589842418163,-0.04545663473555581,-0.03521169830219111,-0.04465645132680662,-0.03352407075318106,-0.03411041372364302,-0.037418228660394785,-0.037468118492282564,-0.034636083222327724,-0.03473832811095348,-0.04653107960878803,-0.035792842859214045,-0.06511144370596787,-0.0430548167538662,-0.04606670529257659,-0.06909336571158971,-0.04788505118984027,-0.03961671831681104,-0.059233941141310704,-0.06081264645898772,-0.05912215439692781,-0.05973031677845226,-0.03679916726909883,-0.03805738368948302,-0.05688734582273972,-0.05652238682438703,-0.038095748841434164,-0.05419266871431874,-0.056306286405644904,-0.05650716000587309,-0.052988582288099946,-0.05443695239825663,-0.055900524881881415,-0.05393247681281242,-0.057426965202944984,-0.05509283755768426,-0.05500599518653562,-0.06342621605063896,-0.058971691266319175,-0.05467480814138642,-0.054376498603469894,-0.053851836885762255,-0.056833238899155224,-0.060752806804354374,-0.05795411080335792,-0.05871985624289953,-0.05735217394236224,-0.05984787429092432,-0.05878722932303128,-0.056568783090540704,-0.056712217321012726,-0.05450706526038566,-0.06184170569926494,-0.056350106242548256,-0.055273069311626094,-0.05070407947235114,-0.058082226834655075,-0.06130525336533912,-0.05754658838256748,-0.06118992445874148,-0.055225975829656354,-0.06066728274396208,-0.05229680171502092,-0.06082441566870628,-0.05517420197413505,-0.053972901433125615,-0.05936923277297985,-0.0567647277208225,-0.0596652836252976,-0.055313729560370124,-0.055239724756812825,-0.06194460614660486,-0.05823954355477985,-0.06432160825997064,-0.058497776118707906,-0.061028000691927924,-0.058069785235090245,-0.05580624795711442,-0.061355351739824454,-0.05551739483613713,-0.0559218309066061,-0.056283018639098306,-0.05404457144618718,-0.05454160280853662,-0.06114186543298528,-0.05925866336483009,-0.056146803857482934,-0.05583383742035731,-0.05411195023875157,-0.057103558701646996,-0.05830934181652199,-0.05525027067675642,-0.06068326290736563,-0.05521647284355085,-0.06073848877737889,-0.05489556077212901,-0.05731524989564258,-0.05707121105136184,-0.055398353019517,-0.055565846603337,-0.05952289188582174,-0.05780907745126686,-0.0590455496934978,-0.054548373026211,-0.05978819258648051,-0.0557679464488535,-0.05632304901595758,-0.06023484029968092,-0.05730606032577834,-0.054677691535424344,-0.06466240505265398,-0.057890183574168794,-0.05503702914052301,-0.05772167795415154,-0.06020412716641168,-0.06044842890528905,-0.061610238352756606,-0.05667083553895211,-0.05525874623305682,-0.061392792039227685,-0.05620424784283902,-0.05995535582163274,-0.06027850682653359,-0.05967928528508384,-0.05556066410181921,-0.05623800751859235,-0.05572243077159877,-0.05527451939524948,-0.05429684041589437,-0.058251216804760614,-0.0568660897193121,-0.06085845469097642,-0.061425927369489645,-0.0564358035796839,-0.05569443665126847,-0.0566870840873933,-0.05827536342364944,-0.06449274231948231,-0.05863846321634898,-0.06128381119639534,-0.06449582240381871,-0.054465567255144814,-0.055965203347610244,-0.05546215924642827,-0.05742257036941988,-0.054500013555030896,-0.057764190341339325,-0.054878282741744076,-0.05587122969652052,-0.05452392429838766,-0.05670721732287277,-0.06336585117520224,-0.06310735360690099,-0.05583564413326269,-0.056223416835665535,-0.062327813406633625,-0.05664760610676626,-0.06260767174028667,-0.052192446111919616,-0.05714535996801032,-0.056189464756506234,-0.053666338773389166,-0.05869156550864112,-0.061117355236875635,-0.054799703919744966,-0.06137813839056968,-0.057306543267732005,-0.056814451487556476,-0.057120220394218386,-0.060085017079087935,-0.05811154527150009,-0.0584472086656182,-0.054114813864690886,-0.056118903553444184,-0.06099656814824414,-0.054934475547984925,-0.059131441198559065,-0.055273651744639565,-0.059717847818988645,-0.06248121665955993,-0.052232165456237045,-0.05795618630077176,-0.058965915058150846,-0.06334758215588128,-0.060215042455332234,-0.05809836380176691,-0.04971931630952268,-0.054223879039236283,-0.05841219454878509,-0.060164551958012326,-0.05763186114614224,-0.05815816235941349,-0.055695380835921134,-0.05450888391632706,-0.051380804745702655,-0.05555709760355709,-0.0540118440943271,-0.05660668008324102,-0.05393496041645881,-0.055891071302326296,-0.055959173420119225,-0.0602597819060091,-0.05580550252174695,-0.06318051493525143,-0.05404985227687537,-0.06213709943350568,-0.04944539021448488,-0.05420166522050882,-0.056988375807338926,-0.06185731136220358,-0.053801396404471055,-0.05691120606271338,-0.057450466929275745,-0.06329490629297731,-0.05822356870148478,-0.05712630457555279,-0.05424295475220349,-0.05158480350655399,-0.05903028001747214,-0.05856189187215605,-0.05717848014919764,-0.05885030416225163,-0.05311053258523984,-0.05620301813927479,-0.056235623127517544,-0.058889258295113565,-0.05447509140635543,-0.05733798357941112,-0.05738553369304531,-0.05891082116016935,-0.0573934333471094,-0.05486952066214834,-0.054648258954930036,-0.04975394939739642,-0.053197253681614466,-0.05760060743983555,-0.05891366521631877,-0.058484776718070716,-0.05402810862844896,-0.05349934943587206,-0.05442561667657552,-0.0619537471139964,-0.05566862040244977,-0.06171371837746434,-0.05490330100081491,-0.05021304576481626,-0.0589038773142173,-0.05457948333847399,-0.06017771099232319,-0.059883053373225144,-0.06025069648788774,-0.052419341446470986,-0.059122113979612104,-0.05117655121834442,-0.049399418017417526,-0.05661845265793053,-0.05607629211803852,-0.052527224534373286,-0.05595044454910301,-0.048867342486616235,-0.05821155415961863,-0.05289418710827296,-0.05150322070968082,-0.05538011202935111,-0.05071301570296064,-0.05455322203294303,-0.05697496721105521,-0.05148070275898451,-0.05090315850130403,-0.059020621187529654,-0.05240080662840057,-0.05389629571389839,-0.05352013450528568,-0.05645366064643903,-0.05035608135251934,-0.04848515550928902,-0.0476274260971857,-0.050404862424626794,-0.04768862559213198,-0.05204565464654252,-0.04745396785712314,-0.05004866170290768,-0.04310934862608614,-0.042095999633060245,-0.061247440319169275,-0.04850765655438045,-0.05423608295480761,-0.04593795583324841,-0.048233073487357815,-0.04536368504686451,-0.04948934664986271,-0.04482595170248434,-0.045158553546570515,-0.04943510639476167,-0.050390133747360344,-0.046304245200384,-0.04960006546922799;-0.05420443773980311;0.006852266499303686;0.0
data/model/LunarLander-v3_171639_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 171639};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 171639};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_pos, y_pos = observations[0], observations[1]
    x_vel, y_vel = observations[2], observations[3]
    ang_vel = observations[4]
    leg_left_on_ground, leg_right_on_ground = observations[-2], observations[-1]

    reward = 0.0

    if is_success:
        return 100
    elif is_failure:
        return -100

    reward -= abs(x_pos) * 0.5  # Penalize for being off center
    reward -= abs(y_vel) * 0.5  # Penalize for high vertical speed
    reward -= abs(x_vel) * 0.3  # Penalize for horizontal speed
    reward -= abs(ang_vel) * 1.0  # Penalize for angular velocity

    if leg_left_on_ground and leg_right_on_ground:
        reward += 5.0  # Reward for both legs touching the ground

    return reward";-0.07722519536392804,-0.04882997838933344,-0.06629714582383578,-0.059756189469428754,-0.06050030461237749,-0.07627689697441835,-0.07814447181377839,-0.06942180830064928,-0.058933766651002695,-0.06095968763785354,-0.06722165680175968,-0.08755120764498579,-0.06975245658712888,-0.10516616766683476,-0.059976261773927696,-0.08794607264382025,-0.07882101831308393,-0.06391402984458897,-0.09556799210526071,-0.14906095337394215,-0.05605085874570717,-0.06945391020434467,-0.1298431800752976,-0.21281037456283058,-0.086329776121881,-0.07064890422648022,-0.07422186559457038,-0.0749358548442754,-0.1596956260452284,-0.06487991676484056,-0.11377829820687113,-0.06328362044624818,-0.09223555939623293,-0.0815273302458877,-0.12560806574296393,-0.07537190789305313,-0.12797070715668588,-0.07335306521682708,-0.1000304017321248,-0.07161300551693843,-0.07647011787906789,-0.07350089020174272,-0.07064126941495966,-0.08340186414254296,-0.08000879361282773,-0.12132669370136875,-0.07502279536562143,-0.10835786365500504,-0.052953542177018906,-0.04871800637082904,-0.05814471990279145,-0.06423044210130939,-0.05097658581904181,-0.05285152077516517,-0.052443171759430196,-0.057164126183799874,-0.0648193312671732,-0.05525476571951135,-0.05518824054588084,-0.10074127548994648,-0.05315770106593322,-0.05982444748454834,-0.05762261185540818,-0.0540629616110841,-0.051396052305899005,-0.05571336882250833,-0.05387530790631673,-0.05179145284317213,-0.0560159148980631,-0.05324999401709416,-0.05383579448901376,-0.05096657906552709,-0.05405854789711465,-0.053983481456500934,-0.06063956064370156,-0.05110075827546712,-0.05258904645664488,-0.0508847756903252,-0.06789996564231822,-0.05916327749052673,-0.0579053236877789,-0.05741367981656636,-0.05581683708871145,-0.06161800406156482,-0.05187169131442128,-0.056152398473966546,-0.054268044121306924,-0.05811091949875983,-0.062955611011372,-0.0589321302669567,-0.05481657849134928,-0.05927565204713671,-0.05590817054200685,-0.05756636898357758,-0.05615758198228893,-0.0576455288658222,-0.05796980545739138,-0.05287584475104507,-0.0565437919347428,-0.0592419772218674,-0.05935667438547507,-0.05181483344833683,-0.06101409467447148,-0.05336782834665345,-0.06886531633887594,-0.05706593646960097,-0.058039133600573396,-0.0670786074428811,-0.0565764088449006,-0.05737534839692907,-0.06509845560062498,-0.050421810787861315,-0.05696279802876175,-0.053458454470595905,-0.05901197146859105,-0.07772156723120968,-0.05118958386227419,-0.07625080092044409,-0.05299468141840931,-0.059570500000752515,-0.05825762509833289,-0.05084114262004146,-0.05229500688792813,-0.052817462050191485,-0.05182183540639292,-0.0673634410632756,-0.06292308293299667,-0.053252777137221444,-0.05826274936924789,-0.053294389885910336,-0.05013480040764801,-0.05000106306432685,-0.05275970388580441,-0.05209410168538368,-0.06047595217948395,-0.05530739648811153,-0.05364960136586435,-0.05751928944719665,-0.06514697613546253,-0.05612212296328869,-0.05302965940987434,-0.056429840691034204,-0.05368638851489427,-0.05462373284975555,-0.05084069280473243,-0.05363774855913022,-0.056122013749556235,-0.05909924604306885,-0.059290942645475006,-0.05712849030678123,-0.05757455079568049,-0.05230527832295896,-0.051612652514133814,-0.05499793111357987,-0.05157977713435925,-0.050675973898631314,-0.051419282372522204,-0.05385056004534731,-0.06102063571256994,-0.05005675548294305,-0.055760499108322786,-0.05090246990174803,-0.06563285623991542,-0.050770946178758915,-0.06773234171770216,-0.05107708805739048,-0.05439644110719893,-0.056207214187603646,-0.05013784204875241,-0.05242685301335878,-0.05171459679436518,-0.0508603632611075,-0.05030419477223354,-0.06288631272747637,-0.06227002923689502,-0.0623479200264823,-0.05984598824298661,-0.05186184819498607,-0.06271509319441221,-0.05316649781822646,-0.056854580438427824,-0.06006230907929323,-0.08143608371593225,-0.05733019805806692,-0.07350399726512208,-0.05223913558931758,-0.060776773368997755,-0.056688016256270506,-0.04732065875788398,-0.07871418844700634,-0.05501853873552874,-0.05571080743853387,-0.11071945391088066,-0.05911942147036398,-0.05451834516071948,-0.06736484380637996,-0.059144284332566514,-0.058644234482942675,-0.06822285756422038,-0.06618778521158492,-0.06153598175881038,-0.055628307268257425,-0.06688227353597367,-0.072124192699273,-0.05849009070698172,-0.06647627763528512,-0.08284272432488565,-0.0625521019734912,-0.056907028796685286,-0.05780795855050562,-0.07100134973458218,-0.06343414617469383,-0.0640858121735709,-0.06310412852845303,-0.06691337921374593,-0.09191299283911573,-0.07167655906984255,-0.061059711597797384,-0.06350463775958722;-0.06460799127028732;0.01979943205449536;0.0
data/model/LunarLander-v3_682673_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 682673};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 682673};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    z = observations[2]
    vy = observations[4]
    leg_0_contact = observations[6]
    leg_1_contact = observations[7]

    reward = 0.0

    if is_success:
        reward += 100
    elif is_failure:
        reward -= 50

    reward -= abs(z) * 0.1
    reward += (leg_0_contact + leg_1_contact) * 10
    reward -= abs(vy) * 0.5

    return reward";-0.019578772774292985,-0.024836593749337974,-0.016422995549533786,-0.02030360557394817,-0.017390726919972066,-0.020807944830667724,-0.02563167495693342,-0.010883940698285379,-0.01933179302144913,-0.0163311129212416,-0.04755103214059697,-0.015394842677931828,-0.02381328468624382,-0.014284020852284534,-0.05167273968856413,-0.016848030509017193,-0.01056828218354129,-0.004009859036681936,-0.02773943332142316,-0.02152657961273682,-0.048456864155440586,-0.04432478970314093,-0.019377926552434983,-0.026611102586792234,-0.02061682240429108,-0.04859057943564761,-0.007152916971102022,-0.01664281433627664,-0.015803765465516546,-0.03799305451668785,-0.032952096010463915,-0.019377204145612458,-0.020958214086000185,-0.016892804777977426,-0.013513447767568661,-0.06854213022589122,-0.025874338886887074,-0.021026455632347268,-0.023468881205406567,-0.02536685092508348,-0.040637539188400885,-0.014955164430829369,-0.04447593774906872,-0.013929143442021282,-0.035982997861225635,-0.018204823234117463,-0.014578262593982875,-0.024217263916306776,-0.007827760863376608,-0.05235432330289499,-0.018634424313968178,-0.023283337883524925,-0.008248505428217473,-0.0526052201743316,-0.014559596919755552,-0.008658718347586549,-0.011451681836529939,-0.06250522406125389,-0.05281220876394974,-0.02134026455586312,-0.02006520867011705,-0.014305262941523499,-0.07791145822177796,-0.0166060847639038,-0.023135946476589116,-0.02231528547839118,-0.011686353740231848,-0.020978161936167913,-0.009927920791625928,-0.0574724761605352,-0.0703601402394737,-0.016738065655157675,-0.02217791431375086,-0.023373769700096417,-0.029724045714865314,0.013108320046223365,-0.05661210031700935,-0.04965603841973895,-0.022098593806292408,-0.021352949068488933,-0.015417408751974584,-0.045121630372746906,-0.02018934478342033,-0.054142462390625916,-0.059242047770602976,-0.03742312393665791,-0.035148828769830866,-0.017111098688373315,-0.054142307465786965,-0.054305819905221514,-0.016742447568134103,-0.06321520185443841,-0.05763034956041201,-0.017608623129628537,-0.06365008248621899,-0.029542364525337622,-0.020704902701900573,-0.028742987786250476,-0.056209918432137414,-0.013396106778060725,-0.05162541555176739,-0.03063392398998649,-0.01790614373382218,-0.01582746602899335,-0.00021974477022266103,-0.021680005300599842,-0.0546041689897107,-0.03587802310035067,-0.021845367431448146,-0.019044535790499827,-0.04671721241341003,-0.051171060510241194,-0.056958656574003515,-0.02344797735453261,-0.06901134239009425,-0.05895199972309618,-0.06026529439513174,-0.037476392985495585,-0.06069583768371912,-0.0646484591172157,-0.05440203993687498,-0.06224703869748024,-0.04652185619550468,-0.05872477185641493,-0.06018473428263058,-0.06499077569798828,-0.02982563435570972,-0.07405457751880193,-0.007814684338732307,-0.04483167456466847,-0.034240748385386724,-0.0553465604580192,-0.044970266390987425,-0.03733023630346097,-0.06276751397965262,-0.059969137603599884,-0.0359238841363818,-0.0439107196119136,-0.05350069573365283,-0.05494489113154346,-0.06399279853665811,-0.07080439671888991,-0.024327295263265075,-0.054642931536797404,-0.06153091441388739,-0.06326905876939362,-0.052487720566459756,-0.05069960078473324,-0.06045595448479178,-0.06510039246819818,-0.056995454790199906,-0.0536744735318781,-0.053098049741789055,-0.055463586940499875,-0.05228546575667709,-0.06958212801859692,-0.03457438541524102,-0.03638093018187772,-0.05130713498736708,-0.05062367914101656,-0.04545921585400132,-0.039214444702959976,-0.05113804047207134,-0.05582241561445299,-0.07266800910142054,-0.06335962084565501,-0.036366315287273895,-0.06496280969840829,-0.04782919961401156,-0.05421279549807658,-0.05201450720843279,-0.06862373288789031,-0.03671446248522915,-0.04984642864310788,-0.039330526460429796,-0.05772631398177599,-0.06863167105491935,-0.06092165524711803,-0.06187059905246449,-0.05707443765799405,-0.06606135251244888,-0.058923996123012114,-0.0641840248383155,-0.0598340920845153,-0.051036149424793655,-0.06537076447139727,-0.06263951076218272,-0.06432285844612982,-0.06014226568881858,-0.056694763955262274,-0.06345922851005519,-0.05730986322129095,-0.05369497170874974,-0.058000501027014435,-0.05249630115111663,-0.058083862840250286,-0.04662901821792385,-0.06350089217766902,-0.06325124222254731,-0.059274682201815906,-0.05865878497773295,-0.06895997401432659,-0.028919131345390703,-0.061057519649123024,-0.04120778852638914,-0.06705707351319365,-0.0539696507014849,-0.06284073382121733,-0.05828562805959208,-0.05773066534214331,-0.044559563057023896,-0.05098122232779862,-0.0623267500345978,-0.05538729100057238,-0.06028250520651072,-0.053289036030949165,-0.053270899353560386,-0.05505793898074389,-0.0647853278900902,-0.05671040329920442,-0.06690791435127058,-0.015621101350496068,-0.042995007978060044,-0.06564193951571748,-0.04886448742051618,-0.05114595874929538,-0.05596058877777421,-0.06641770710819904,-0.062074238632697225,-0.04910016282321818,-0.029964211381889136,-0.06705102184028786,-0.06311284925972435,-0.06504878986323441,-0.0534772817756789,-0.05911891692841979,-0.05966442760047822,-0.06470299326220802,-0.03726454199600298,-0.06645346446613118,-0.07916771970995029,-0.05924347767136431,-0.05631692319110954,-0.03185041618186089,-0.07350645397442115,-0.054802441616509726,-0.06593500573988426,-0.07186592737042215,-0.03541141904497508,-0.06529447361283375,-0.05702744498029507,-0.05550700673704008,-0.06334061226450276,-0.03446465800559611,-0.051262241686093404,-0.06305084251022292,-0.01922162994728179,-0.0627129665091352,-0.06059754326128374,-0.053197078609769986,-0.057696617447121394,-0.05823216672494841,-0.054048907743263555,-0.05989801977599319,-0.06362331992073697,-0.05133361140030964,-0.030805081579925595,-0.061351030289712415,-0.06620632300705254,-0.06276810942559914,-0.05208420804764443,-0.0674633631733854,-0.06407297894413679,-0.06078657736442214,-0.07298766937874712,-0.06578287270884246,-0.05610336746303562,-0.04615678313712229,-0.04545095861937543,-0.05321133784117903,-0.07911363159201176,-0.06029973376832241,-0.07445856599431355,-0.0615186479762725,-0.056106468565205736,-0.06819539415718118,-0.05576887652336097,-0.06961735569939397,-0.057166689340779474,-0.051183625703903786,-0.06630601997335944,-0.05437170509759114,-0.05641936543667676,-0.055061881625357426,-0.08514090759333087,-0.06332108972086709,-0.041115914826421567,-0.05631701495082525,-0.06359682493288883,-0.05464179462815275,-0.05962708059016088,-0.03774199520848525,-0.021553193532429078,-0.07072213560503939,-0.08001588271199055,-0.0689885207447861,-0.037253624751343604,-0.061806671447620115,-0.029489603491426215,-0.06867807660178585,-0.041314019621585166,-0.06685647919007814,-0.07508161700236683,-0.026157543412195998,-0.035602027956581184,-0.052080089166206704,-0.08015273761782729,-0.07362177583638616,-0.056628496983987406,-0.04115586432577617,-0.0707245190542323,-0.020806912818103415,-0.02213909499156045,-0.07390185345763925,-0.027916684451738553,-0.06933984915408756,-0.05977955306704438,-0.015326558389264805,-0.07395958480172721,-0.02926118397621004,-0.06319458688055396,-0.07567806577582155,-0.049439935259500196,-0.027859705725231092,-0.014485533411700963,-0.004863565021229957,-0.035294574481228046,-0.06359087034797888,-0.02773982142365221,-0.01987041872090042,-0.05341698190597586,-0.07832792436513883,-0.028614553554228397,-0.054193640875957995,-0.08518404118170451,-0.022336723755278853,-0.07628926623138009,-0.06187304170363461,-0.020770315293079166,-0.07163053984477023,-0.07228740029489322,-0.023979899364230377,-0.03898618029024885,-0.07212079202650921,-0.0617191924654661,-0.06512502881037466,-0.04409838945169728,-0.06274413864276951,-0.04700411642825965,-0.03079111664304495,-0.03684566724453881,-0.08241473294921844,-0.029938195118468618,-0.02405202820879519,-0.06523408881987029,-0.04406126521366692,-0.07498433105358233,-0.036044121847336116,-0.03658467894105066,-0.028671209143705516,-0.06264359464964266,-0.03558041797590917,-0.07216690902092483,-0.04395368335036067,-0.03025881143240361,-0.03751615466996476,-0.06358046341314685,-0.03499170807097517,-0.031297687465195886,-0.02522609125327271,-0.04687757331620708,-0.05779119310579856,-0.07086816128642281,-0.07406104287104365,-0.029576856273983626,-0.04309248047965499,-0.045886716502214986,-0.07795112913476364,-0.049863213724224,-0.030411572050778705,-0.044507986017246925,-0.044353908616072746,-0.037357977887484455,-0.035796439589111016,-0.04447405359383736;-0.046373445376627714;0.019523041093056682;0.0
data/model/LunarLander-v3_975860_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 975860};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 975860};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, left_leg_contact, right_leg_contact = observations
    if is_success:
        return 200.0
    if is_failure:
        return -100.0
    reward = 0.0
    reward -= abs(vy) * 0.1  # Penalize high vertical velocity
    reward -= abs(omega) * 0.5  # Penalize angular velocity
    reward += left_leg_contact + right_leg_contact  # Reward touching the ground with legs
    if y < 0.5:
        reward += (1 - y) * 10.0  # Bonus for being close to the ground
    return reward";0.0013162908373269408,0.0028823511906707288,0.0011979837761725192,0.0035989881435695386,0.0012856284674804671,-0.004921465807701864,-0.006177662355070608,0.004160845082430001,-0.00246531373543463,0.004927820743171849,-0.0016523398644998479,0.0024180267180062753,0.00077159538671349,0.003353622381391232,0.001393343362678036,0.001122742366524371,-0.0015208167441773896,-0.0007366550336564109,-0.007598426637516628,0.0011675912074317993,0.00010655152929929671,0.0024230290948004884,0.002219013545547369,0.021817623736604768,0.02664940497252743,0.0010418224595986649,0.008613894671457817,0.012660884826392821,0.00044419848445945175,0.0010918161740062222,0.00013186282717238124,0.002081846535118527,0.0019644391883985204,0.0009235035474195545,0.007820448907115213,0.003655402748026677,-0.008724187500752056,0.0021528695782626296,-0.00217578186488144,-0.007938043552784603,0.0005655044493769002,-0.007575658743543523,-0.007549828569870941,0.0035074804728395864,-0.0075081631012565726,-0.001231360221957711,-6.770855438080273e-05,0.0002991482175363493,-0.007833499380481184,-0.003751193980678163,0.01652839294651766,-0.00031873825741981696,-0.007672755937349276,-0.00021192773063420477,-0.00746010200877324,0.001509132205349787,0.011530500716493513,0.002767492127825812,0.0010441740576415091,0.0006631494355603612,-0.0029592959243589898,-0.0008402101761100488,0.0003923712372353638,0.0006843881458061518,-0.0010876643746613986,-0.0035755965037776566,-0.0008734016036809028,0.00038348223450672625,-0.00018709482918461806,-0.0010002040807039138,0.005545762342318677,-0.0073515460633540725,-0.007455049079930518,-0.0009080841937834894,-0.007975030911514523,-0.007404740601345599,-0.00010015425969111638,-0.007764351590575128,-0.0008113863417270804,-0.007408787381473438,-0.007673097249207523,-0.002135212558515879,0.00018595570774288485,0.0019328092385728936,-0.0009400841787383018,-0.0008297378269723904,-0.0005867530746020788,-0.00026571371485503123,0.002058202125565336,-0.00028283157113061425,0.0003156717201847371,0.7585788786922726,0.002780387960263728,-0.0010448998791697946,-0.0006860087534039799,-0.00042308133241454187,0.001112822236152517,0.6466816101120761,-0.00823063585243344,-0.00016661266029898154,0.0013570422893840097,-0.0016859659726731733,-0.00790839490943451,-0.0023952998713513097,0.0005397184041134467,0.00019789468380498383,0.00022061389036790165,0.01730974907964985,0.00023943234503563478,-0.00036776902782782473,-0.0009863704451437336,-0.0005171213632955109,-0.0009577931892640071,0.00042839384747756133,0.002596067948904121,0.0008314621931356295,-0.0004121910885776677,-0.002822689536827255,0.000245231215444092,-0.0011453818095412953,-0.00028199736701262274,0.0004179724110618843,0.0019246527077242108,0.0003493929872879479,-0.0018499407294385844,-0.0001615117605686604,-0.00040646352106014303,-0.00024871726275826683,0.0003140507126038613,0.0010492115277826847,0.00017084041146051153,-0.00023788408446902135,0.0006151186553725632,-0.0008909261425577994,-0.0017553635112210176,0.00040647586257736403,-0.0003433026760476089,-0.008844190399178128,0.0011697861506618312,0.0009145209717886783,-0.00022564957895690363,0.00016594641693113207,0.0002966391516547221,0.0009004131148747385,-0.0007365299338252566,0.0010048094281751418,-0.0009921209738713397,0.00032460495144821355,0.009041076231783678,-0.0015510727448920449,-0.0011465923317255642,0.0007394028196024108,-0.000305769573261225,-0.0008081773590834553,0.0010172728692735358,-0.0009859977752984038,0.0011977999809082989,-0.0003236811481062226,-0.0005336277311275558,-0.00033150353158345756,7.157140612790614e-05,1.4638274459485803e-05,-0.0004958619935939366,-2.6729931055143764e-05,-0.0005044008462505444,-0.0009388282919399883,-0.0005790925427446926,-0.0010342532601926642,-0.0027691301667836198,0.00026324150488374147,-0.0018439479602954823,6.0908345644879573e-05,0.006522701059847595,-0.0009166111056856178,0.006152092267645864,-0.0011948970097265786,-0.0019199158418179718,0.00167415989006903,0.003953482243574232,-0.0006534814125672328,-0.0009119113033157442,0.0001311757573967596,-0.0013496575785851635,6.128877630488612e-05,-0.0016153820256688963,-0.0008125539455224127,-0.0021471806327599276,-0.0014937559474180804,0.004866606964338152,-8.913097561888166e-05,-0.0010953324783876033,-0.003145325148739139,-0.0005017998102902349,-0.0012423228325780492,-0.0013293994236620353,-0.0012673844167981163,-0.0028701436852326028,-0.0017037881303852195,-0.001320254596948059,-0.0023431000309518065,-0.002912246052305412,0.01239663835123678,-0.0024599216414181832,-0.0017592020895329534,-0.0005128592726861902,-0.002244762157695416,0.0035948536188661908,-0.001158459393421672,-0.001757938757761028,-0.002044099749283311,0.004623280669328276,-0.0027412092860739975,-0.0023498925743855744,-0.0018553493897444627,-0.0015192365268105407,-0.004590261410158993,-0.0013779446090785707,-0.0047572168989429755,-0.0025944466297867417,-0.002290417352276777,-0.0019515091518059748,-0.0009484845155631587,-0.0025334218996495815,-0.0017908704201230689,-0.00369222855931489,-0.004548100185622948,-0.0022395948373883554,-0.002116778441490063,-0.0024926831191802146,-0.005424761287415338,-0.0018346279462045732,-0.002300319494782023,-0.0038432809427757014,-0.0055386950961675355,-0.003029566765530175,-0.0019036458735508576,-0.0022067892392090595,-0.0031579240479041428,-0.0026856811749092157,-0.0040050440031549756,-0.004063945961840836,-0.003844051981247227,-0.0031609949615456824,-0.0027022238952291396,-0.003670411878763132,-0.00394705287974474,-0.003910202936340906,-0.0023557828015458816,-0.004100764279002226,-0.00486573296278407,-0.004991977904859832,-0.00626035899546576,-0.0026904384168199643,-0.004334434423517735,-0.004744749370428473,-0.002039660926560708,-0.0027069817026779725,-0.004851531895005828,-0.005001596272777482,-0.0032739345366725467,-0.003846148772106992,-0.00401118121958734,-0.0016187278043341212,-0.00532217462113419,-0.0036062086138959155,-0.0024796484500502025,-0.004776263751597938,-0.005918759883181697,-0.0017857549059374217,-0.0026352832880278776,-0.0032746268384551427,-0.0035822613873848054,-0.004351295325284094,-0.004199633394801685,-0.007807566273906704,-0.006353272169979712,-0.0024965171547347165,-0.003325976980234156,-0.004539008652166837,-0.00363306118692667,-0.008911110873379527,-0.005591479855246482,-0.00414050555987032,-0.0035334245170596636,-0.0038670279001918797,-0.0031056825692433844,-0.003075686967498856,-0.0044234134209124734,-0.004217696393654549,-0.004137392461466971,-0.003964278232536472,-0.002011409367078569,-0.008035114240761174,-0.0026056165027566274,-0.003408928515349288,-0.004110633263166218,-0.006158708927046066,-0.0041273032784159445,-0.0028610255827433606,-0.0019407945613431773,-0.0036545208807890685,-0.006063709600532687,-0.0061366849294849585,-0.0059597920825342635,-0.0021965370359067525,-0.004024377093061191,-0.0021980432478331422,-0.004181465958042482,-0.004628631031520182,-0.0034782617364151436,-0.008525061232286413,-0.004284707708970133,-0.003138240002371995,-0.003802161080601796,-0.0038323066889841134,-0.0027717499137117946,-0.0032533882347675386,-0.00429286808267089,-0.001364920684782314,-0.003022635528104566,-0.002700393834780061,-0.007537610027230035,-0.003941064169234041,-0.004218175626624788,-0.0026544037595249985,-0.003967121923579563,-0.0036721558980895215,-0.0034669475284806696,-0.0038499358352533436,-0.0034118551888402842,-0.002590533759545514,-0.0029956062986233396,-0.003569256347928187,-0.005750591136916768,-0.004140842873254433,-0.0020173037558558686,-0.003699444900901374,-0.00403654446353692,-0.0056344293368225315,-0.0037932057426729175,-0.002815889199181916,-0.003682226766322234,-0.0016342785789109538,-0.003361268417306788,-0.0030461617416600558,-0.0028900982442672113;0.002613110441871671;0.05369678821143036;0.0
data/model/LunarLander-v3_328964_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 328964};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 328964};100000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    reward = 0.0
    
    if is_success:
        return 100.0  # Large positive reward for successful landing
    elif is_failure:
        return -100.0  # Large negative reward for failure
    
    # Penalize excessive vertical and horizontal velocities
    reward -= abs(vx) * 0.5
    reward -= abs(vy) * 0.5
    
    # Penalize non-zero angular velocity
    reward -= abs(omega) * 0.1
    
    # Penalize being too far from the ground
    reward -= (1 - y) * 0.2
    
    # Penalize misalignment with the ground
    reward -= abs(theta) * 0.5
    
    # Reward for having at least one leg in contact
    if leg1_contact or leg2_contact:
        reward += 1.0
    
    # Reward for both legs being in contact
    if leg1_contact and leg2_contact:
        reward += 2.0
    
    return reward";-0.15961734324425245,-0.15688027248182507,-0.15933002742310173,-0.1635921086197948,-0.16794664817570218,-0.13503706213346137,-0.13026803442400864,-0.16565537318285561,-0.13132339814573557,-0.1466106652094559,-0.16682965958473722,-0.19901384074444592,-0.14182617621814786,-0.12533322051247478,-0.170866003305168,-0.12354647478990605,-0.1597213704168299,-0.1309576254865872,-0.13285353993813662,-0.1278008551801472,-0.13972700119362264,-0.17678706918927775,-0.1515176174797382,-0.1863004506469424,-0.14699971973020115,-0.17344381978137297,-0.1392341407689711,-0.12270896881865788,-0.0958131944360585,-0.1088029587065679,-0.09112094668320228,-0.09348357253677776,-0.08233624574417013,-0.07824406169578552,0.0002909969674792213,-0.026246647800014358,0.0252414067526712,-0.033804844071654946,-0.02673257484262329,0.028101338881587,-0.010394940230291562,-0.0139843358814918,-0.0062976812122839225,0.003884687758088875,0.027022240640963334,-0.02757786374235089,0.03878236351235971,0.004733527614240635,0.06491615508389507,0.03579890337743491,0.15346176214699458,-0.15137671079489373,0.04768477454604775,-0.16799166598712534,-0.13847998712143117,-0.18073016840275433,-0.17118121386433904,-0.15563070871270138,-0.15698912796227651,-0.1500919770789107,-0.17468703682103043,-0.15939639904426778;-0.09843879343414191;0.08024235917079489;0.0
data/model/LunarLander-v3_133280_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 133280};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 133280};100000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, theta, omega, leg_0_contact, leg_1_contact = observations
    
    if is_success:
        return 200.0
    
    if is_failure:
        return -50.0
    
    reward = 0.0
    
    # Reward for being close to the ground
    reward -= abs(y) * 0.1
    
    # Penalize high y-velocity (descending too fast)
    reward -= abs(vy) * 0.2
    
    # Penalize large angle deviations from vertical during descent
    if y < -5:
        reward -= abs(theta) * 0.3
    
    # Reward for having both legs in contact with the ground at low velocities
    if leg_0_contact and leg_1_contact:
        reward += 20.0 - abs(vx) - abs(vy)
    
    return reward";-0.052476518402913695,-0.05348544839499395,-0.05334657619850267,-0.041337957986525245,-0.04969401564496112,-0.0524452722273284,-0.051778490251948674,-0.04960349373050191,-0.04857183697626509,-0.05456995521982155,-0.05227569685075924,-0.05130002078212056,-0.05831055450059784,-0.05102955859562783,-0.05294716163657177,-0.052029369887582465,-0.05477273524047134,-0.05318758968909019,-0.050126040483102915,-0.03661423239603326,-0.051377079514623544,-0.03880256736312988,-0.05058583607423062,-0.052030097967145625,-0.04961251550877514,-0.04924076699497139,-0.05523331850143137,-0.05167497263998951,-0.05554647612681671,-0.05255072425401951,-0.054880757758432326,-0.05291564696438852,-0.052290095713905964,-0.06263545232565101,-0.053682640485538696,-0.05083967181677383,-0.05452631874943521,-0.06102404235765237,-0.05669118099115649,-0.05409465634023102,-0.05672745933444203,-0.05144308016481513,-0.05238295194949794,-0.05306905459510499,-0.057162308294388973,-0.053655962410761766,-0.050366722796933515,-0.059600253053467805,-0.05247129682475404,-0.0523955463386423,-0.047405639530211235,-0.05855276367535996,-0.05031344712382997,-0.04876118199924925,-0.0558700042671285,-0.051830953632319036,-0.05260125637491227,-0.06354836980868851,-0.05805452950602418,-0.05389119107531822,-0.05397620265413654,-0.05080958326750362,-0.05576585786715252,-0.05256993643952075,-0.049578910728173144,-0.050257628410237835,-0.04855967178389762,-0.05134479379060045,-0.04996976454195304,-0.052589228937100475,-0.05151696584150301,-0.05426614996830171,-0.050516136356436335,-0.050544458565969855,-0.053700138228970545,-0.0486719309749423,-0.0487794203583362,-0.06784807137653448,-0.054762874541227684,-0.0562860504746926,-0.05614269742596286,-0.05315360620673894,-0.05556951562282615,-0.05825648204050419,-0.055732395903758704,-0.06091738140830583,-0.0517337381460871,-0.04725360520425821,-0.05050817006450493,-0.045841031341021556,-0.05736798653566703,-0.05324866846576756,-0.05439921868842192,-0.050029478561202365,-0.051006314821041634,-0.05407527831450659,-0.04823073275290498,-0.0525977727549525,-0.05975558916029882,-0.05866172467979077,-0.06120200739252388,-0.05709682401831639,-0.04916813177153764,-0.054882116587516204,-0.049707240947998034,-0.0475775718228765,-0.05638143366493448,-0.049719569427346184,-0.05214382682868145,-0.04898197525532105,-0.05562417899966589,-0.05040952238456018,-0.04888684412449365,-0.05214283842796446,-0.04959126182508576,-0.052038951768361826,-0.05803059918589795,-0.05017477341180827,-0.05073222075393369,-0.0582953880100245,-0.050856295080128344,-0.0550441067730471,-0.04749338262922203,-0.04849180675164894,-0.049357001398301216,-0.0499975465160562,-0.049330657075055774,-0.04922732754830811,-0.04624418463895795,-0.04885131909732697,-0.04986990901393375,-0.05047526462031123,-0.049960637280794355,-0.05696119245638056,-0.047994887584386824,-0.05551726548751613,-0.0502403939795272,-0.05071054924799838,-0.04730360620687839,-0.05468921094184673,-0.05596953344034887,-0.0495416133890931,-0.050641538960469835,-0.04930843147166537,-0.05500938389139234,-0.05062670390926417,-0.051555194883975156,-0.04923530719819062,-0.049466548640359875,-0.05203745944743185,-0.06138792719138212,-0.05228406243475173,-0.05007868200976387,-0.05652001657795465,-0.05012959685403676,-0.04917626401327346,-0.0492040908499294,-0.05189161067470082,-0.053841004573603427,-0.04994219430068934,-0.052040546788814174,-0.04952210520279176,-0.05374774583522053,-0.054323677075079714,-0.05060037600128597,-0.05011454357182511,-0.048914936498369636,-0.049561912587454085,-0.050021921007233475,-0.048797059713582794,-0.050390712712807983,-0.04975651559148025,-0.04984179305817853,-0.0504567563845878,-0.05108784283469079,-0.04942597583085353,-0.04936668983586201,-0.05081108583427796,-0.051828196470120325,-0.05116895189740742,-0.05382493621860506,-0.04926748823379214,-0.04869660571867113,-0.04947910519110787,-0.04865221498976741,-0.05211360676002715,-0.04935743527419634,-0.05046772515820229,-0.04952591610899085,-0.05000070029653415,-0.051755889738319356,-0.051210079483772444,-0.05104069937066978,-0.05271175230545262,-0.05148836461625899,-0.05356189776823099,-0.050286160336316305,-0.050737872789054304,-0.049568343394411706,-0.049456354145752245,-0.04801183395893604,-0.049514938163427974,-0.05022871744270833,-0.05070219546590363,-0.05096884610788664,-0.05016971801357358,-0.04927254599898123,-0.053023596764249795,-0.05129326260125863,-0.05204091043410335,-0.05350064504231992,-0.050954999764225385,-0.05050407972618669,-0.05507199513955986,-0.04914675795395326,-0.049524000596335015,-0.04934602622514329,-0.049858395435351886,-0.052524752627472276,-0.051614162227727745,-0.05195382368278701,-0.053317567199610894,-0.05212503918275511,-0.04944137907165958,-0.05029104960941662,-0.05118739491038681,-0.049784400517142606,-0.053929649022007496,-0.04906547725416674,-0.05003250437272787,-0.04962051924461052,-0.05363437878896746,-0.04936452475197035,-0.050245215673887164,-0.04944494746365362,-0.05080641583320526,-0.05064551468778673,-0.049044985631177825,-0.05333237661976845,-0.049312376910732175,-0.04996434372321337,-0.04878761575173095,-0.049577136772541434,-0.049574073330823885,-0.04854619369889504,-0.05242569652735057,-0.05027374219761133,-0.04974917681642347,-0.04917167584745825,-0.049695194300597816,-0.049440682891190496,-0.0514806928129068,-0.05002552928679275,-0.04943250726624841,-0.04992508561443232,-0.048504595789920064,-0.04961484021963464,-0.049757546652167424,-0.0499633419755034,-0.050899516478757456,-0.05130765479090887,-0.049596500695162436,-0.05274229604416587,-0.05144721200154259,-0.05174570250894682,-0.0514408818558966,-0.05010541040423849,-0.048600035961713126,-0.05318474491670353,-0.04990601546811258,-0.04990038060436964,-0.04989461454998629,-0.04810641117859643,-0.051786984111721036,-0.04924841163313835,-0.05123307279129631,-0.04913691874358748,-0.05039832911189373,-0.049214862936206374,-0.04922228314107011,-0.051458744263723,-0.050571530026379936,-0.052837253686000715,-0.05225217619455686,-0.05095518678649902,-0.051592454165496376,-0.05150325929060819,-0.05199751506432429,-0.04916977479952388,-0.04917968043802717,-0.05145599683233691,-0.048578874107088776,-0.050778744459430675,-0.052822659099831235,-0.05007804111302189,-0.047986277097318605,-0.048679766985757454,-0.0500924592624639,-0.05412855262880297,-0.05247784883950264,-0.049695395152021815,-0.0473988276326337,-0.05015400858091368,-0.050656938694676745,-0.04996559986373299,-0.049465215705319046,-0.049376344807317236,-0.05135007377007301,-0.04905662576511435,-0.04982437926492176,-0.051831101051938604,-0.05032689693687696,-0.049866218548457075,-0.05134084719545175,-0.048817992390036945,-0.04941028187106234,-0.051607278148998494,-0.04750885012845736,-0.053358869951561194,-0.052265074792134936,-0.052387312515112576,-0.04928790173632703,-0.04764968770801915,-0.05232426866219212,-0.04972293377910263,-0.048294373900198716,-0.04949812673815512,-0.0497475132967485,-0.049276280461319016,-0.049320458931393404,-0.050608177680303894,-0.04824719772618258,-0.052572028860103315,-0.045786453525200894,-0.047034860492447206,-0.05003885965630646,-0.0487054482111051,-0.05009723799002625,-0.04915790469843235,-0.05107250521112119,-0.047584927736436584,-0.05091450979812378,-0.05143211937967181,-0.04559889550897212,-0.049693168187613414,-0.049263091955656854,-0.047988357365343515,-0.04789585781663304,-0.05181646452903501,-0.04990260755781992,-0.050102091210904136,-0.05067751208717441,-0.04987654075998034,-0.04805051719366209,-0.04493574234935778,-0.04749724226619107,-0.052552276209051146,-0.04717698007369729,-0.04931271949451026,-0.04769988417066714,-0.049704269718879805,-0.05242984437389473,-0.050968667008335446,-0.05020455803755595,-0.04994681310541456,-0.04516710365146896,-0.04905316343678625,-0.04723477015349472,-0.051446581438309956,-0.04885787860743124,-0.04872855271069614,-0.05128412117124779,-0.04594257390484632,-0.052520077552788945,-0.052789497235575265,-0.047753223707707564,-0.04948585803536422,-0.04827404583814354,-0.0498627669371726,-0.04981292729290358,-0.047888300427035985;-0.05113433080439191;0.0031546995415595125;0.0
data/model/LunarLander-v3_356471_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 356471};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 356471};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, z, vx, vy, theta, omega, leg_contact = observations
    if is_failure:
        return -5.0
    if not is_success and np.any(leg_contact):
        return -2.0
    reward = 0.0
    reward -= abs(z) * 0.1
    reward -= abs(vx) * 0.1
    reward -= abs(vy) * 0.1
    reward -= abs(theta) * 0.05
    reward -= abs(omega) * 0.1
    return reward";-0.08272845845553428,-0.1282691628062477,-0.10931596128855435,-0.06674426358949648,-0.0636275693901504,-0.09996888985106708,-0.08076867623950024,-0.07532471048417044,-0.11413079721278716,-0.07875823755693999,-0.07914953723033769,-0.09608267983425721,-0.10607690790266536,-0.07222997898185239,-0.08279040723141047,-0.10482929939122124,-0.06481561736477308,-0.08507129501932652,-0.09315398962197606,-0.13407171172307544,-0.08028330048481974,-0.14907578388227713,-0.06265922768969555,-0.10181914439993037,-0.10912612046937156,-0.09547627889107085,-0.1221712129536205,-0.09779572664420927,-0.11603747760149948,-0.1232356315619011,-0.10026341368524982,-0.11768672049659837,-0.22248887553585142,-0.23581115411645945,-0.15853499225689943,-0.11006189546976756,-0.08899799310619029,-0.126163742540742,-0.22171764277313896,-0.09678947815052405,-0.09306689131882279,-0.1044394637230437,-0.09460529500164638,-0.1366824202367684,-0.12187613546241195,-0.1229964326128629,-0.08032499163987912,-0.0830276569485174,-0.13974983868518745,-0.11339757900197703,-0.1439836121680406,-0.10796542813951299,-0.08473942275596057,-0.08342003679926456,-0.12213616741996858,-0.13030150074834507,-0.1141003141018531,-0.4502651571724199,-0.08831075890087854,-0.10872930447796929,-0.1348702897917688,-0.07917576950137352;-0.11439142629828443;0.05516913854238328;0.0
data/model/LunarLander-v3_96719_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 96719};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 96719};100000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, omega, left_leg_contact, right_leg_contact = observations

    altitude_reward = 1.0 if y > 0 else -1.0
    vertical_velocity_penalty = -abs(vy)
    horizontal_stability_reward = -abs(vx)
    angle_stability_reward = -min(abs(angle), 1.0)
    leg_contact_penalty = -10.0 * (left_leg_contact + right_leg_contact)

    reward = altitude_reward + vertical_velocity_penalty + horizontal_stability_reward + angle_stability_reward + leg_contact_penalty

    if is_failure:
        reward -= 20.0
    elif is_success:
        reward += 50.0

    return reward";-0.028024549440277283,-0.016114935252556754,-0.03350603877615849,-0.03871921246644692,-0.03887742474966474,-0.027194032071817247,-0.038625897409361135,-0.0354027300309042,-0.015408061695509753,-0.025457457696511383,-0.020789371895632645,-0.0052191857879859875,-0.03228247537379457,-0.01916093310300995,-0.041467750028358584,-0.0358974572253606,-0.05885460428000277,-0.02968791551046467,-0.02314256464353211,-0.024565759111039857,0.11508128299928193,0.1702379581267131,0.03338082710988505,0.203230884221979,0.18879507065816023,0.19038152039427086,0.21239014975011783,0.049671977354371843,0.030731007845069134,0.21411210355231983,0.21067709497161957,0.057649326235232154,0.04337892012860817,0.07418211724063009,0.19251536776401204,0.1889872830739903,0.2076153742973283,0.1922660097868933,0.18164225366913198,0.19759603450368296,0.20614108834647685,0.19782971158908286,0.16858441525537363,0.20615502612119382,0.16225023577391803,0.20981449128343935,0.21596976317415176,0.21647716387130092,0.2095219558567283,0.21415924615958662,0.20450676438101859,-0.034985906935149115;0.08735669542330825;0.10770133237564233;0.0
data/model/LunarLander-v3_741267_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 741267};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 741267};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    r_theta = -abs(theta)
    r_omega = -abs(omega)
    r_z = 1 if abs(y) > 5 else -1
    r_x = -abs(x)
    r_y = -abs(y)
    r_leg1 = -10 if leg1_contact else 0
    r_leg2 = -10 if leg2_contact else 0
    
    reward = r_theta + r_omega + r_z + r_x + r_y + r_leg1 + r_leg2
    
    return reward";-0.08153877024432624,-0.056086438620621876,-0.1246605393376172,-0.05160544053122361,-0.05045123679611865,-0.08391879708126315,-0.042563653346208465,-0.09063297754868202,-0.036250978281241755,-0.03656015453002127,-0.04849742101752455,-0.05705757024901204,-0.046130659844592775,-0.04887903687706032,-0.0415422776737321,-0.07879007805220888,-0.038437492623418654,-0.07435269695850996,-0.051200980473192506,-0.0643079457201756,-0.0766580566934988,-0.1078546987700544,-0.05216984205273144,-0.05811967815260903,-0.03528920736039111,-0.0694740038806481,-0.07177581664737594,-0.08853703731047581,-0.03681955099516485,-0.07045143615561829,-0.05513858597776328,-0.05022913387070594,-0.07063074631152258,-0.18393811160559034,-0.06627060566305645,-0.06663530386419901,-0.04610773237286695,-0.05000366395990254,-0.0853238721777678,-0.08871746366357891,-0.08338795957484904,-0.035981307920334875,-0.05603436838971489,-0.0643960028270943,-0.07293002111389835,-0.07149880437234395,-0.03652845432911239,-0.07019038720175214,-0.051180857418484695,-0.05314882520357853,-0.07258173470117302,-0.04754828606443871,-0.044220670490892865,-0.06135704572600613,-0.04025328158672847,-0.038717129793120426,-0.0715884335391559,-0.0526026321297156,-0.050831555202377136,-0.07959822506003264,-0.059763005898782334,-0.05503231164619036,-0.108841655508803,-0.0631632872536119,-0.054247136536929766,-0.03506602277693668,-0.04120080441449884,-0.04383347554163047,-0.04422373296282098,-0.0581081671861419,-0.052801642310149645,-0.04780521705682581,-0.061417767216621365,-0.044043834638933466,-0.04916002324105116,-0.04579960711677559,-0.06890651859483768,-0.039065160047203104,-0.04771314067560394,-0.04404068431564345,-0.05953701584181803,-0.05241738868841499,-0.040324109776497176,-0.050253105237661744,-0.061015665329698744,-0.049803564996879074,-0.06351932541803687,-0.05529103217325743,-0.12826097754580645,-0.03498393961680629,-0.05581544742816904,-0.03856870056931897,-0.051646140769603444,-0.05419460998280625,-0.048905650530167356,-0.04103042613879553,-0.0678026144373656,-0.04876830699422357,-0.05149388165443777,-0.04773562433947839,-0.0358861415713069,-0.045442834202893675,-0.0434052591262826,-0.044580810850687554,-0.04930698375153526,-0.06332849337858286,-0.04812520541624935,-0.0322423455059098,-0.13617149339773782,-0.03989236784779999,-0.058182715906822155,-0.05289861693981579,-0.05613842360076232,-0.055986834789049894,-0.042869009482945884,-0.05426909122345489,-0.043410185737469985,-0.046825702517660786,-0.037527433647285516,-0.04899168816643327,-0.046270036043792866,-0.05437608036658701,-0.05483685144095571,-0.05462466591302611,-0.05999293834994958,-0.05275430435010619,-0.04736930875765057,-0.049545177562733966,-0.06440579680465609,-0.04090502692060976,-0.03559821679181429,-0.0628226189599102,-0.06190239382309434,-0.048846819049317286,-0.05852069502238759,-0.06113237923663081,-0.05603930117731625,-0.056485730455903216,-0.047409796722434394,-0.05112038317405511,-0.06608882892372474,-0.05988800484199942,-0.04351407908854598,-0.05891667231761794,-0.04100130838325515,-0.03882045415560396,-0.04528809043558076,-0.04312502167957548,-0.03672514965460437,-0.0531088531048091,-0.03460204977371385,-0.03748995132058544,-0.06538729329546797,-0.051663625168157715,-0.05956751575961154,-0.05295128761026534,-0.03491905630675488,-0.060798502099718814,-0.041778148150964284,-0.04123220844552191,-0.03915933020567217,-0.04878435813966177,-0.038515538657242325,-0.03036469851054517,-0.05192451020324779,-0.038072339263909565,-0.04333250980087305,-0.03545270578816725,-0.04390428360387469,-0.04704180933704558,-0.04668849795103139,-0.045826752510364506,-0.04524445621093717,-0.03740692617605562,-0.03240665041623146,-0.04381116397757168,-0.049524965816888665,-0.039703832784194974,-0.04614330824645413,-0.052667788989891114,-0.03503112628179696,-0.03328460655969751,-0.05499796287435815,-0.04330082550152121,-0.031000572898574864,-0.048984774727482736,-0.04323395598676596,-0.037166357452415824,-0.055325878796563276,-0.04271179682959507,-0.042695903805772484,-0.044896894253645486,-0.037621667574519894,-0.04104064937712843,-0.04728798995583884,-0.033554413506039694,-0.04541228484669885,-0.05241640907665148,-0.045916688547428565,-0.05558062572228313,-0.03770331827731405,-0.032472789949287935,-0.048625576162460736,-0.05322930341712021,-0.0458586563974868,-0.04843040708845838,-0.0448833393546755,-0.04546282622552085,-0.048034532570923695,-0.03441947327004129,-0.03103889860376709,-0.03292057782223261,-0.033724253323056445,-0.0537636046727439,-0.0366731906804175,-0.028633666336108917,-0.036913237984688235,-0.04552667197929346,-0.04095636121012027,-0.040999632326637156,-0.03212700254616338,-0.03239945221208935,-0.04716128458863506,-0.05940931458204022,-0.040789288643279555,-0.03354471826983285,-0.040607967306120187,-0.049217540635649475,-0.030056387122259044,-0.055963001687080564,-0.03758413350680803,-0.0429355812566223,-0.038693075965620174,-0.03891296014976088,-0.06205798722658199,-0.04171854518724787,-0.03511358146251105,-0.05960044029914282,-0.048745252282952005,-0.04367761178458385,-0.05045458790704184,-0.04496069512005865,-0.041620850355205075,-0.054701214924968385,-0.03698984250308766,-0.05679333502404297,-0.05011702496800211,-0.04516957136330704,-0.03450268237960307,-0.04698024937114402,-0.030319004587289373,-0.04616581856643098,-0.04567847141214026,-0.04801980764784892,-0.05165772552796382,-0.048244634832345666,-0.035665125965648733,-0.060380986050683226,-0.039514421699208165,-0.055096559435751424,-0.03491583208321348,-0.03890823394695318,-0.037474859632296735,-0.04220800724862307,-0.041833589511960804,-0.06489295170451716,-0.04104981820949178,-0.049312401929424175,-0.030768549406203455,-0.034792692565676575,-0.04118161443173346,-0.031660945870089906,-0.05383742736679748,-0.03780680005708528,-0.04820160784671791,-0.04106160670824465,-0.0468443669634478,-0.037375127017075516,-0.03819638660594231,-0.04128997021481517,-0.04075187712862389,-0.04965378674132576,-0.03806018535441951,-0.044799811292929,-0.053912792566061664,-0.042915659639696506,-0.042478221594481634,-0.04030350024792041,-0.045779901051279534,-0.03843825245778497,-0.0416446507601057,-0.05433646888370707,-0.051832527795622724,-0.04771891535177303,-0.03919444642403001,-0.0355549686743126,-0.03650580940123629,-0.04021415075346747,-0.034911295290434276,-0.04635988563815085,-0.05182334460580584,-0.03720116801955063,-0.03449511792494819,-0.052725976958838024,-0.06283380804852284,-0.05088702855611445,-0.046410409354596054,-0.04253534145015429,-0.05436036681093358,-0.06004133998058355,-0.06058826357793596,-0.03461440791120803,-0.06000818190217132,-0.04248138511037518,-0.062063398550818556,-0.052565881762250355,-0.04919264584062569,-0.04160087946241517,-0.045808895711973024,-0.04269369798620866,-0.03410805788156994,-0.0479690124671738,-0.04353937868249079,-0.034567377471565526,-0.035713846440109276,-0.03409503393748533,-0.031935203843743584,-0.0288979525435828,-0.03138647220955882,-0.051568856087160046,-0.03351683837059282,-0.05144600794466126,-0.0378314047502791,-0.054406177246279275,-0.046659953924752084,-0.04184614131254047,-0.032046485784213444,-0.03697050710369857,-0.05062851653719803,-0.04741342048952704,-0.04144570291269161,-0.04409084722657242,-0.03583398942164617,-0.03302879680316273,-0.04862241898551838,-0.03507762603744944,-0.050751463502320376,-0.04566194874625641,-0.03234546815971596,-0.04987764333487414,-0.045978019688028254,-0.031323780280349094,-0.03241133213802274,-0.048143357030049884,-0.047052735007020195,-0.031192552044387083,-0.03845827067599246,-0.038477775953855334,-0.04008191451590931,-0.04412076463809553,-0.051653803152927225,-0.04211537973081228,-0.05794972962528846,-0.028695649061293186,-0.04242016482015258,-0.051538976736433574,-0.05087562673338371,-0.04121410342572152,-0.03522092309467217,-0.039711531900928174,-0.03700667929921899,-0.1248463553433289,-0.0373594965179363,-0.04698896716275015;-0.049075348654140115;0.016291315045705773;0.0
data/model/LunarLander-v3_929223_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 929223};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 929223};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, ang_v, leg_contact_left, leg_contact_right = observations
    altitude_reward = -abs(y)
    velocity_penalty = -(abs(vx) + abs(vy))
    angle_penalty = -abs(angle)
    angular_velocity_penalty = -abs(ang_v)
    contact_penalty = -10 * (leg_contact_left or leg_contact_right)
    return altitude_reward + 0.1 * velocity_penalty + 0.1 * angle_penalty + 0.1 * angular_velocity_penalty + contact_penalty";-0.029070859393072915,-0.05245378721706796,-0.06548919906880438,-0.054740096490444895,-0.03433871286634204,-0.04637861753761144,-0.02900624804116832,-0.07534096915683444,-0.04301600162669763,-0.09358158759202274,-0.06094334399334841,-0.03737672670788695,-0.043940783872465694,-0.03951474535634652,-0.04321716586760514,-0.028954384243597267,-0.04090060109736209,-0.05163351875096986,-0.03895007256737998,-0.03467813271658488,-0.05670959961895134,-0.044456497455054395,-0.03374011607910301,-0.06240314560577207,-0.046151886802883686,-0.05431681360552044,-0.038969631128660934,-0.0489095771491031,-0.052551464169628734,-0.07347690424059236,-0.03473553865029155,-0.0405003907367175,-0.04216117913781786,-0.050633006084903474,-0.03937073253041253,-0.03372463372312305,-0.05544122109749802,-0.04094450714048667,-0.053209902573469206,-0.03361461103321783,-0.03152689727721466,-0.031983887498306635,-0.03583941189063343,-0.03498612224118089,-0.03578597918991516,-0.04599686013056863,-0.050642909116177796,-0.02748958129096066,-0.04464032999516164,-0.03367449059209592,-0.03443517103532214,-0.03394924952851373,-0.046412698849302145,-0.03478282781979695,-0.03724031469921388,-0.06258872321653014,-0.048296530932263125,-0.03449352657656645,-0.05450976001180703,-0.03163143357672497,-0.0293492760791579,-0.035189827569712596,-0.0520171876151107,-0.04369893748287025,-0.03876157950520142,-0.04615359333171851,-0.044276221199715,-0.04287001957091088,-0.04956097001761826,-0.03743841646452009,-0.032131144111964244,-0.04723348773840448,-0.03043575805303659,-0.05523894620707082,-0.039366924062260104,-0.05536371223219115,-0.04564398718236328,-0.04024864320011431,-0.028505082583779047,-0.04326969819153209,-0.06171688301988778,-0.048373481557906876,-0.03687399017187907,-0.038277677018562155,-0.04626355004945451,-0.037695840040092576,-0.03815450173124155,-0.050858360425717626,-0.06216313928812151,-0.05580643791591096,-0.038720800647959755,-0.062155775985515506,-0.03916358348776523,-0.05316378163210166,-0.06575246781054471,-0.05397710406927855,-0.039155239572871814,-0.05098424237059411,-0.040080845574300965,-0.04453583482976134,-0.048604121945901364,-0.0641696865947377,-0.04504944244184398,-0.05206648190689188,-0.053523670578326514,-0.04743049631506114,-0.0546933188650513,-0.051553958267682345,-0.05003029030238284,-0.05443577964119119,-0.0504310141028256,-0.06374978982818096,-0.05856367153875569,-0.060226236591956424,-0.043155547370507384,-0.052314448559863114,-0.03932683747884289,-0.05828159373987321,-0.04727206898697635,-0.07888405889700137,-0.03306781545735055,-0.18819741633003415,-0.04682792294883309,-0.06984019216974868,-0.04358947161086337,-0.05753195842185296,-0.07188308223910236,-0.0719366557402119,-0.06789394453351502,-0.056532127780342924,-0.043428425928805615,-0.09318626096480821,-0.3203140733344349,-0.046104995676124354,-0.09495959848041821,-0.05059789825904997,-0.09601871569069993,-0.050542078072691586,-0.058629809877441375,-0.06296081279444458,-0.08266395563293114,-0.057519049562882035,-0.06276417399082569,-0.07021265494949504,-0.047151250831474534,-0.07516878803039358,-0.06498135281299693,-0.06337919285203783,-0.05590340719505057,-0.04474295999932231,-0.04649954388427322,-0.04500628460671121,-0.04516047855882426,-0.06561927041201306,-0.11542064734235265,-0.06385972420879338,-0.050174829746561116,-0.07469748263654805,-0.08227638343352643,-0.05680127849996782,-0.056284943246451696,-0.0501911944817318,-0.05308451667032964,-0.041316819752752997,-0.05019003999161014,-0.045300046571238824,-0.07621054556708144,-0.06546565690535903,-0.05588899664414965,-0.05636189939356746,-0.05247975431737878,-0.04130341053536176,-0.06934253108843845,-0.06477306814573316,-0.09573141361432091,-0.043274190100295734,-0.06905532695395128,-0.04627115311070561,-0.15748410371138283,-0.04695269101238724,-0.0596455772800872,-0.03661720584801201,-0.029457341175983854,-0.05202973791528484,-0.04821167334172155,-0.054866037732619055,-0.04156693456667156,-0.05855430574042728,-0.03242108377325495,-0.10932448711612813,-0.02553181253523834,-0.06275246897263062,-0.03176137995309139,-0.03588176559502682,-0.04951643340183424,-0.04525543951814483,-0.02932901839217409,-0.029684059457422612,-0.03018715141178301,-0.03872540308323192,-0.04880591238568595,-0.042028305673257466,-0.03017706076465825,-0.026047997835395638,-0.05449954485463191,-0.03499146433101666,-0.04429795295984894,-0.046920607765537574,-0.038017536473356796,-0.04091072310325034,-0.029897979429238566,-0.05420563691083494,-0.03818239874304289,-0.0280578208195195,-0.04481822008384751,-0.02324291863054997,-0.03180809386743565,-0.03202029394354399,-0.06263847648709599,-0.04755962230460668,-0.048119234010690515,-0.023449282533580876,-0.038052851991064465,-0.05703305014450629,-0.02761377931249116,-0.043101972361984604,-0.02395973502695632,-0.02400571640698061,-0.04077491544738203,-0.030823593161870517,-0.035715697691656695,-0.05579894932670837,-0.029163146954997346,-0.028128088271427237,-0.030512602845708524,-0.0547028055990335,-0.02922737959216286,-0.03153043972118813,-0.05790498227622712,-0.035245391039026845,-0.06812898362759719,-0.034797482126272025,-0.04000761044823952,-0.05936910302730052,-0.05392004308197024,-0.030735189107586814,-0.029013379087936088,-0.04311480369195141,-0.027887077673959287,-0.0282973244148517,-0.06638407244281488,-0.03524306153740771,-0.04927284282091236,-0.0350618115159494,-0.02304350584396,-0.02462226781641514,-0.03161934953545628,-0.0214992148038411,-0.029586324994762454,-0.0335110726298582,-0.02870619730844531,-0.02770389217956915,-0.02582098676748286,-0.03574278389784713,-0.06383873398177971,-0.062251656843770944,-0.02697481794399845,-0.055959304841894285,-0.025727620971133482,-0.05866451418475599,-0.0628027885052672,-0.02611324854749373,-0.03839160758024572,-0.04612950050564559,-0.023286704611635248,-0.03254208946466863,-0.03521671823471323,-0.032098447878943025,-0.030674798684074855,-0.053105942082980216,-0.02928246360128593,-0.038546115976478446,-0.05816697951489238,-0.031544217980750106,-0.027573440385812196,-0.03695745313109068,-0.05392103948212747,-0.06410577957025364,-0.021608455488864295,-0.02987030490934874,-0.04400376497978167,-0.049253092624012305,-0.0593606223660439,-0.027035620279600346,-0.026912925897075286,-0.058439640697348305,-0.04653399342732905,-0.033265538445108794,-0.030059284831747156,-0.05426512190429525,-0.03999121287544159,-0.02922259794030119,-0.023786531006428406,-0.05733657387741516,-0.030146449632463466,-0.08377751264158351,-0.035207637120512635,-0.027670815216214624,-0.025081029396531417,-0.027315644330709977,-0.031352039190400895,-0.06510141192882916,-0.03108028126823512,-0.032909163775927286,-0.023997840698068103,-0.02547699371664903,-0.07613392193591463,-0.026207771671784407,-0.054564743766529276,-0.04022420175046829,-0.09700202568254625,-0.03466537893846179,-0.030578738660619,-0.02532789672842192,-0.026112449070321776,-0.05513185994675379,-0.038841558192887204,-0.0631781328510404,-0.026119114920225235,-0.04094079853275206,-0.05340504475554812,-0.0490456228620667,-0.042550708070962076,-0.07189020255126063,-0.03908579148000319,-0.021633940205515807,-0.06255029244662778,-0.03636241031611054,-0.02772984851101108,-0.027874414397730085,-0.026631914889980825,-0.025442037031813275,-0.04125126595923359,-0.03089335494515218,-0.029435808114613674,-0.02864518057756821,-0.03909042958501234,-0.04269290055836099,-0.029274790057045672,-0.024551608848175508,-0.03151932209168887,-0.027742895880703902,-0.03029185820886755,-0.032546026759554814,-0.03422104533585717,-0.0402905372291154,-0.03341007212799932,-0.028802221085464416,-0.03928079584796785,-0.02301967644977205,-0.02206850693508976,-0.031241814073168075,-0.026407310247442042,-0.029725586088703793,-0.03911959746038011,-0.052051421598071995,-0.029845927524765784,-0.027685457337765937,-0.052614595572897466,-0.04187745442144267,-0.04025262713345281,-0.033740704723976535,-0.04906415438387417;-0.0463004693824056;0.023178258830680216;0.0
data/model/LunarLander-v3_797934_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 797934};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 797934};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    reward = 0.0

    # Reward for staying within the desired x-coordinate range
    if -2.5 <= x <= 2.5:
        reward += 1.0

    # Penalize linear velocities
    reward -= 0.1 * abs(vx)
    reward -= 0.1 * abs(vy)

    # Reward for angle close to zero
    if -np.pi / 4 <= angle <= np.pi / 4:
        reward += 1.0

    # Penalize angular velocity
    reward -= 0.1 * abs(angular_velocity)

    # Reward for having at least one leg in contact but not both
    if (leg0_contact or leg1_contact) and not (leg0_contact and leg1_contact):
        reward += 0.5

    # Penalize failure
    if is_failure:
        reward -= 10.0

    return reward";0.03390277735834509,0.026487598345657195,0.04296656676836278,0.04225805381692617,0.026730609804561423,0.024131160528867525,0.04144832219581156,0.04313815919128592,0.03324505876337665,0.023395824623238182,0.04890349382331885,0.03998277407365148,0.03093353150072734,0.027373869993470298,0.021545211733904758,0.02059348513822616,0.02048325426182275,0.025879747767919372,0.02813401300506562,0.014751054233618107,0.025751129721151792,0.018868072670605394,0.01353148830913328,0.016134134944674514,0.026141342298231885,0.03792388075455018,0.05175324187634785,0.03689814935794333,0.02173259965014178,0.01627548950820374,0.019636790314562523,0.0282277051952792,0.017054527780313713,0.021902005611276292,0.026932476232303135,0.01938976825954378,0.025597748837616546,0.025194378495691123,0.02403747579677919,0.03486985107229161,0.02850977504218945,0.021269771673627105,0.02111799454469,0.023033812949828758,0.020239718837411227,0.01996647344858598,0.021247265857379995,0.03642540181718177,0.039936951208992835,0.033387557454852605,0.02007622581682705,0.029863401369193233,0.03330940104055111,0.02302999121176869,0.04096080063859436,0.03050887077361449,0.03906307700522808,0.03400996713765583,0.03687171867823449,0.02384043247135316,0.03350336447518118,0.03223700551420995,0.022117106632573876,0.024056392121845276,0.048745128822126726,0.024614227280594984,0.021342807247518893,0.04147220417215915,0.045702999244345795,0.02131578572968839,0.02604390330908618,0.026470392694071126,0.021181703668544685,0.0225704732399911,0.02402734379764047,0.023334001918359944,0.02486378207772805,0.04500977185659255,0.05614043572451554,0.023057462307106796,0.045178002654817695,0.03818547883498757,0.027626174584203363,0.02760957208165586,0.031263635825574405,0.024633164906410335,0.022355081953039768,0.03514232023633303,0.030069010387251283,0.030413044629104415,0.03477393156522328,0.03054628594051315,0.027898389255825173,0.11218469152312499,0.042717059897915556,0.0327039606826743,0.06749904747066933,0.03304427301941451,0.04701561540198732,0.0739635135199061,0.029279313079923583,0.04613444154024474,0.05428779890612676,0.04395714228036463,0.044287814310261575,0.028719155881833998,0.03914925348087204,0.03428027046785196,0.03505354395270762,0.15310255554858568,0.04662797348750865,0.04167997586044314,0.08301059853306632,0.11561652867272228,0.03743420868055873,0.05146944635381698,0.05173385043577908,0.060748429217214225,0.10443743520368967,0.028951256418434473,0.042915590926075296,0.08968247942577687,0.07235088541326656,0.049862326466334296,0.043703193144384894,0.08211967645786224,0.045276324651636425,0.030110321658737175,0.04744207778884518,0.0722155850294292,0.08037323735929137,0.04338562763156288,0.0235822680344777,0.08685129720887247,0.07357177771021348,0.0850678499766721,0.03155130081244091,0.08957576894195456,0.07270154060938516,0.06446338301384978,0.05960076351378151,0.07218866995808493,0.06052440325355111,0.10809869195868953,0.030985849776928975,0.056065383479283366,0.16391628512447878,0.05348351115815561,0.04626779035745117,0.03717687776433331,0.08472976199357758,0.055690385434759064,0.08000667009549627,0.04823183178365076,0.048562503097796715,0.05819215372589982,0.0398229865603252,0.09224767757621118,0.07174366220558058,0.047168749036502915,0.05499843935578601,0.06076443584275315,0.06905886976016748,0.05740751196817713,0.08715722163318267,0.03641173060121109,0.03112565747374821,0.03784139151304152,0.05172696685816284,0.05081280935878937,0.04391331847957219,0.06596773169619669,0.09893871331800298,0.059018292120298056,0.04683029962779189,0.04940247818979295,0.05794053822442589,0.05129012110042095,0.042407129758912546,0.05420771327094003,0.03226967110073393,0.02746828205023529,0.07441046722755368,0.10328102373899256,0.044756203356985706,0.052991637806330184,0.08323288682512232,0.07127532549456835,0.03246202803228208,0.11134727813252787,0.03486027687220916,0.07921463807287878,0.035090855822424376,0.052571275822362686,0.07083258389556711,0.056441195089320294,0.11197422921237479,0.13333651840001678,0.03980250434388798,0.033218991212771644,0.04552169545482178,0.094300343382205,0.04689822150446879,0.03248389184852725,0.08568549835509955,0.051822375662589605,0.04188611681031693,0.07804520626752512,0.029751382976284237,0.21729314544949901,0.17848302234282348,0.1980323033532061,0.061870666950805564,0.30931423259069163,0.05490826390782351,0.0696433000209419,0.04281981857740912,0.11912179955416831,0.11835858136857601,0.1984818785417749,0.0336076416776458,0.05858350952908041,0.07395198875524409,0.11160149781522177,0.13002797408124162,0.1271504761908116,0.13762187379541505,0.048347490987086274,0.04512196479253632,0.07458826727286447,0.12790669060988255,0.12696479675785657;0.0532463674615071;0.03840793120880589;0.0
data/model/LunarLander-v3_201384_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 201384};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 201384};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    altitude_reward = -abs(vy)
    horizontal_velocity_reward = -abs(vx)
    angular_velocity_reward = -abs(omega)
    angle_reward = -np.clip(abs(theta), 0.1, 1.0) * 10
    contact_penalty = -10 if leg1_contact or leg2_contact else 0
    failure_penalty = -50 if is_failure else 0
    return altitude_reward + horizontal_velocity_reward + angular_velocity_reward + angle_reward + contact_penalty + failure_penalty";-0.07149060055828817,-0.08167492334657049,-0.1106055261180373,-0.11858202798792773,-0.03772815211773773,-0.05557231543175953,-0.04672082527270097,-0.03203126693844291,-0.03597857663560792,-0.10995600083860442,-0.09445274199437903,-0.055965794304030474,-0.04988897442531405,-0.058233988190716596,-0.06042050892447592,-0.07082158618935605,-0.09587569159931253,-0.04972408735999702,-0.12881685708553625,-0.08686127180840328,-0.05259800983977642,-0.16662182264462636,-0.16247395534051984,-0.04175127901450092,-0.15955652359436193,-0.1624047866867659,-0.13863436308937271,-0.07344970700303714,-0.11607486926077465,-0.1953706348229095,-0.1795526231229476,-0.15921980501988314,-0.059743822827332316,-0.1667275988156156,-0.16641187483171238,-0.17782571905617794,-0.05683613089008156,-0.17618329331563978,-0.16416756986454628,-0.05457244071744585,-0.16156751817270737,-0.17823331522638064,-0.3350240079783132,-0.17100803557178956,-0.18150634814417876,-0.2012640418059454,-0.19835988348027692,-0.16745382700135727,-0.171286011766192,-0.1911589878050139,-0.1720742244528902,-0.17848088723212208,-0.10788817539761297;-0.12258271341358502;0.06197905211008611;0.0
data/model/LunarLander-v3_359362_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 359362};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 359362};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    z = 0  # Assuming z-coordinate is not directly observable but can be inferred

    reward = -0.01 * abs(x) - 0.01 * abs(y) - 0.01 * abs(z) - 1 * abs(angular_velocity)
    reward -= 0.01 * abs(vx) + 0.01 * abs(vy)

    if is_failure:
        reward -= 50

    return reward";-0.08879937220947565,-0.07510653380800361,-0.06483587964820482,-0.0614573614635087,-0.06021118294445731,-0.05491470039013571,-0.06023986733081985,-0.08198480925317388,-0.06656784629563413,-0.07562565481169162,-0.06406628490377039,-0.06828442206885271,-0.09617721147134212,-0.05452581635778197,-0.06350209928968444,-0.05837662928714609,-0.06168381040043474,-0.06996769165902984,-0.07377173872471922,-0.06095053583808378,-0.06299358259832948,-0.0672161445100465,-0.06260684287914657,-0.06795134864780865,-0.0639384442908805,-0.06264862242336726,-0.06147462985152831,-0.0641507249454529,-0.06887224615984791,-0.06039441537004505,-0.0584058636986752,-0.06021137739721393,-0.05588303950721049,-0.055465788662025964,-0.07096162082875902,-0.06045972668563118,-0.06080987388871696,-0.055661654548637855,-0.05637945560005562,-0.060631660766267303,-0.05743974659104164,-0.06222095972859816,-0.06237789850379405,-0.06453030044665309,-0.06308613380663215,-0.06810818269252046,-0.05548910587314423,-0.05491184882994492,-0.05547804320868567,-0.06047561125376433,-0.06177595575171833,-0.06362395442339637,-0.061378414242259684,-0.0600410573346251,-0.05293247914389725,-0.061240858880566545,-0.061282474100566815,-0.06039726320527697,-0.05936356157708772,-0.05874677971372142,-0.05316507456754147,-0.09252433393614064,-0.057849013626389056,-0.06503832613666939,-0.05835381358984135,-0.06433367365754389,-0.06147330226011562,-0.07762863747031196,-0.05894543846369283,-0.05444728101683015,-0.061025265637911046,-0.05794577191554543,-0.06975198075177172,-0.12365206481232498,-0.05875932907120959,-0.07739731246645491,-0.07340985942404646,-0.06299189173233453,-0.12588077951164767,-0.07412252218759137,-0.07372524000982568,-0.06527760295747936,-0.06805765310311729,-0.06172376430746217,-0.06694403095752083,-0.07328120346465285,-0.06422313572434415,-0.06049661222061519,-0.08581519815548007,-0.09825830221289933,-0.06407174809457114,-0.059655670120261794,-0.057184772972912364,-0.07573148267967353,-0.06672359480866365,-0.06898406272465474,-0.07507707593678016,-0.05983264535488579,-0.10855894761141212,-0.07919152661482583,-0.07431188971574282,-0.06786724209131444,-0.05830151804106611,-0.07572371627682294,-0.05920478071209616,-0.08426589082531193,-0.06798869178095732,-0.057719261533147784,-0.07155588890241042,-0.05895829388629956,-0.057239677943668806,-0.05683753561950427,-0.0937611500340578,-0.0898091295936712,-0.07329067860246338,-0.05701392548342766,-0.09734765591100922,-0.08099590151673232,-0.07425867921635286,-0.11998802926464879,-0.05796916840559781,-0.05741818882365381,-0.057743521042076966,-0.06765170876845764,-0.08800887193636418,-0.07826171444936372,-0.09318941634810685,-0.05767561985517163,-0.061921516163081794,-0.08027016139422355,-0.08480792029338309,-0.06792163833658002,-0.07094791557178004,-0.05702889298667922,-0.06722625626640544,-0.09389697913657388,-0.05773674245777251,-0.06632078355214267,-0.08642284697464425,-0.08935796653229403,-0.10254408659687321,-0.05836825279171459,-0.08726042387782645,-0.06556404601665092,-0.08989641021593157,-0.05804849584546073,-0.07935931057929159,-0.05841439303233655,-0.0627335991328707,-0.05616527092439235,-0.0673432026741633,-0.060324850549425005,-0.0628197395327935,-0.06700264279489554,-0.07409664714241622,-0.09418461925570483,-0.08357527956044832,-0.058069204258694225,-0.06219856719858038,-0.06752922236212525,-0.06371225559189524,-0.07310984175146235,-0.06854798462932811,-0.05860769564833882,-0.06670708939536578,-0.06458411550864362,-0.10533631764205316,-0.06069471402056545,-0.07170879243068445,-0.0570749764868441,-0.06381661902784455,-0.06509813162109285,-0.05672922259573881,-0.06518077944277022,-0.06186919577564173,-0.05840840990006018,-0.06179994279770375,-0.06298748420067155,-0.05929189325434614,-0.08420313899184577,-0.062157581413479455,-0.0636116760489586,-0.06175947566104031,-0.056699788592934446,-0.061950238301673635,-0.0622989259515167,-0.09154396973716022,-0.0581719522779849,-0.07101789581920943,-0.09718679691322979,-0.06562694064207585,-0.06004105722251197,-0.06793135703923978,-0.06602188077367065,-0.08332904015525845,-0.061562474395378215,-0.057868016023406105,-0.0676210321055452,-0.09036388877656337,-0.05901334970714628,-0.06558833674348225,-0.09855571946244979,-0.11335586814238052;-0.06882285012905562;0.013766759767562795;0.05
data/model/LunarLander-v3_405168_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 405168};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 405168};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    # Penalize velocity in both x and y directions
    vel_penalty = -np.abs(vx) - np.abs(vy)
    
    # Penalize angular movement
    angle_penalty = -np.abs(theta) - np.abs(omega)
    
    # Penalize contact with the ground
    contact_penalty = -10 * (leg1_contact + leg2_contact)
    
    # Reward for maintaining stationary flight
    stationary_reward = 1 if np.isclose(vx, 0, atol=0.5) and np.isclose(vy, 0, atol=0.5) else 0
    
    # Total reward
    reward = vel_penalty + angle_penalty + contact_penalty + stationary_reward
    
    return reward";-0.06223604555674841,-0.033204409258507615,-0.05986135317616077,-0.05158211003549919,-0.06365385028851737,-0.053036498696051246,-0.07204246358680683,-0.03330320216822444,-0.08454646120083907,-0.05555696681991372,-0.048485280799299424,-0.02629318621440297,-0.02032679620126953,-0.047910967927588956,-0.04703052409117409,-0.06013259950507042,-0.06147143414589264,-0.032853693095563054,-0.07872806310920993,-0.059730470171553175,-0.06752548738720522,-0.06131984223353018,0.14177794020798068,0.16158990182900607,0.19466539067443062,0.1555091350704935,0.20164202408902446,0.20978210376359627,0.17372367204153522,0.18578587843646222,0.19677146356064404,0.16874334949084369,0.18402718571457366,0.20706296214144665,0.19113630141031712,0.2182669224006135,0.18303816090702166,0.18247067139837775,0.14695251385898137,0.17477674369388413,0.22495915074114597,0.18263142198383292,0.16799798546504846,0.19281965544912041,0.214898076949351,0.22267137798619124,0.1771647269776065,0.012922660985698442,0.222129502908346,0.011541508643415107;0.0745325336621992;0.12018694365817423;0.0
data/model/LunarLander-v3_203694_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 203694};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 203694};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    vx, vy = observations[3], observations[4]
    angle = observations[5]
    leg_contact_0, leg_contact_1 = observations[6], observations[7]

    if is_failure:
        return -1.0

    if is_success:
        return 1.0

    reward = 0.0
    reward -= abs(vx) + abs(vy)
    reward -= abs(angle - np.pi/2)
    reward -= leg_contact_0 or leg_contact_1

    return reward";-0.03853865104890844,-0.0370273868989354,-0.04491027458435531,-0.04170322600018397,-0.052590030482497295,-0.03788235488016449,-0.04434449401602865,-0.033162927249308256,-0.03488861406408273,-0.03599446016636581,-0.04250265409734261,-0.0484124548544853,-0.054093110013877184,-0.047569517329773575,-0.05421002892188751,-0.07800182124913635,-0.05410833277560106,-0.031130484664800128,-0.028133734614917232,-0.04895685261283444,-0.04096692012055048,-0.033118511736621906,-0.032740690238798,-0.07289808590715897,-0.029826668426766158,-0.0653943531264869,-0.07210266534354176,-0.024916407457789398,-0.06083165630477288,-0.06218505785387234,-0.06618997427724153,-0.10755389630111065,-0.050586872320435204,-0.06925151005426228,-0.07061247292957634,-0.07451687098931035,-0.05815193619440054,-0.0808608703143885,-0.06675827612172221,-0.07249184050784226,-0.07049665258577911,-0.06382988479494461,-0.0793980133242816,-0.06404238755705895,-0.05933914560705197,-0.033722220343515324,-0.0502620852393003,-0.034356909683245875,-0.032038800212195684,-0.061584680339630375,-0.06271848527453414,-0.061095772788951064,-0.06207625726459677,-0.04832244633742033,-0.05636181443266354,-0.0639657689345675,-0.02788852573307154,-0.03255438819922079,-0.06480581694540964,-0.058615483622502795,-0.046758649422875866,-0.027314327429797655,-0.06223864200850367,-0.0407297786590111,-0.06965425496459536,-0.042268917961795244,-0.031507612089618414,-0.051254322868135214,-0.05531333499085945,-0.033256408808224135,-0.025445439768119058,-0.029816593990646928,-0.043047291664102906,-0.037105455855075874,-0.03355003064971879,-0.03295947424328982,-0.04821889538567463,-0.04666803732105555,-0.0263732697613433,-0.04899977665026857,-0.03840929595174818,-0.041016972537201137,-0.04600913148281215,-0.057263503330549234,-0.0656422818931028,-0.03853963868015191,-0.07732588629808265,-0.06008417335138101,-0.07026081394167369,-0.03973844055903322,-0.07845839029708733,-0.2715478867423306,-0.2710778676488813,-0.26623003606584916,-0.26649504792786927,-0.26826584331967784,-0.2645412590301135,-0.26614642030604935,-0.20328848569362618,-0.19325390936738132,-0.04971750435135399,-0.02537091767982746,-0.1429544744966171,-0.06597738969745526,-0.11726151349846055,-0.09692234206442212,-0.04372643346831332,-0.027256943408764764,-0.035592528001517465,-0.0468271058112202,-0.08906511442212066,-0.03769913118685052,-0.06808112435676154,-0.024053199459372773,-0.030134750077284167,-0.05099550474742144,-0.032133499201776466,-0.0272819512769742,-0.025960238480352407,-0.030189359164103282,-0.030300387820445814,-0.02743926425628906,-0.026274842461878688,-0.032817255984339766,-0.041484442383637486,-0.0328794652888937,-0.03507087082303706,-0.04919192820725301,-0.027345101407166478,-0.03228226463963375,-0.021144958925163063,-0.024385221177952485,-0.024527327417685967,-0.025471714549421355,-0.025639302513198327,-0.022857624878367525,-0.024059638789475812,-0.02955462379465829,-0.02616379681353032,-0.02718180755215268,-0.032010810188769764,-0.023469136986353282,-0.02931675245275852,-0.02875755679102328,-0.03207763030126419,-0.030690792616292116,-0.032861182297953914,-0.026900247144610697,-0.032250631731887594,-0.033367728908502425,-0.028031864572132668,-0.028421696450302656,-0.03231994947526763,-0.02940469296900331,-0.03188909276546678,-0.02267756396761977,-0.032555589025825185,-0.02755483963200212,-0.024883429252594687,-0.026043959450928134,-0.025409412312561518,-0.02410040598660719,-0.028220707207541763,-0.021902231077863817,-0.02363865565709504,-0.034898935660177294,-0.033554752584601576,-0.03443145972299913,-0.03364646612143049,-0.024194514891930415,-0.02336411890292537,-0.03427566089434153,-0.03064332343066608,-0.029452243855917697,-0.06132157423968978,-0.030772679303717018,-0.03375602182691074,-0.03472380444843851,-0.026067501331894113,-0.02809058642266635,-0.024209011226007417,-0.02604361949442776,-0.02429060522807147,-0.027573769289027116,-0.027388355333919444,-0.024086499891965877,-0.04180965154930098,-0.027903570854624783,-0.02442640434947337,-0.023582126182657148,-0.026185028324825714,-0.02772881051862987,-0.03214411059303911,-0.024411275354137882,-0.03149690854194055,-0.04100193501937654,-0.027086162616055082,-0.024806571073856545,-0.03243743569514412,-0.0332266824190509,-0.033476270893415164,-0.027003056383663186,-0.03031555054762851,-0.03095137844873658,-0.033759199894523306,-0.03075215627759657,-0.02597991665851132,-0.022798926847677644,-0.029522385924950843;-0.05069516137807325;0.0470604888209464;0.0
data/model/LunarLander-v3_165729_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 165729};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 165729};100000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, dx, dy, angle, d_angle, leg1_contact, leg2_contact = observations

    altitude_reward = 10 if -0.5 <= y <= 0.5 else 0
    position_reward = 10 if -1 <= x <= 1 else 0
    angle_reward = 10 if abs(angle) < 0.1 else 0
    angular_velocity_reward = 10 if -1 <= d_angle <= 1 else 0

    crash_penalty = -100 if abs(x) > 2 or y < -1 else 0
    landing_penalty = -50 if 0 <= y < 0.1 else 0
    angle_deviation_penalty = -20 if abs(angle) > 0.5 else 0

    reward = altitude_reward + position_reward + angle_reward + angular_velocity_reward + crash_penalty + landing_penalty + angle_deviation_penalty

    return reward";0.018500181699648403,0.02419254529954022,0.019448908966297036,0.011147545383121472,0.014942454449716017,0.011384727199783631,0.020634818049607834,0.01873736351631056,0.01861877260797948,0.03344263614936442,0.011740499924776871,0.01185909083310795,0.020634818049607834,0.01636554534968897,0.020516227141276752,0.007945590858182326,0.011384727199783631,0.015298227174709255,0.013282181733080904,0.022413681674574026,0.015298227174709255,0.025259863474519934,0.01861877260797948,0.017432863524668687,0.022413681674574026,0.027750272549472602,0.027750272549472602,0.010435999933134996,0.03427277250768197,0.08455531764005968,0.02632718164949965,0.05170563603235066,0.02182072713291863,0.07388213589026253,0.020279045324614595,0.03225672706605363,0.03154518161606715,0.057635181448904636,0.03830486339093868,0.09392399939821497,0.03723754521595896,0.12214863558101188,0.09475413575653252,0.09475413575653252,0.1191838628727349,0.12179286285601865,0.03960936338258055,0.12297877193932943,0.1445623172555859,0.1799024079382476,0.019448908966297036,0.16970358982177478,0.1666202262051667,0.017670045341330844,0.12345313557265376,0.022057908949580787,0.11574472653113359,0.04660622697411424,0.022413681674574026,0.06605513594041128,0.12131849922269433,0.05253577239066822,0.020753408957938913,0.0190931362413038,0.04411581789916157,0.019330318057965958,0.053247317840654694,0.09036627214828258,0.08455531764005968,0.0190931362413038,0.022057908949580787,0.046250454249121005,0.024785499841195616,0.07328918134860712,0.02786886345780368,0.019448908966297036,0.12238581739767404,0.021583545316256468,0.050756908765702026,0.06048136324885055,0.11384727199783631,0.13898854456402518,0.06048136324885055,0.029173363449445558,0.05336590874898577,0.053840272382310095,0.07008722682366798,0.09167077213992446,0.12179286285601865,0.05751659054057356,0.24690627114530753,0.0902476812399515,0.1266550900975929,0.13626095367241034,0.07139172681530986,0.06036277234051946,0.16460418076353833,0.05573772691560736,0.1023439538897216,0.11194981746453905,0.05692363599891816,0.09522849938985684,0.08645277217335695,0.053247317840654694,0.18381590791317323,0.043167090632512936,0.21097322592099044,0.036288817949310326,0.09499131757319468,0.04542031789080345,0.044708772440816974,0.06463204504043833,0.04079527246589135,0.13637954458074142,0.06747822684038424,0.11301713563951876,0.054670408740627646,0.20077440780451758,0.2070597259460648,0.07826999949851247,0.04435299971582373,0.11586331743946467,0.060718545065512705,0.14017445364733597,0.06985004500700583,0.05644927236559384,0.06036277234051946,0.12878972644755235,0.06747822684038424,0.04648763606578316,0.04897804514073583,0.13151731733916716,0.21607263497922685,0.10198818116472837,0.0942797721232082,0.049333817865729074,0.07838859040684355;0.06785823712328456;0.05190885981711394;0.0
data/model/LunarLander-v3_901644_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 901644};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 901644};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    if is_success:
        return 200.0
    if is_failure:
        return -100.0
    reward = -np.abs(vx) - np.abs(vy) - np.abs(angle) - np.abs(angular_velocity)
    if leg0_contact or leg1_contact:
        reward += 10
    return reward";-0.043820530697188664,-0.057924184554072305,-0.06756819816717496,-0.06137793720492859,-0.044341477553894094,-0.03532528685627042,-0.06445130920559207,-0.04509480700367654,-0.036097946683491366,-0.041318842683554055,-0.053464545488408774,-0.036349902499358,-0.04596822971182648,-0.05844005855482584,-0.04532699769909181,-0.03853360372313202,-0.05100066770542589,-0.060398847566457387,-0.036316506792624006,-0.07496498578035984,-0.06048774808581162,-0.056414550348326334,-0.0713940576862898,-0.06258064574433904,-0.04576287257651951,-0.05186153163142958,-0.05120841323825052,-0.09180851870724223,-0.04634833369880661,-0.04919263515094118,-0.04984791014113792,-0.055421463563002885,-0.047026391436560094,-0.05357036131804996,-0.04397413049958038,-0.08039321214649664,-0.050370919233543435,-0.04414153669577731,-0.04828314694813062,-0.07075532707094487,-0.054407744285186854,-0.08447047563690362,-0.04341174055156549,-0.05228424825158412,-0.060043071749850296,-0.04736300029313726,-0.05078378884574365,-0.051129670824595706,-0.05541481567114796,-0.05984051402410668,-0.06517649085222926,-0.05387003969729475,-0.09193469043611403,-0.062198229993804616,-0.05421067350969062,-0.07142739759517214,-0.06278794229402422,-0.050024780626102355,-0.06061559494160468,-0.060297954479987204,-0.055794637867159186,-0.053658592283801265,-0.06778467568273788,-0.05678479948882127,-0.08026538755491452,-0.06088448108875581,-0.061198902359152436,-0.061443739058639785,-0.07616304824570257,-0.06994912287402982,-0.06072881126330764,-0.07314165172996359,-0.06483024155476265,-0.058878837085330975,-0.061381407785797405,-0.05791202508600173,-0.05119383551916596,-0.05740166475740844,-0.06147887469759097,-0.059738100865698876,-0.0814462732684033,-0.05263583534484214,-0.05365936662506128,-0.0685666073414588,-0.08505661278544457,-0.06010558281740655,-0.061810881032157435,-0.051306126382482886,-0.051041530980339006,-0.06334547774426702,-0.06404165056945242,-0.07458509769481647,-0.06037952395435837,-0.06274214036840917,-0.07921976830423628,-0.0738116399168617,-0.060085514923714396,-0.078806491121566,-0.06317904491165716,-0.06328082624567354,-0.049906614620627475,-0.08571966230821407,-0.061889595854301434,-0.0525060136225395,-0.05016951296813897,-0.05890779277957609,-0.05900079495019538,-0.06468342490499542,-0.05284776030824624,-0.05930890935140187,-0.07015109043582422,-0.051880122807906465,-0.05870690091559625,-0.0709339569778708,-0.06757783457890272,-0.06240458181367932,-0.05014670156287512,-0.08219135870286166,-0.060736150652307586,-0.06719418818123252,-0.06950695256104189,-0.05579026282195739,-0.05622230394024826,-0.07289935090473698,-0.069184677081989,-0.05512781251328815,-0.07258597517823864,-0.06035433462504104,-0.06737051001100731,-0.07388316462926854,-0.06298768963456776,-0.059990309384814436,-0.07590995324916228,-0.04929259743920795,-0.058607446319375193,-0.04809069720876089,-0.050531688940957935,-0.054656194117755144,-0.07660405144485197,-0.055474025029927806,-0.07238646323145333,-0.07892606337516053,-0.06959717122300187,-0.0668119168557488,-0.06125380497114468,-0.0708027677675128,-0.0654635340042314,-0.06378504728050358,-0.07168774230314798,-0.07576266191820044,-0.06949233490966616,-0.058305414420780015,-0.061265886347699715,-0.05012748117742756,-0.08157476645121366,-0.07602313995299241,-0.08257063262951671,-0.04861153692746491,-0.06677144976111894,-0.058934665650518595,-0.0565762637926192,-0.07615665978598804,-0.08402383443775441,-0.04605400817279878,-0.06945690224963269,-0.09046814222119576,-0.060767913123031765,-0.06478238108095513,-0.08092545457909586,-0.08487045512400034,-0.05864838287908462,-0.06716914517410318,-0.09307198776236737,-0.05704791991736372,-0.09627754085403704,-0.06922126366094551,-0.06457291297547404,-0.07778968620870999,-0.08563181084354814,-0.0877922315828122,-0.0672423783806629,-0.06339131415927059,-0.10503402130779571,-0.09762621148725062,-0.06497047573243277,-0.09206115288313976,-0.07838613686363782,-0.06361983632946745,-0.0736701139039486,-0.06218454960555184,-0.09265350122705679,-0.05766838516535043,-0.06287579238029274,-0.06596148621717453,-0.09555916249405165,-0.0744154080065707,-0.07918033164709364,-0.05920288119554226,-0.0696849134585079,-0.07475005982155539,-0.0932241964672299,-0.08895399603765614,-0.07318335989180995,-0.06027543679413149,-0.06764144997031873,-0.0612212288866151,-0.05580736734379829,-0.08359716377966588,-0.05339044384434786,-0.07934932617535358,-0.08440548839140258,-0.11028799938794455,-0.07531568171685787,-0.06384141100260009,-0.0839407564693949,-0.049944916467912236,-0.1062980508228474,-0.0576132453452991,-0.06332895081807105,-0.05012153366351431,-0.05383057397599447,-0.09023760915176693,-0.0706891098873875,-0.06501756456875982,-0.09052149191533572,-0.05226197558065645,-0.0826677266671356,-0.05596658150615858,-0.06770506573873232,-0.04886433662886496;-0.0644494554777181;0.013931754217691186;0.0
data/model/LunarLander-v3_835591_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 835591};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 835591};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_position = observations[0]
    y_position = observations[1]
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]

    if is_success:
        return 50.0
    elif is_failure:
        return -100.0

    reward = 0.0
    reward -= abs(x_position - 0.5) * 2
    reward -= abs(y_position + 0.5)
    reward -= abs(x_velocity) * 0.5
    reward -= abs(y_velocity) * 0.5
    reward -= abs(angle)

    return reward";-0.05789836406174414,-0.03266644687932347,-0.036027198275735625,-0.05254167408212098,-0.04561411725066744,-0.05474865940605868,-0.04516055601746282,-0.065995370710997,-0.0387183460663273,-0.03271545594211385,-0.03929735946299811,-0.031696940189905876,-0.03664518674312905,-0.05673420171419925,-0.040179193821335245,-0.05692583669227453,-0.04211142470647797,-0.03808547942965097,-0.03970047363720285,-0.050214148053431704,-0.07430514500357577,-0.04209593864431018,-0.03447631192912779,-0.051678731111354397,-0.07386793944916034,-0.06954543600338997,-0.1558459653173779,-0.060135119621312655,-0.1952854970187139,-0.07675305359308372,-0.12061700089598411,-0.3086786502902021,-0.20141265179440995,-0.1960821085462796,-0.1612477982727905,-0.26918002997963625,-0.16134458261253176,-0.1178694808927165,-0.25983301427496475,-0.23061771656833643,-0.15926654324161568,-0.14414740389425573,-0.1301416617067324,-0.12551117371644963,-0.26333509427230817,-0.12307604992765205,-0.13932745500634225,-0.08906628227951638,-0.20836861751952496,-0.21933738310358683,-0.1340225961465376,-0.13525149593614816,-0.030867385708617693,-0.1413651417275571,-0.11275292495630401,-0.04240975857549612,-0.03592095319137656,-0.043812008215072584,-0.031945247230576644,-0.13202304509128035,-0.04230254041138518,-0.055717586301367895,-0.05335842499129011,-0.04180908910499268,-0.0310297881845106,-0.04003988255051117,-0.05199529551194338,-0.03699341658510818,-0.03044910051559772,-0.036585062271044855,-0.044745330920564055,-0.040554171922525174,-0.04324875015564971,-0.03569818277252444,-0.03983321601689064,-0.03911871732028877,-0.028485181573925017,-0.05390767779082621,-0.03070614047451544,-0.033641240688976136,-0.03546218787030758,-0.03469474724151663,-0.037569934978952974,-0.03791980855074398,-0.04382537739903405;-0.08466103151193365;0.06780277004435971;0.01
data/model/LunarLander-v3_474957_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 474957};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 474957};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y = observations[0], observations[1]
    in_box = -1 <= x <= 1 and -1 <= y <= 1
    
    if is_success:
        return 50.0
    elif is_failure:
        return -100.0
    elif in_box:
        return 1.0
    else:
        return -0.1";-0.045053218278472376,-0.05113960030409852,-0.04715197071188617,-0.045053218288896996,-0.051279517122568154,-0.04225488174228579,-0.0528885606131536,-0.04477338461025926,-0.04694209544769556,-0.052188976468682334,-0.05309843583564574,-0.04764167956089297,-0.0513494754848922,-0.045682843977222665,-0.04519313509694201,-0.04470342619581213,-0.05974448518727351,-0.044493550952470755,-0.049180764657880516,-0.046942095426846325,-0.04540301032985878,-0.05841527526065503,-0.0531683942709421,-0.059534609912658285,-0.049810390367055424,-0.052818602188281855,-0.054917354590421796,-0.0496704735590104,-0.04645238652571644,-0.05169926754670322,-0.05470747935750503,-0.054077853627480896,-0.051769225981999574,-0.05596673078627946,-0.04946059832609364,-0.04722192907421021,-0.05743585747924449,-0.05078980816931519,-0.054707479326231184,-0.05764573272258587,-0.05106964181667908,-0.049810390367055424,-0.049600515144563276,-0.05379801994884316,-0.05400789518175992,-0.04883097261691873,-0.05393793678816203,-0.04946059831566902,-0.058625150493571795,-0.048970889414539136,-0.04883097258564489,-0.03532899879541721,-0.050440016086654944,-0.05442764566844268,-0.05512722979206471,-0.04904084782898627,-0.05050997451152669,-0.05400789519218454,-0.054287728849973044,-0.04869105575675063,-0.047151970659763086,-0.05799552477397227,-0.04995030720637429,-0.050020265620821416,-0.05057993292597381,-0.04953055671969153,-0.04841122209896213,-0.04806143003715111,-0.057925566359525144,-0.04848118052383387,-0.04813138845159824,-0.05358814470550178,-0.057715691116183764,-0.04582276080611692,-0.05148939230336184,-0.05148939231378645,-0.05044001609707956,-0.0558967723509831,-0.056806231728371126,-0.053937936767312795,-0.048411222109386746,-0.049600515134138656,-0.05463752092220867,-0.05197910120449172,-0.05435768727484478,-0.050020265610396804,-0.05316839423966825,-0.048341263694939615,-0.05071984977571729,-0.05295851899632687,-0.05463752091178406,-0.044913301428728895,-0.05365810310952429,-0.05099968340223195,-0.05016018243929105,-0.0491807646474559,-0.03071174354615304,-0.05526714664180819,-0.049600515134138656,-0.055546980289172085,-0.05925477623402055,-0.0527486437529855,-0.032740537502572005,-0.038127335331603805,-0.05037005768263243,-0.047781596389787226,-0.05883502573691317,-0.05281860216743262,-0.05113960023112621,-0.04764167956089297,-0.05337826947258502,-0.053937936767312795,-0.05694614857811461,-0.053518186280630035,-0.05400789519218454,-0.04890093101051663,-0.039386586770802846,-0.05197910120449172,-0.050649891329996324,-0.050160182460140285,-0.05113960025197544,-0.05491735457999718,-0.05162930913225609,-0.052258934851855614,-0.049950307216798905,-0.0525387684992195,-0.047571721146445846,-0.020008106281687338,-0.044213717294682243,-0.05554698031002132,-0.05323835264369076,-0.056316522837665854,-0.05330831105813789,-0.052049059618938846,-0.04190508965962554,-0.0513494754848922,-0.05085976658376232,-0.051209558655997946,-0.01651018562187872,-0.047082012255740574,-0.04141538075849566,-0.052119018012536746,-0.05358814472635101,-0.045053218268047764,-0.05253876850964412,-0.050789808179739805,-0.05281860216743262,-0.04848118051340925,-0.04911080623300877,-0.052049059618938846,-0.04764167956089297,-0.05064989134042094,-0.05030009927860992,-0.04995030719594967,-0.050440016086654944,-0.051209558635148714,-0.05421777044595053,-0.051209558635148714,-0.04792151320825686,-0.0557568555533627,-0.052818602177857235,-0.045472968744305904,-0.0508597665733377,-0.05463752091178406,-0.0525387684992195,-0.047361845903104466,-0.05253876850964412,-0.04848118053425848,-0.0521889764478331,-0.05337826947258502,-0.04407380047621261,-0.04288450744103608,-0.03917671153788608,-0.04890093100009201,-0.052049059598089614,-0.05050997450110207,-0.0526786853593876,-0.049810390367055424,-0.053867978373714896,-0.052608726934515855,-0.05463752092220867,-0.05050997451152669,-0.0510696418271037,-0.05169926756755245,-0.045752802391669796,-0.053867978373714896,-0.038127335331603805,-0.05561693871404382,-0.05337826948300963,-0.05239885168074986,-0.05253876850964412,-0.04701205383086884,-0.05134947547446758,-0.033580038465512906,-0.04946059830524441,-0.0406458382204265,-0.05050997450110207,-0.050020265631246036,-0.05044001609707956,-0.04743180431755159,-0.03903679470899183,-0.04659230335461069,-0.04246475696477794,-0.05141943388891471,-0.041345422364897765,-0.03756766804730064,-0.049390639911646515,-0.041415380768920276,-0.05519718823778568,-0.04995030719594967,-0.049600515144563276,-0.05533710506667994,-0.045123176672070275,-0.054077853627480896,-0.05533710505625532,-0.04708201224531596,-0.04316434109882458,-0.04638242814254316,-0.050160182460140285,-0.05253876852006873,-0.04729188748865734,-0.0421149648925423,-0.045822760837390765,-0.04617255288877717,-0.04883097258564489,-0.052049059629363466,-0.04148533917294278,-0.03309032956438302,-0.046522344940163565,-0.05030009927860992,-0.04092567186779039,-0.04498325985360063,-0.056526398091431854,-0.043024424269930334,-0.05239885168074986,-0.05421777044595053,-0.050440016086654944,-0.05162930913225609,-0.055686897118066334,-0.05477743776152754,-0.05512722982333856,-0.053658103140798136,-0.03267057909854949,-0.05232889326630274,-0.048341263684515,-0.05456756251818616,-0.052258934841430994,-0.04820134687646998,-0.0521889764478331,-0.05561693871404382,-0.05351818631190389,-0.05484739616555005,-0.04820134687646998,-0.04932068148677477,-0.044633467781365004,-0.04869105576717525,-0.04561288556277554,-0.04743180431755159,-0.054287728849973044,-0.04883097258564489,-0.05561693870361921,-0.05400789519218454,-0.044843343014281764,-0.04533305192583627,-0.044493550952470755,-0.044213717294682243,-0.04624251129279968,-0.05037005768263243,-0.04043596297708512,-0.04925072307232765,-0.054287728849973044,-0.04694209543727094,-0.055686897118066334,-0.05148939231378645,-0.04561288556277554,-0.04071579662444901,-0.0421149648925423,-0.04960051515498789,-0.040715796634873624,-0.050230140864162796,-0.04932068148677477,-0.04764167957131759,-0.039946254075955236,-0.048131388462022855,-0.059394693042065565,-0.0496704735590104,-0.046102594463905425,-0.05687619015324287,-0.006855924563695297,-0.05023014087458741,-0.04169521441628416,-0.05092972500863406,-0.04757172115687046,-0.048201346866045366,-0.04246475697520255,-0.05106964183752831,-0.0589049841513603,-0.04470342620623675,-0.0547074793366558,-0.052818602177857235,-0.052818602177857235,-0.046942095426846325,-0.04764167957131759,-0.0443536341235765,-0.0558268139573852,-0.05148939231378645,-0.04701205384129345,-0.047151970659763086,-0.05848523366467754,-0.041555297597814525,-0.04372400840397698,-0.05617660602962084,-0.057785649520206275,-0.04869105576717525,-0.05211901804381059,-0.041135547121556384,-0.058415275250230415,-0.04785155482508358,-0.044843343024706384,-0.043584091595931955,-0.06275269687297994,-0.04435363413400111,-0.06478149087109736,-0.04414375888023512,-0.05582681394696059,-0.058765067322466044,-0.04071579662444901,-0.0440038420721901,-0.04372400840397698,-0.06268273846895742,-0.06520124135778012,-0.06736995217436718,-0.0435141331606356,-0.05911485938427706,-0.04085571345334326,-0.03532899879541721,-0.046312469696822185,-0.06729999374949544,-0.0547074793366558,-0.0685592451991191,-0.07345633413744564,-0.04645238652571644,-0.05687619016366748,-0.05848523365425292,-0.05232889327672735,-0.04260467381452142,-0.04435363414442573,-0.046662261800331666,-0.04988034882320101,-0.04414375889065974,-0.04911080624343339,-0.058415275239805796,-0.0696785798094239,-0.04267463220811932,-0.05246881011604622,-0.0398063372574856,-0.037847501673815294,-0.07016828870012916,-0.05659635650587898,-0.04225488172143656,-0.0386170442431583,-0.061493445444205506,-0.06974853822387102,-0.038547085807861946,-0.04141538077934489,-0.04792151320825686,-0.041625256012261656,-0.04309438268437746,-0.05876506731204143,-0.039946254075955236,-0.03959646201414422,-0.038687002647180814,-0.04477338461025926,-0.040785755049320756,-0.04099563029266213,-0.06939874616206,-0.03441953941802919,-0.05037005771390628,-0.04400384206176548,-0.04127546395045064,-0.0391767115483107,-0.04274459061214183,-0.03854708581828656,-0.07009833030653126,-0.06457161562775598,-0.04638242815296778,-0.046242511313648905,-0.03987629567193273,-0.041975048084497285,-0.050579932936398425,-0.028892824760103138,-0.038687002636756194,-0.04414375890108435,-0.039106753123438955,-0.04085571347419249,-0.0702382471250009,-0.04729188748865734,-0.03462941466137057,-0.054707479347080416,-0.05127951709129431;-0.049460598319343706;0.007324562368669915;0.0
data/model/LunarLander-v3_179751_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 179751};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 179751};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, v_x, v_y, theta, omega, leg1_contact, leg2_contact = observations
    reward = 0.0
    
    if is_success:
        reward += 100.0
    elif is_failure:
        reward -= 100.0
    else:
        # Penalize high velocities
        reward -= (v_x**2 + v_y**2) * 0.1
        
        # Penalize large angle and angular velocity
        reward -= abs(theta) * 0.5 - abs(omega) * 0.2
        
        # Reward for being close to the ground with legs touching
        if y < -0.5:
            reward += (leg1_contact + leg2_contact) * 2.0
    
    return reward";-0.07268915325384546,-0.08227530636208434,-0.07198245436314042,-0.07662063572681824,-0.08837837959472525,-0.0761815921089521,-0.07373213633675993,-0.07471367772220373,-0.08431907158832211,-0.06938983091117441,-0.07809984728667096,-0.08403228935237224,-0.0732741604867634,-0.06829932607197828,-0.07635370797077763,-0.06988973068747087,-0.09383761522286842,-0.08651224639267066,-0.07928290465292431,-0.07458953803783683,-0.10817296012389326,-0.07465044179296203,-0.07707945520839302,-0.08770860588166314,-0.07997054563972746,-0.0709196257798824,-0.07079160996587967,-0.07670865356379654,-0.07746307610316566,-0.09363683946600575,-0.08870514891788699,-0.0834437109702005,-0.08390386070530764,-0.0987468068862655,-0.09350378237224637,-0.09210663068354066,-0.07738195614084345,-0.09304465348122665,-0.12628230404672594,-0.09559061610269502,-0.08212629918150192,-0.12152062264760549,-0.1070418929216963,-0.10727968768817162,-0.09097058248353339,-0.09151997581797172,-0.09283398421603584,-0.10991794109566237,-0.09151313507970701,-0.078037007569648,-0.13280404321907968,-0.08226778101263126,-0.08259702887847356,-0.08411972535565923,-0.08253920927956594,-0.0903077093286116,-0.09708323833598123,-0.0849164796621237,-0.09889360897998771,-0.07756632706597275,-0.0725001687389992,-0.07127801727641432,-0.08652329442324494,-0.07195365192343305,-0.07260460149846501,-0.07029864020575578,-0.1034695373123408,-0.0894832687724533,-0.08630180150859539,-0.07308425137151968,-0.10756898922712865,-0.07826733579396464,-0.0788852972235702,-0.07802165911769161,-0.08858365414803256,-0.08539941654443511,-0.09669907639681248,-0.13812175600429125,-0.07535258888111177,-0.07487064418112008,-0.09196532065947072,-0.08973159801408981,-0.08922182466075124,-0.09473462612138361,-0.07100612087986288,-0.07444662432176535,-0.09425436429090345,-0.10493284433971078,-0.07531016552806995,-0.07241848243602808,-0.0735192164786527,-0.06763288848714219,-0.07274519533421218,-0.11418062305271541,-0.07117750669428831,-0.07872223070528503,-0.07705203939181209,-0.10919704019594739,-0.07214565725458415,-0.07243639164798113,-0.07112337120380888,-0.07093574396794342,-0.07337051833066187,-0.07300167433382622,-0.07522610185611613,-0.08267007062320386,-0.07750564419934645,-0.07612355254704332,-0.10244574644186444,-0.07831849885681641,-0.07050526661464425,-0.07394390831072714,-0.07428101018256389,-0.081594538372521,-0.07963201355212116,-0.07836487430481293,-0.07778234269870668,-0.07955674734019003,-0.07031327584069252,-0.07955024882185782,-0.08020189252638261,-0.09708979387159176,-0.10565533423998752,-0.0889878856143566,-0.07776778859504904,-0.0787565877632533,-0.09185402688918713,-0.11610265962261966,-0.07467398504869138,-0.07377567483831228,-0.08063066149561021,-0.08550174488729795,-0.11926505226633362,-0.07836878510873711,-0.08335382274282291,-0.07540740892032455;-0.08463130758570846;0.01380155617326529;0.05
data/model/LunarLander-v3_201815_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 201815};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 201815};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    in_bounds_x = -2 <= x <= 2
    in_bounds_y = -5 <= y <= 5
    
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    else:
        return float(in_bounds_x and in_bounds_y) * 5.0 - abs(vx) - abs(vy) - abs(omega)";0.014460196455524788,0.007613122210111051,0.007773776173185498,0.013845739402190683,0.004812618688503834,0.011993776153561998,0.010123751645173545,0.008115016880218328,0.00994176264460059,0.016703332198812548,0.011711734500939812,0.009187253959324687,0.01577567043813751,0.015850607272288514,0.017927580925826917,0.009461242669312671,0.016145544133408952,0.010878834550918128,0.014157817077260578,0.012263731483498535,0.012908480922820481,0.0152392210610663,0.016263205887787936,0.1692660692891336,0.011774971090844995,0.034999984731156834,0.07120384440205049,0.03916442586938847,0.07629395637771177,0.10992627556345543,0.1504158302359045,0.21238793174661502,0.2083525524500061,0.16777859376313523,0.1458570835836715,0.10789573044393896,0.13157766872846965,0.13036744594820698,0.21281933437354808,0.21033373099109226,0.21510006826811304,0.2141845442230555,0.21253736684057437,0.21796875415655662,0.2174502736047639,0.2155037723824084,0.20118224763461534,0.029086047766514054,0.21716755830159845,0.2145839874281776,0.21159476001641733,0.11730194609337176,0.2163611717991264,0.17127668248532604,0.2140977214153788,0.14408864252142503,0.17694222674180116;0.09964907401056186;0.08725778875241089;0.0
data/model/LunarLander-v3_676175_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 676175};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 676175};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, _, _, angle, _, leg0_contact, leg1_contact = observations
    in_safe_zone = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    upright = abs(angle) < np.pi/4

    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    else:
        return (leg0_contact + leg1_contact) * 10.0 + in_safe_zone * 5.0 + upright * 3.0";0.05084372295539206,0.043116713387703294,0.03338068133241545,0.03399884209783055,0.03276252056700035,0.060579755010679893,0.055479928696005314,0.03956228898656646,0.03345795142809234,0.04265309281364197,0.06397963922046294,0.04636205740613257,0.0318352794188777,0.07402475165845834,0.030676227983724387,0.03755326649896738,0.04404395453582594,0.0330716009497079,0.038557777742766926,0.04659386769316324,0.03508062343730698,0.026426372721495568,0.032144359801585254,0.03909866841250514,0.0399486394649509,0.030753498079401274,0.04234401243093442,0.02920809616586352,0.05393452678246756,0.05725714089657373,0.03430792248053811,0.034617002863245656,0.03508062343730698,0.03376703181079989,0.03500335334163009,0.024185539946865824,0.038325967455736264,0.03848050764709004,0.027199073678264442,0.03291706075835413,0.034617002863245656,0.027199073678264442,0.027199073678264442,0.03137165884481637,0.0649841504642625,0.041416771282811765,0.15940820738141917,0.030135337313986172,0.04018044975198156,0.047443838745609,0.032144359801585254,0.03878958802979759,0.031294388749139486,0.035235163628660755,0.041416771282811765,0.06312966816801718,0.03817142726438248,0.035853324394075854,0.03616240477678341,0.030135337313986172,0.03739872630761361,0.024571890425250265,0.029517176548571073,0.02766269425232577,0.028126314826387094,0.029671716739924848,0.07788825644230273,0.02596275214743424,0.06405690931613985,0.03399884209783055,0.0318352794188777,0.07526107318928854,0.03878958802979759,0.07711555548553385,0.030753498079401274,0.03817142726438248,0.025808211956080466,0.02889901578315597,0.035853324394075854,0.038325967455736264,0.03894412822115136,0.03894412822115136,0.05980705405391102,0.05362544639976001,0.06289785788098652,0.08468802486186884,0.040025909560627786,0.036316944968137185,0.02766269425232577,0.0761110442417343,0.04605297702342502,0.03399884209783055,0.032144359801585254,0.07897003778177915,0.030289877505339947,0.034617002863245656,0.03647148515949096,0.030753498079401274,0.03894412822115136,0.04651659759748635,0.040798610517396666,0.11443701169747057,0.1085644844260271,0.030753498079401274,0.03276252056700035,0.03446246267189188,0.05401179687814445,0.0561753595570973,0.030289877505339947,0.059961594245264795,0.05107553324242272,0.0449711956839486,0.08206084160885466,0.041725851665519315,0.044430305014210386,0.03446246267189188,0.037244186116259834,0.05192550429486848,0.04358033396176462,0.10338738801567564,0.033535221523769226,0.051848234199191594,0.06088883539338744,0.1036191983027063,0.04528027606665615,0.06459779998587806,0.058029841853342604,0.05717987080089684,0.04435303491853349,0.057411681087927505,0.05161642391216093,0.043116713387703294,0.03909866841250514,0.05362544639976001,0.07757917605959518,0.06336147845504785,0.03755326649896738,0.07464291242387344,0.06722498323889223,0.05223458467757603,0.04798472941534721,0.16458530379177064,0.0530845557300218,0.058029841853342604,0.05277547534731425,0.12255037174354377,0.16079906910360314,0.03963955908224335,0.08746974830623679,0.04481665549259482,0.047907459319670324,0.04419849472717972,0.029980797122632397,0.07340659089304324,0.05532538850465154,0.08793336888029811,0.20986557985842677,0.04296217319634952,0.045666626545040584,0.0737156712757508,0.04543481625800992,0.041725851665519315,0.05099826314674583,0.05532538850465154,0.07881549759042537,0.0661432018994158,0.08368351361806929,0.03739872630761361,0.07757917605959518,0.12200948107380556,0.07448837223251967,0.047907459319670324,0.04914378085050053,0.06042521481932612,0.04048953013468912,0.04605297702342502,0.053470906208406235,0.09179687366414249,0.18683909134671428,0.053470906208406235,0.05594354927006664,0.07062486744867529,0.059034353097142146,0.08746974830623679,0.05161642391216093,0.06336147845504785,0.0992148028491237,0.04481665549259482,0.06459779998587806,0.05532538850465154,0.04481665549259482,0.059652513862557245,0.09859664208370861,0.04605297702342502,0.047907459319670324,0.05223458467757603,0.05849346242740393,0.17215777316810563,0.059034353097142146,0.041725851665519315,0.04419849472717972,0.053470906208406235,0.06892492534378376,0.059652513862557245,0.053470906208406235,0.04605297702342502,0.059034353097142146,0.054089066973821334,0.054089066973821334,0.04419849472717972,0.06212515692421765,0.05038010238133073,0.06088883539338744,0.06397963922046294,0.06521596075129316,0.06645228228212335,0.05779803156631194,0.06096610548906434,0.06088883539338744,0.06954308610919886,0.047907459319670324,0.05038010238133073,0.06274331768963275,0.052852745442991136,0.04852562008508542,0.07325205070168947,0.060270674627972344,0.041725851665519315,0.05779803156631194,0.05161642391216093,0.06274331768963275,0.08066997988667068,0.04543481625800992,0.06892492534378376,0.05223458467757603,0.06645228228212335,0.07016124687461396,0.054089066973821334,0.05841619233172704,0.07077940764002906,0.04605297702342502,0.047907459319670324,0.05161642391216093,0.06150699615880255,0.06150699615880255,0.05656171003548174,0.06397963922046294,0.07139756840544416,0.060270674627972344,0.04852562008508542,0.04914378085050053,0.07448837223251967,0.060270674627972344,0.05099826314674583,0.11219617892284083,0.06892492534378376,0.06521596075129316,0.041725851665519315,0.047907459319670324,0.05656171003548174,0.05779803156631194,0.043116713387703294,0.0899423913678972,0.05099826314674583,0.07325205070168947,0.1536129502056526;0.055175496138601635;0.02674066420453609;0.0
data/model/LunarLander-v3_120521_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 120521};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 120521};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    in_landing_area = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    elif in_landing_area:
        return 10.0
    else:
        return -1.0";0.04401617623511194,0.026504364184583535,0.03928325405929345,0.029817409707656475,0.04212300736478455,0.03123728636040202,0.0378633774065479,0.025084487531837986,0.03833666962412975,0.03833666962412975,0.028870825272492778,0.028870825272492778,0.04212300736478455,0.048749098410930426,0.026977656402165383,0.046382637323021184,0.03597020853622051,0.023191318661510592,0.0416497151472027,0.03833666962412975,0.0591615271977311,0.030290701925238323,0.022718026443928743,0.026504364184583535,0.046382637323021184,0.02366461087909244,0.05726835832740371,0.03265716301314757,0.040229838494457146,0.04732922175818488,0.024800512201288878,0.02839753305491093,0.03928325405929345,0.046382637323021184,0.029817409707656475,0.026031071967001683,0.06436774159113144,0.021298149791183198,0.026977656402165383,0.03928325405929345,0.02413790309667429,0.057741650544985555,0.02839753305491093,0.022718026443928743,0.022718026443928743,0.029817409707656475,0.030290701925238323,0.025084487531837986,0.022718026443928743,0.03171057857798387,0.03313045523072942,0.08093296920649615,0.026977656402165383,0.02839753305491093,0.02082485757360135,0.022244734226346895,0.02366461087909244,0.03502362410105681,0.02839753305491093,0.020351565356019497,0.023191318661510592,0.04117642292962085,0.03502362410105681,0.04496276067027564,0.028870825272492778,0.03123728636040202,0.025084487531837986,0.03502362410105681,0.0795130925537506,0.024611195314256137,0.0776199236834232,0.03644350075380236,0.057741650544985555,0.025557779749419834,0.046382637323021184,0.02839753305491093,0.0378633774065479,0.06815407933178623,0.03313045523072942,0.02792424083732908,0.05584848167465816,0.027450948619747232,0.028870825272492778,0.02792424083732908,0.03644350075380236,0.07620004703067766,0.033603747448311266,0.04212300736478455,0.0378633774065479,0.03455033188347496,0.05158885171642152,0.03833666962412975,0.054901897239494464,0.05939817330652203,0.024611195314256137,0.03218387079556572,0.05584848167465816,0.03502362410105681,0.03833666962412975,0.026504364184583535,0.04780251397576673,0.027450948619747232,0.10696404117349784,0.033603747448311266,0.045436052887857487,0.0766733392482595,0.04969568284609412,0.05717369988388733,0.029817409707656475,0.030290701925238323,0.02792424083732908,0.03171057857798387,0.054428605021912616,0.03265716301314757,0.0397565462768753,0.03076399414282017,0.06001345318937843,0.04354288401753009,0.03171057857798387,0.034077039665893115,0.05263009459510159,0.028870825272492778,0.03123728636040202,0.045436052887857487,0.06910066376694993,0.04212300736478455,0.05679506610982186,0.04117642292962085,0.01727516594173748,0.05348202058674892,0.05158885171642152,0.01897901792503214,0.033414430561278526,0.07336029372518657,0.033603747448311266,0.052062143934003366,0.08850564468780572,0.033603747448311266,0.03313045523072942,0.060581403850476646,0.042596299582366395,0.05537518945707631,0.03833666962412975,0.040229838494457146,0.033603747448311266,0.05537518945707631,0.05868823498014925,0.03076399414282017,0.017227836719979298,0.03502362410105681,0.052062143934003366,0.040229838494457146,0.04827580619334858,0.030290701925238323,0.05395531280433077,0.04827580619334858,0.0378633774065479,0.036916792971384206,0.06768078711420437,0.019026347146790322,0.06862737154936807,0.049222390628512275,0.060581403850476646,0.06484103380871328,0.054428605021912616,0.03644350075380236,0.040229838494457146,0.0591615271977311,0.05395531280433077,0.06834339621881896,0.049222390628512275,0.025936413523485316,0.054901897239494464,0.06200128050322219,0.04685592954060303,0.0388099618417116,0.05016897506367597,0.0591615271977311,0.0416497151472027,0.048749098410930426,0.05348202058674892,0.10757932105635423,0.06436774159113144,0.07146712485485918,0.05584848167465816,0.05963481941531295,0.05348202058674892,0.1017578267800975,0.04827580619334858,0.07620004703067766,0.12068951548337145,0.05726835832740371,0.06342115715596774,0.10933050226140707,0.10033795012735194,0.08377272251198724,0.08282613807682354,0.1027044112152612,0.0776199236834232,0.14624729523279129,0.0776199236834232,0.08661247581747833,0.09323856686362421,0.07194041707244102,0.09607832016911531,0.12778889874709917,0.09513173573395162,0.16091935397782858,0.09797148903944271,0.09939136569218825,0.10507087230317043,0.09229198242846051,0.09039881355813312,0.049222390628512275,0.0785665081185869,0.09039881355813312,0.14530071079762757,0.22812684887445112,0.03265716301314757,0.12305597657128069,0.08945222912296942,0.14861375632070054,0.36396171532044175,0.08519259916473279,0.15098021740860976,0.06200128050322219,0.046382637323021184,0.0998646579097701,0.10033795012735194,0.20588211464810424,0.042596299582366395,0.06152798828564034;0.053904311487781;0.03747892782103683;0.0
data/model/LunarLander-v3_368781_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 368781};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 368781};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    else:
        reward = 0.0
        if leg1_contact or leg2_contact:
            reward += 10.0
        reward -= (abs(vx) + abs(vy)) * 0.5
        reward -= abs(angle) * 0.1
        return reward";-0.06769040279436124,-0.0490074892581595,-0.06033188410434806,-0.07968186970162816,-0.04529729948968322,-0.07902267223414404,-0.05222463794165589,-0.051404172892294306,-0.0777496161487649,-0.05310756023435133,-0.04887732577702974,-0.011872531415449725,-0.04306495656062639,-0.06199157180568421,-0.06777065123646134,-0.06126927915497159,-0.06909687169085105,-0.06226093352952949,-0.05686957996953023,-0.049263064706936574,-0.04811708425297336,-0.061403538244438706,-0.06108222268437171,-0.0575084211888892,-0.04770273240168488,-0.06118129946687794,-0.07717327929880001,-0.07958636227833636,-0.06405471648406708,-0.07380590114873121,-0.06518615660338359,-0.046138827072332016,-0.07399311085664691,-0.07081647798308723,-0.07273866164171591,-0.05618408644352808,-0.0677098323192572,-0.11294539769281044,-0.06595137490361203,-0.04418996400620596,-0.06521743140597175,-0.06088679839460636,-0.07117462521656395,-0.12060555678687511,-0.06863095475224466,-0.1422222338964887,-0.06621332564812352,-0.14951408687214748,-0.08323641382448584,-0.0728203527509571,-0.07128782051978788,-0.06756224270347788,-0.07671535620567144,-0.07841566286646003,-0.0705256380139556,-0.0702936161134598,-0.07607805381335454,-0.09202953704479505,-0.06684189848797412,-0.07834017465260212,-0.07725574494867488,-0.05647842978564926,-0.09156535145012691,-0.07832193143693299,-0.09764196138995214,-0.08888134818060496,-0.07646914269941746,-0.06407081516264751,-0.13200430396565352,-0.09625844237987859,-0.06797677857987033,-0.018530688605765865,-0.054100860818806946,-0.06848852483013286,-0.06204217145369937,-0.056124190320796075,-0.05554908077470032,-0.052130887107101474,-0.055777336296358206,-0.058760336107244286,-0.0593523340105682,-0.06076816775196441,-0.06420384931699057,-0.05326618501891547,-0.05316996424969508,-0.0010758779220582757,-0.053476683267882824,-0.05468146018621804,-0.04962637853580223,-0.05913627512239906,-0.05922692853561476,-0.050427066504812726,-0.03516171919177157,-0.051907776783555654,-0.03852906813841563,-0.05445402667978355,-0.057702788737176026,-0.059458398852392666,-0.055421657612180694,-0.05446263465861182,-0.05457198396340951,-0.052994093818923976,-0.033369574952986224,-0.053645852649963896,-0.052828607063582646,-0.06571421496888369,-0.05216928270091712,-0.04681449019105477,-0.0552190960528952,-0.057059086836977434,-0.05615408341903911,-0.06157928568880971,-0.05706867028446366,-0.07476659273984355,-0.056522817000519913,-0.06276555266138413,-0.05819083366226396,-0.052785730482151745,-0.06531916342175041,-0.04935818547250162,-0.0607826322441543,-0.05232500253005294,-0.05257031093560511,-0.05132629077076526,-0.06757534377257063,-0.056495273903410144,-0.05502577428795378,-0.053571344105381655,-0.0491431318423709,-0.06375962775451219,-0.044819207855161795,-0.05507010838631811,-0.055821591499208074,-0.05623264296931303,-0.05736055356527289,-0.0045953370735724065,-0.05520935472306227,-0.05168111425636157,-0.06440172635807989,-0.04822614052511601,-0.0567327655164763,-0.007972912704028346,-0.056411833284081156,-0.061312012458812085,-0.051340574802288354,-0.05065921884057571,-0.05170973170558294,-0.05843968115823177,-0.04826931195946962,-0.05921620111077869,-0.05153613521794029,-0.05228712471107062,-0.05650101130186487,-0.06353035434556747,-0.04618986515867729,-0.046287327744254106,-0.05603846004121768,-0.054060887278175,-0.0514933481888083,-0.0535211274833092,-0.05080826776920473,-0.04681892056427076,-0.05564819926812265,-0.06394037536610356,-0.054575615920959324,-0.055245081134815216,-0.051936579201498016,-0.049496235741192635,-0.052203375303726325,-0.07264263092190927,-0.05653996835389392,-0.05904297335366142,-0.05205227672326562,-0.05781130915052179,-0.05457356483848248,-0.047965626574490675,-0.05073777344751403,-0.05281748254948588,-0.05676736362405367,-0.0565934133241663,-0.05260495444029281,-0.053504665652197525,-0.05248558226078337,-0.05365141220400611,-0.05640417935684847,-0.049450391170716625,-0.051470220531414236,-0.0524491831688099,-0.0518798779306545,-0.051627519247939443,-0.05220760223311329,-0.0541658254412803,-0.048945947518144094,-0.04639204710083655,-0.05359669595027249,-0.054068482195860884,-0.0530413102015568,-0.053856065220401095,-0.0536446571419931,-0.060740521550997795,-0.05169719917335318,-0.05046090730494271,-0.05766008366270398,-0.05316935839468148,-0.05460209219510811,-0.05499350767539165,-0.05672754604809512,-0.0563247874754864,-0.05579130617951255,-0.05468633199108474,-0.055353190922561975,-0.0557548864953806,-0.056436706912999186,-0.051808799485678424,-0.05519865522624599,-0.05962058198629139,-0.055383431534596385,-0.05590058888930019,-0.022972831340700835,-0.029588109888848264,-0.0544897308830534,-0.05417068385135123,-0.050121620637915226,-0.05410157647012889,-0.06080993412840292,-0.04873697364898569,-0.05165341650955438,-0.05682004506205027,-0.052627080481705744,-0.05371694348980609,-0.05008030301224716,-0.05299766771663187,-0.05181592166950199,-0.05032045717770548,-0.05149565960608855,-0.0324083935576753,-0.05561451474619043,-0.05287764457531294,-0.05269219733699939,-0.046709070344945106,-0.0514365269690222,-0.054935124020635454,-0.0532149602272895,-0.05343897834084563,-0.05564659480262423,-0.0563299213851994,-0.05199441835270787,-0.0499679793900825,-0.04456883243625533,-0.05057013732132973,-0.03658540641104831,-0.050204421938451156,-0.04448990475739237,-0.05936373684907023,-0.05135812920645185,-0.05054397916559001,-0.06072960681209585,-0.051249331165759845,-0.05316293485880999,-0.05750436306345492,-0.05036882375947262,-0.03946525997384808,-0.05543784571521515,-0.04774222715104203,-0.05122665517826114,-0.0015406220756004315,-0.04254495935093671,-0.04269339762846645,-0.05592869039460963,-0.05160171364806405,-0.05043731759482218,-0.05602502129116532,-0.05518987145461125,-0.06288676032818934,-0.0548415665606033,-0.06125425142082774,-0.047139885657367556,-0.05940572834208992,-0.06153032276087289,-0.05359124791958607,-0.06008521022713666,-0.0553347299383487,-0.05587103697158028,-0.05307236997665607;-0.057188656589764;0.01582985527480976;0.0
data/model/LunarLander-v3_585037_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 585037};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 585037};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_pos, y_pos = observations[0], observations[1]
    angle = abs(observations[4])
    leg_contact = np.sum(observations[-2:])
    
    if is_success:
        return 500.0
    elif is_failure:
        return -500.0
    
    reward = 0.0
    reward -= abs(angle) * 0.1
    reward += leg_contact * 0.3
    reward -= np.linalg.norm([x_pos, y_pos]) * 0.05
    
    return reward";-0.05655726596612615,-0.057112139654534565,-0.05654416148579978,-0.05708784122560489,-0.056496456778001074,-0.05591945244453729,-0.056264614317627595,-0.05636182452483139,-0.05700262373113232,-0.056497258342076785,-0.05602246874149158,-0.05619567107169425,-0.0563559333648894,-0.056326292239538854,-0.057622395489643936,-0.0561861826774806,-0.05686955458220851,-0.05679449230341188,-0.05642042835627165,-0.05729426217807927,-0.057501719603197256,-0.0575355359796858,-0.05634893054623912,-0.0565442782357413,-0.05668198062087801,-0.056161521623371936,-0.05714866429317486,-0.056067501239888504,-0.05941510307516175,-0.056463851883752025,-0.05603885033982168,-0.056388140431667726,-0.0581573353176935,-0.05606898037722601,-0.05623757293498565,-0.05641101665159096,-0.057549939032657364,-0.05620700999246838,-0.05845392952206905,-0.055980716066262766,-0.056106387137965806,-0.05605283565178273,-0.05751000445872698,-0.056168939608428885,-0.05823395111786285,-0.05835681741466565,-0.05623936472071553,-0.05654094466560503,-0.05618233110124046,-0.05622726000799865,-0.05613375074648079,-0.05599515869950369,-0.05774205351169264,-0.056661239604429196,-0.05667262763130988,-0.056106525027720545,-0.05819853468362489,-0.05731646723662115,-0.056556046966752746,-0.05759930870223968,-0.056048166443085023,-0.056413165648023005,-0.05630335732835446,-0.05611576701284002,-0.05655361291448049,-0.056115437654774045,-0.056079844256784014,-0.05840089907754805,-0.056135889542391924,-0.056523962066363086,-0.05619283786716116,-0.05634470822165295,-0.055719597314461716,-0.05741091507465249,-0.056484332622446745,-0.05623774478126277,-0.05649647639007982,-0.05709054864984633,-0.05679214337204129,-0.05692545034521194,0.06077898552028365,-0.05662808476434593,-0.05682890423252868,-0.05641819533942112,-0.055809718512222405,-0.055894614046298474,-0.056312728442917945,-0.05654647709530282,-0.05623063959392873,-0.05659568474580255,-0.05626252956402726,-0.05676046713875727,-0.05678292825791706,-0.05643702074151572,-0.05699253443908638,-0.05664667610573831,-0.056894860385065124,-0.05646432020509346,-0.05661233102817494,-0.05772060677275877,-0.056959540013611906,-0.05670453025302436,-0.056018120982977676,-0.05588196934477653,-0.056330336732181734,-0.057039941319964496,-0.056254299438143675,-0.05677348309303066,-0.05616506959899173,-0.05672973520798367,-0.05715138786834477,-0.0584452105261309,-0.057335765733657056,-0.05694296365734303,-0.05732238521373716,-0.05751129833907448,-0.05670006462002694,-0.056666541450752526,-0.060731622595059986,-0.0565317273486478,-0.0577868277439424,-0.05737038056980513,-0.05679806038680488,-0.056696368553716694,-0.056442069556764646,-0.056554724668801806,-0.05715541115190165,-0.05817770939621412,-0.05748811907292057,-0.05650584144970436,-0.05694394188692451,-0.05665296263728571,-0.056805305841982644,-0.0582371521426188,-0.05651148753239401,-0.05661812330173862,-0.05719413488529908,-0.05822326189614436,-0.05823426361692467,-0.0572025168853285,-0.0566568488129992,-0.057138846473281685,-0.05631823994020605,-0.05813287100575328,-0.056244063503084,-0.05637578223138126,-0.055991420421802766,-0.05735354349567185,-0.05718607550666125,-0.05732971549032588,-0.056445390372412814,-0.0614162573575435,-0.05802323334642841,-0.05702761292833701,-0.05686381650111581,-0.05796892668155654,-0.057144261289409616,-0.05727035183269831,-0.05761200255051928,-0.05694040046898985,-0.05729339020382018,-0.05685898965660194,-0.057499691676092854,-0.05768288774027144,-0.056566157338464866,-0.057779785498605074,-0.05712928956704186,-0.056587606117005154,-0.05838120657932563,-0.05758503467791402,-0.05847853746842725,-0.057527159971959466,-0.057581104639670276,-0.057549318292528406,-0.05842550737317381,-0.057498895765837645,-0.059280559861161417,-0.05783086522074503,-0.0578370132946668,-0.05763857316238398,-0.05802064308776518,-0.05730052145265345,-0.05873016865023632,-0.057353705616382165,-0.05731353969344716,-0.05840254449569609,-0.05714334642285403,-0.05728607830484434,-0.05843163867063804,-0.05743863872866123,-0.05796848645675787,-0.05830547943529689,-0.05823861576285306,-0.057985091572431216,-0.057727288922410684,-0.057269179075603374,-0.05661208572661568,-0.05735861131987002,-0.05843175178272147,-0.05716331339103998,-0.057491809981519586,-0.05895321054161494,-0.05720802503968635,-0.05675817490197396,-0.05660524166448659,-0.057046269732093924,-0.0581494359573163,-0.05720636601420686,-0.05720625121676226,-0.05655032432851283,-0.05721426379790234,-0.05679247714738786,-0.05677135907254771,-0.056809562116869085,-0.057125789891143655,-0.056550213793625785,-0.057122572306874266,-0.058332353097747744,-0.05698109348406671,-0.05631975344596937,-0.05647227777949627,-0.05683936994540747,-0.05686754718722496,-0.056639339795365805,-0.059144519302281595,-0.05714782926578239,-0.05812528268099853,-0.05675307339419647,-0.0571322228960487,-0.05670896912930588,-0.057424146243283215,-0.05668422353751431,-0.05803097886149653,-0.0567594635586559,-0.05739070793607085,-0.05727554143015175,-0.056836304187581094,-0.05921769626215911,-0.05687055946148566,-0.05644310201241647,-0.057191311087760946,-0.05817840033441744,-0.05764669342163473,-0.05845926385317924,-0.057833343955206326,-0.056780050737676974,-0.057313049455255144,-0.05716193865732606,-0.057219117729318536,-0.05691883967967893,-0.056961003458797586,-0.056887921688019184,-0.0566646677207136,-0.05735785342419486,-0.056829572724004275,-0.057032866949478046,-0.05698592325214088,-0.05701204285422282,-0.05673876458414907,-0.056549939292551726,-0.05714514003663871,-0.05670621099241007,-0.05760080379720556,-0.056926376649657946,-0.05767985899899927,-0.05686610739267976,-0.05669467351593094,-0.05683196822244728,-0.05757934745548778,-0.05655154715655558,-0.05662719616378945,-0.05711099722688891,-0.05702522692731691,-0.056615125331685265,-0.05675007738452137,-0.05672006888642111,-0.056915663464534444,-0.05739275310753518,-0.05704987405552228,-0.05656669169294538,-0.05683020933921499,-0.05765398878059307,-0.05666440152905497,-0.05650593683542203,-0.05670088803282117,-0.05665204067504021,-0.05714727340189556,-0.0572680817072064,-0.05698045155517729,-0.05710927866705287,-0.056713611774587794,-0.05666967584587682,-0.057545873312262165,-0.057341969471370505,-0.05721505526142565,-0.056764008589876506,-0.05743930174592778,-0.05676703596726299,-0.05725527431295517,-0.05731171769638432,-0.05643584934332878,-0.05702923157359168,-0.05717381515895016,-0.057302444306635635,-0.05654768353846591,-0.05725953787517239,-0.057793173435275555;-0.05667159623212461;0.006757157000621836;0.0
data/model/LunarLander-v3_402287_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 402287};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 402287};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    reward = 0.0
    
    if is_success:
        return 100.0
    
    if is_failure:
        return -100.0
    
    # Penalize for high velocity to encourage soft landing
    reward -= (vx**2 + vy**2) * 0.1
    
    # Penalize for non-zero angular velocity to keep the lander upright
    reward -= abs(angular_v) * 0.5
    
    # Reward for being close to the landing pad and having a low altitude
    reward += max(0, (1 - np.abs(y / 10)))
    
    # Small penalty for not having both legs in contact with the ground
    if leg0_contact + leg1_contact < 2:
        reward -= 1.0
    
    return reward";-0.06338521880468106,-0.06617899051923538,-0.07348724600284237,-0.07290596167817565,-0.06416673261317059,-0.06341527885175291,-0.06450558244184937,-0.07342247548036576,-0.0666221468356467,-0.06937824428386286,-0.06155937581463134,-0.07081004633561061,-0.06495696018425351,-0.06843053890631723,-0.06596435787526188,-0.07727118994617813,-0.06992041805440712,-0.06511533369595848,-0.06473632121777964,-0.06779238771337508,-0.07024081569553024,-0.06425654767307214,-0.06363539901760767,-0.06434414586249905,-0.07203873274581837,-0.06510383329664306,-0.06748128815223156,-0.06599892297770583,-0.06237591344879047,-0.06887799837799626,-0.07302745021085917,-0.0651359775765287,-0.06339263279311187,-0.06432883935511179,-0.06253094174977018,-0.06366775699647859,-0.06846957610421606,-0.06386805856014503,-0.0797255567716578,-0.06164924123759583,-0.0634043307320757,-0.07049446605784924,-0.008975392909816528,-0.06249686387433554,-0.06279100965693767,-0.06827240146587163,-0.06858729213609557,-0.06719925537840254,-0.06936030245286869,-0.07007174127065215,-0.061865687953396524,-0.06636470839132384,-0.07430721083732754,-0.06528832680684321,-0.07063832827335242,-0.0865558135342093,-0.07843248059105776,-0.07472066602797174,-0.10545729998997917,-0.09069141433184699,-0.07590930815205583,-0.06904047385328599,-0.0862903900893637,-0.07105628874736643,-0.0984399220661503,-0.07737390793527027,-0.08034521807599636,-0.0733768805607659,-0.0834832718353834,-0.06199152670047979,-0.09227998272324073,-0.06830043237821623,-0.08558496247770987,-0.07609748046822028,-0.08695570097676808,-0.08005091983011214,-0.08215269340252988,-0.08283620439346366,-0.08417540668656827,-0.07015656452147108,-0.08714371061759282,-0.08178863107337199,-0.07373818440175685,-0.0810722474964773,-0.10452390836084414,-0.10181626589744067,-0.08442127519533132,-0.06974915588168892,-0.07514922130258736,-0.07028677504196855,-0.07219000348595037,-0.06518762254431246,-0.06774945584353073,-0.0707511184556798,-0.08907233796722083,-0.06850179864024017,-0.06569319888775345,-0.08070886188484411,-0.05959131829551408,-0.06834995807482566,-0.07401150075844783,-0.07767574492096858,-0.07925082967456161,-0.07168037302536119,-0.0653420046295845,-0.07084865901604555,-0.0792947013951936,-0.06928007570180217,-0.06850325077284665,-0.07698557089477207,-0.073679665199557,-0.067112639521129,-0.0640835703316889,-0.06869482260084882,-0.0685515590014446,-0.06472366703204192,-0.0710043732600595,0.2878647850905822,-0.0678102046097735,-0.07307115053371274,-0.05812009705506354,-0.0707560821589569,-0.06968649520105327,0.2532433198178761,0.10674714153313933,0.2950254544004446,-0.06251913811351636,0.33133859244118735;-0.05884374137405851;0.06595387859029152;0.06
data/model/LunarLander-v3_33305_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 33305};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 33305};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    distance_to_target = np.linalg.norm(np.array([x, y]) - np.array([0, 0]))  # Assuming the target is at (0, 0)
    
    if is_success:
        return 200.0 - distance_to_target
    
    if is_failure:
        return -150.0
    
    reward = -0.1 * (vx**2 + vy**2) - 0.1 * (angular_velocity**2)
    
    if leg0_contact or leg1_contact:
        reward += 10.0
    
    return reward - distance_to_target";-0.06520253478472249,-0.04519540171081398,-0.05647650526533223,-0.026550085603460342,-0.06647086666254533,-0.0516369562624358,-0.06290457378692295,-0.05027773491534848,-0.04431141044575993,-0.06420132875109391,-0.04504914237276875,-0.04901587296446676,-0.05095982608692811,-0.04795593788826634,-0.047382060997227485,-0.06431871617484582,-0.038945738902592765,-0.06913798987577975,-0.05654669017816422,-0.04838620860121581,-0.054537378039486065,-0.06374068910697805,-0.05101674505838836,-0.06272823423827019,-0.05030327486183504,-0.05828849258171285,-0.06181057292117691,-0.050131446840771594,-0.05855595333932809,-0.05093406734634204,-0.047443682241579826,-0.04973226291265236,-0.052896680679246584,-0.04617247284039728,-0.048903500274505525,-0.056529692917499756,-0.05120670773230874,-0.041804269612934215,0.08221678865760895,-0.04274355356538051,-0.04299016702111239,-0.051749355531328936,-0.07683380997525592,-0.05925883300471292,-0.05288552610430632,-0.07663175194547991,-0.042981075650931726,-0.05219002582112664,-0.051945189856750146,-0.024358820252876036,-0.04216499144648759,-0.04913193559500304,-0.021392951375599222,-0.0533574554160767,-0.06428210480866181,-0.04458078160961756,-0.0555199817335422,-0.05474101682123289,-0.04643781979753882,-0.03932409142764179,-0.03825605327656805,-0.052226114643621535,-0.05380342806119657,-0.097280674749359,-0.047644190831551386,-0.04446161442228803,-0.05758672598158332,-0.057556959991666684,-0.054618617090990015,-0.05184048290293569,-0.05647024249493697,-0.0495779992773473,-0.044658289577816264,-0.05396159968950127,-0.05253146525315181,-0.061180143324720125,-0.05624930571009072,-0.05537267525165649,-0.04552956285092472,-0.046139110509279685,-0.04220632252166665,-0.04533571873596661,-0.04518375949810304,-0.06012691552491817,-0.05245487278149644,-0.04916538592922037,-0.05382616405173235,-0.06417339069316927,-0.04644127867940828,-0.04946558326008611,-0.0496202620984928,-0.05401594742911362,-0.06002078648362442,-0.05159956833564727,-0.058069770910133496,-0.05478316019226231,-0.05711574621597731,-0.05945146231010258,-0.049904942322576605,-0.05347398936079306,-0.052383829211389496,-0.053172411557153174,-0.05493739051962125,-0.04841109567824595,-0.056370393660141446,-0.051520847755934865,-0.05202447412288187,-0.04676778768973566,-0.05310719453122732,-0.05817614099577416,-0.055526268480264665,-0.04905553210211564,-0.0421588542214277,-0.049642707905347395,-0.05578618869645853,-0.0481701658594243,-0.048351243335305,-0.05289318554295884,-0.04769757411059112,-0.04725403030247824,-0.044836081110189836,-0.053948692954775175,-0.04982559570181214,-0.054196830424346976,-0.0496287584296328,-0.05812309481472515,-0.0510025670119504,-0.05124658409979731,-0.048366676403576725,-0.04370629758535322,-0.0471721319963711,-0.05576928632972801,-0.05780250358133572,-0.05650528612217366,-0.0515843656720587,-0.05726896441329418,-0.05356603942993231,-0.051484143666901655,-0.04555419700332433,-0.052645818161192307,-0.047017321557864755,-0.05405053520946342,-0.051911515253523936,-0.05557368420249475,-0.05086436781254349,-0.04808137166224569,-0.04852314474172989,-0.058088236336516885,-0.05003403611391948,-0.043084862550273384,-0.05733818977409298,-0.05331424702684138,-0.059239781763027785,-0.05847322678461746,-0.05457857903837029,-0.05367892419922387,-0.05030054880872019,-0.0590704901218338,-0.04859754635963055,-0.057136780264861395,-0.06095913566272214,-0.04792943368348213,-0.052539495448351126,-0.05846972634872533,-0.0466969434144205,-0.04616418152168839,-0.04682490837654491,-0.056329261825814166,-0.05107950034391106,-0.054024740497644046,-0.051779320249667415,-0.04304715453007716,-0.04237673668109984,-0.04146711805979941,-0.04104744888851964,-0.04806920213889869,-0.05724908345314073,-0.05806028535996376,-0.04705008986131656,-0.05150044545899966,-0.050957554073710346,-0.03799011117924836,-0.05743805809471124,-0.04098424591453411,-0.04673698199969767,-0.047555725991974385,-0.04516166459787756,-0.04099029570286418,-0.06128968409758634,-0.05795501334426015,-0.040665860112182706,-0.04074582147357054,-0.05449440288678357,-0.04275091358987042,-0.041965660663248784,-0.05131789851609769,-0.03667080117299304,-0.04837972804135343,-0.040351661631088394,-0.05061807338490444,-0.053902305895195235,-0.044351967050509235,-0.04975361224754222,-0.048765407046958774,-0.04430119477057777,-0.04626960638984919,-0.053411238511834845,-0.04939026071118777,-0.0495619069275024,-0.048218574037083746,-0.0353055922843284,-0.04470536456784854,-0.04534975055108161,-0.03937062773244184,-0.010121548413149401,-0.03941573091229138,-0.055561797041529845,-0.04552578514323741,-0.04849735255834772,-0.038689111844380175,-0.04160946385576816,-0.04439401419258987,-0.05571899851859259,-0.049100948713783656,-0.037904445886027656,-0.05029560075824674,-0.05262519304488557,-0.04077776755621315,-0.037867564098427654,-0.03369108719388947,-0.04745847706487592,-0.05050641534591993,-0.05169584173098941,-0.03910897819330698,-0.043649565239528725,-0.05185658822534908,-0.05096606351226882,-0.047033838732357655,-0.039767371887220355,-0.04042028593179473,-0.04679039797311609,-0.020142098247052247,-0.05792142832187851,-0.04292539791289435,-0.013706145646962684,-0.05107268922628219,-0.03924610731763357,-0.058113460450855255,-0.04065625768753159,-0.011290575073547122,-0.03407498090032533,-0.042462391692009244,-0.05592079096132456,-0.023139397506919263,-0.044458906958243505,-0.02594273112502233,-0.025700708414503032,-0.034252366891598655,-0.04766302961034378,-0.034672359844433204,-0.05174316509446525,-0.06369711093211582,-0.04231434023812783,-0.04693254651052782,0.002425804284783121,-0.04745897309705812,-0.04108645383518225,-0.07814709770257797,-0.036797249831325374,-0.042808656970080856,-0.06006126429552791,-0.06638417113567216,-0.0627720117416367,-0.025128693093784765,-0.039356473723013576,-0.03597546088257721,-0.036008375255531994,-0.03896228716674954,-0.036988281248682475,-0.02841055593924168,-0.039295270790054994,-0.05079425744478282,-0.042659666741177577,-0.039069784948868806,-0.03591140240680636,-0.037894963133995097,-0.05050783344183969,-0.03633839722931504,-0.027336733701504405,-0.05118790877471671,-0.056603120567903904,-0.04319857443542857,-0.0425031898805054,-0.05444172676106144,-0.04024051293397954,-0.0010527879056682142,-0.056705255608878034,-0.04353165916250974,-0.061960398279404125,-0.004168148077306168,-0.0686770154396079,-0.05686335739837588,-0.05239665146260043,-0.06072680366313867,-0.06090577743880948,-0.046482120100809404,-0.06217571813088486,-0.04380381301647564,-0.03367464211694066,-0.0627944343070965,-0.04406907123558501,-0.06684936710454212,0.3041335214420958,-0.062132717909570284,-0.04757340807479905,-0.06441459761522363,-0.06552290630703252,-0.04229143139351094,-0.04625939372856418,-0.05278410746735872,-0.04779713792645986,-0.05508992945059728,-0.03456656272963328,-0.06569467550653281,0.29906495827177304,-0.06415678079919843;-0.04633187666097115;0.03034537638008869;0.0
data/model/LunarLander-v3_11203_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 11203};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 11203};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg_contact_left, leg_contact_right = observations
    on_ground = leg_contact_left or leg_contact_right
    distance_from_center = np.sqrt(x**2 + y**2)
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    
    reward = -np.abs(vx) - np.abs(vy) - np.abs(angle) - np.abs(angular_velocity) - distance_from_center * 0.1
    
    if on_ground:
        reward += 5.0
    
    return reward";-0.12381416647102646,-0.06961962952061734,-0.08577591857196658,-0.09922822367289431,-0.12495974087206621,-0.09963857806472541,-0.0626888392041804,-0.08152097793026485,-0.08568128654698087,-0.10589672196775783,-0.12234743813024646,-0.09388012904797685,-0.08558519886596712,-0.11647226194755322,-0.07424231141394189,-0.1146157302607732,-0.08752779611066797,-0.10269100839665563,-0.0787523504682685,-0.17222874128277296,-0.1848636154772466,-0.09739533408282257,-0.20714347471324973,-0.11487256408859424,-0.09634609059567177,-0.09563731535565739,-0.09936192237201182,-0.13556215721197531,-0.10066120409934873,-0.14302624817855258,-0.12588626190183785,-0.13669680982448626,-0.19267168471079862,-0.1688876503187833,-0.12100402861703043,-0.1746534207704945,-0.14706604408787988,-0.23999568950236447,-0.20916594539660505,-0.16614687790700317,-0.11448736211085128,-0.123634802631508,-0.16729393937753678,-0.14603210917354975,-0.17610515138553193,-0.1811429395364509,-0.13311301369522707,-0.15926496294060258,-0.13909701419827314,-0.13783625949630937,-0.15766532922147233,-0.12095891766332235,-0.12843428569053014,-0.1520953960260741,-0.12463396939835569;-0.12920012437282388;0.038589455086396586;0.0
data/model/LunarLander-v3_228848_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 228848};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 228848};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, theta, omega, leg0_contact, leg1_contact = observations
    if is_success:
        return 100.0
    if is_failure:
        return -100.0
    reward = 0.0
    reward -= abs(theta) * 2  # Penalize non-level position
    reward += (leg0_contact + leg1_contact) * 5  # Reward for being in contact with the ground
    reward -= abs(vx) * 0.5  # Penalize horizontal speed
    reward -= abs(vy) * 0.5  # Penalize vertical speed
    return reward";-0.0638992669798009,-0.0736753398279662,-0.0763102918867103,-0.051388309728103744,-0.09970948592815915,-0.10045148847882814,-0.06858190521690014,-0.10327771186878237,-0.08845370603693907,-0.0713872658427853,-0.061149037904566994,-0.060569359585011896,-0.104503680338052,-0.06412081906232589,-0.06060487029279634,-0.08485026463122057,-0.08034097226152671,-0.13578427852434796,-0.10182966384765464,-0.10904379728766854,-0.06079697065410924,-0.19297231749350335,-0.10700426072073081,-0.11176798930524036,-0.05877243319655954,-0.11468625645079705,-0.08514368164073538,-0.11859887614279233,-0.09954129010948516,-0.09577118143303838,-0.08402392797202894,-0.07434734395968982,-0.0930524152617987,-0.09439541326089329,-0.08722033585130863,-0.07892221314994727,-0.06068780574091929,-0.06788451711703854,-0.0688006825491922,-0.07032569054220371,-0.07023772675173247,-0.06669289698282141,-0.07353497659480059,-0.0732783336536409,-0.07783356142569856,-0.08069936674581109,-0.08419581185330197,-0.22582998698568948,-0.12495480649351343,-0.06599394965727406,-0.06812178899270746,-0.15631601661816694,-0.07138299578146297,-0.1905571571092089,-0.09894745851347425,-0.16994766149777993,-0.09882249193563322,-0.1304090731255659,-0.08091226408779346,-0.05720561382030071,-0.05966994007001069,-0.05889446877581708,-0.18267932116726046,-0.1474986535498655,-0.06946782069561633,-0.07516709130027457,-0.10725566711464768,-0.05500426437258216,-0.059293565916711484,-0.08159041978126248,-0.059181865121430394,-0.05842344775977647,-0.05798211367633761,-0.19862669095615781,-0.06800080963358116,-0.07267986004000827,-0.06016979315940121,-0.054951597440833666,-0.06198397858803243,-0.06682338822397048,-0.12924097904316986,-0.06684448524595817,-0.0694884150781824,-0.054440777352093406,-0.0547800015032383,-0.06949978764139739,-0.08513676023426721,-0.051935080939767175,-0.05379316706756575,-0.0648031822221248,-0.06647316758299794,-0.06099404786423202,-0.06822614652931865,-0.060024283666216725,-0.05586433495237596,-0.06201468922816572,-0.06973952838768714,-0.07377208149556973,-0.07335362908171611,-0.052890919706961845,-0.057844041129124724,-0.06190632887672329,-0.05867760952214834,-0.06181175820623414,-0.052413133549966094,-0.06520823745557434,-0.06126543223045902,-0.05644626219432665,-0.054457526320353195,-0.05733312367802399,-0.055919481837892665,-0.05151136034364578,-0.06688205156560552,-0.0669271957374632,-0.06711293214029608,-0.05843412683070409,-0.06140335492558648,-0.05866866622007882,-0.05926800390425633,-0.06061611555313463,-0.056662054628317284,-0.0656015435703466,-0.06030227544945651,-0.05788815412128902,-0.058862015526243046,-0.058526470089104325,-0.058963675432410184,-0.058132163208076564,-0.06898700227492896,-0.05656436935085187,-0.061198209397749996,-0.05720211492940728,-0.06743285333887027,-0.05164027613332031,-0.05795060864379754,-0.061224866123106465,-0.060601248501774084,-0.05597049999853191,-0.05425509946949912,-0.05366750512520161,-0.05834141182538671;-0.07789547828535026;0.03200770288941098;0.0
data/model/LunarLander-v3_200489_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 200489};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 200489};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, dtheta, left_leg_contact, right_leg_contact = observations
    reward = 0.0
    
    if is_success:
        return 200.0
    
    if is_failure:
        return -100.0
    
    reward -= np.abs(vx) + np.abs(vy)
    reward -= np.abs(dtheta)
    
    if left_leg_contact or right_leg_contact:
        reward += 5.0
    
    return reward";-0.0575662619680807,-0.06453001475473082,-0.06437225179562513,-0.0643413975170193,-0.09581189425366009,-0.10135281077363288,-0.09564744578761886,-0.07422757490971306,-0.05713021006443755,-0.06653969576098769,-0.07057236363890863,-0.08758017606089155,-0.058224272636091944,-0.0682795611424297,-0.08667153570357658,-0.060746235009583094,-0.07970774886953534,-0.07782380579171268,-0.06361097700709636,-0.07058117080567934,-0.07254666072687407,-0.09608941830383576,-0.07143909095649073,-0.06963977604858794,-0.11312356325708324,-0.14947282161067732,-0.17640173804627093,-0.14267149806774443,-0.1969643225521488,-0.2635254559112494,-0.20422580776636987,-0.18292016158263819,-0.15968389921168508,-0.07960444675045382,-0.1487096728895591,-0.17486124993946375,-0.14076828461662183,-0.06595675496674187,-0.08779052921262397,-0.07048491309458295,-0.06608528421822235,-0.09201331574837038,-0.07051688632405975,-0.06331454687723304,-0.09141578834184579,-0.0585711775505543,-0.06002730581185282,-0.05937596343411184,-0.07087954736268305,-0.0694451426426922,-0.06674307143669804,-0.058134165420115624,-0.0733667468227172,-0.07209624393993896,-0.05750725155130309,-0.07413382793631977,-0.06336092501504215,-0.06966961393208672,-0.05409523635216511,-0.0632469312244478,-0.055672078061929364,-0.0601281770959372,-0.05411338876062232,-0.06376489093781822,-0.05973095752674753,-0.06365509334462714,-0.0746179893872128,-0.06519338978359267,-0.07640498449091498,-0.06640762185498664,-0.05204905034878389,-0.05899052037461107,-0.06094844463039343,-0.07192015680107583,-0.058364320305540764,-0.06202340387640796,-0.055871181689012346,-0.06033362543599731,-0.0751035908253057,-0.06274504558846396,-0.06202279565464158,-0.0655263857033997,-0.07145985629277264,-0.061053310971529086,-0.06797708457166726,-0.055786105132742465,-0.05210485090705298,-0.06180415358812097,-0.06360575645340799,-0.05756906383209854,-0.058560695095882714,-0.05525364594204589,-0.05625916417369655,-0.06219324642063841,-0.06704456356061039,-0.05897195843731849,-0.05310787404478602,-0.05956755789355448,-0.0574096287102603,-0.0546388708294669,-0.06547253619148392,-0.06280896471278448,-0.0611115423930348,-0.06025414198501475,-0.06714430872982254,-0.049167675177033986,-0.058438514795065254,-0.06311613771497236,-0.05455374369630114,-0.05922673981861628,-0.05580629351776761,-0.04245479095738849,-0.054145514549732966,-0.06525783725903717,-0.052388286533171104,-0.051691339421183126,-0.06106683665299302,-0.06623976275719803,-0.05387387188750326,-0.058074359779782384,-0.05418203428786214,-0.05741558935699342,-0.05579525614333467,-0.06633905916353386,-0.05525353034847033,-0.06367172245943956,-0.06323026997311529,-0.0678982927147881,-0.07457020065920089,-0.06640098439280757,-0.06643543909124468,-0.0755910230849028,-0.05433252255167062,-0.06116538085390353,-0.07009534936326657,-0.05138345971206727,-0.06490046848088953,-0.06565674666886939,-0.06521743950705854,-0.05629288858995243,-0.06717894568581745,-0.05891583128013266,-0.05710455791091077,-0.06405977385785068,-0.06764484224101971,-0.06478095594424647,-0.05544287392425003,-0.06132988139353272,-0.06719622575813182,-0.07271447771019549,-0.059245262098275804,-0.05749879794273254,-0.06720282936118292,-0.06728781099987796,-0.05852685689337754,-0.055398389581675436,-0.06055635978807425,-0.07457135095647505,-0.052907029835434334,-0.06041266267506928;-0.07258904683007732;0.03131821004305393;0.0
data/model/LunarLander-v3_82523_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 82523};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 82523};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    
    # Define the boundaries of the landing pad
    x_min, x_max = -2.5, 2.5
    y_min, y_max = -1.0, 1.0
    
    # Check if the lander is within the box
    in_box = (x_min <= x <= x_max) and (y_min <= y <= y_max)
    
    if is_success:
        return 200.0 + (leg0_contact + leg1_contact) * 50.0
    
    if is_failure:
        return -100.0
    
    # Reward for staying in the box
    stay_in_box_reward = 1.0 if in_box else -1.0
    
    # Penalize high velocity and angle
    velocity_penalty = -(abs(vx) + abs(vy)) * 0.1
    angle_penalty = -abs(angle) * 0.1
    
    return stay_in_box_reward + velocity_penalty + angle_penalty";-0.06558983802695045,-0.05640494112526063,-0.05845972682256624,-0.05528158031182264,-0.04505043717130315,-0.04007090196337799,-0.03892973534889892,-0.038469525553482986,-0.035859086854824244,-0.044851662210142355,-0.045027281806185794,-0.04619107443172291,-0.03732669413917775,-0.03701497240737335,-0.04349719881433184,-0.04071216663270005,-0.050779093658368565,-0.044408785266141546,-0.07031299101404559,-0.05069566726338445,-0.03908429549618748,-0.04202272709377398,-0.057478339967828036,-0.06780483186245397,-0.03724961470722186,-0.06870148337745186,-0.03990541664163458,-0.0752404945607754,-0.05766976551941903,-0.07839942143347559,-0.04533476420554194,-0.04149659139666966,0.315041107516282,-0.05302779932130636,-0.039276552233412906,-0.040902922212003236,-0.04016814525406758,-0.06700450609587141,-0.04562195200883071,-0.04165342669737186,-0.032186642009139114,-0.045956150157326466,-0.060276802190275924,-0.04023354480167919,-0.03281490753989692,-0.06676992867659735,-0.07054768798024233,-0.045637659417333255,-0.043032666020288345,-0.06033003243972746,-0.036556981908553575,-0.04079612947694024,-0.06942256734372218,-0.07997904697658229,-0.03871614585498684,-0.03903082409337878,-0.04249231266790826,-0.052783117413273045,-0.04725406633491193,-0.04096559237075194,-0.04438007764765241,-0.053814542690817445,-0.04703640034093641,-0.041538871317050974,-0.04326029383718749,-0.05155411885804409,-0.04334828006275293,-0.041957687139305797,-0.042521828543593966,-0.059598424594283744,-0.03057598022476105,-0.02933470055059483,-0.03568696221461277,-0.03499469031860409,-0.03354915200093443,-0.04974078913518227,-0.03892003623873067,-0.06727076095562078,-0.044622947185290605,-0.03656663159043832,-0.035296332061506536,-0.03604786908847954,-0.039726219375955274,-0.034973695917089355,-0.04505615942368466,-0.042589484482823736,-0.04633655294143686,0.3140875423804315,-0.03640721356668554,-0.0314408207107761,-0.032663612825967796,0.01903490222666628,0.04506115210888742,-0.042281732323134216,-0.04266752886153966,-0.022107018938378888,-0.04279997418526864,-0.04058205093825786,-0.038046684659436565,-0.06082803916973383,0.00012682835644845297,0.018240537580121428,-0.04126681968749703,-0.04939202807151715,-0.04775958796161937,-0.05045123397295053,-0.04416661658156366,-0.052920440708587285,-0.019840011739192493,-0.035863996778604336,-0.03289793638957774,-0.049870746759116666,-0.004864893709058306,-0.03870153386867475,-0.040748871418890484,-0.049091226204674716,-0.0435138065747326,-0.046050733082560615,-0.044058423473705616,-0.04014915986465964,-0.04309814111507893,-0.035587085082122744,-0.05614663839180828,-0.04240008618132854,-0.05152472388641601,-0.05292580372496615,-0.05217667646967024,-0.04359285428093736,-0.04564258834100267,-0.04170574324976484,-0.046220628569090504,-0.05549393450340668,-0.04612531274336368,-0.0567160808306935,-0.04977808660839642,-0.04487050155278199,-0.05430733048693899,-0.044275512351995276,-0.0496772576004988,-0.05066960431996598,-0.04196897624021217,-0.059674346193698435,-0.04205819024433994,-0.05385622378135367,-0.04715880467553625,-0.04745292891460996,-0.06468350764152878,-0.05309765185488357,-0.05203939041223432,-0.06387454783121149,-0.04520580074248311,-0.06149823891752958,-0.06085071360312887,-0.050063610730900134,-0.04777159491548701,-0.045112856510084336,-0.049183471524478065,-0.06371107804237024,-0.045155198180105945,-0.042256786777968666,-0.0479412694747324,-0.046859795857772904,-0.04378396690577976,-0.06569407204179924,-0.042923984891463554,-0.051622786660427265,-0.05576383908594361,-0.05126567918109525,-0.0552482491607423,-0.05605888255775792,-0.04121415520855934,-0.04769151929860328,-0.053511831597001236,-0.04827706955437292,-0.04672715730897901,-0.04106667190099976,-0.04612967983697248,-0.053777259157998275,-0.04547967928996647,-0.043643263368251056,-0.04228724007676521,-0.05614978876631413,-0.045125543233801774,-0.045174370270807285,-0.052699852987583534,-0.05215059427636389,-0.04209654363997466,-0.06425123429917223,-0.057345952465190815,-0.04732310486132607,-0.04367910577851255,-0.041578516895634764,-0.044294126648326784,-0.046513929312961166,-0.046019823417374844,-0.05375056887299604,-0.044167849431525026,-0.0594057803295538,-0.06405187805121892,-0.05453117461159286,-0.05474587714664039,-0.05892911270738754,-0.041979425441249135,-0.04944814151845944,-0.059465476690149024,-0.06406268534540806,-0.047335525169928734,-0.047414227021005284,-0.042516590716962045,-0.04654763092616924,-0.060725173387986366,-0.05830703566141443,-0.04098376259824162,-0.05508592108251235,-0.049884815439069766,-0.04634269023901973,-0.045339520118314394,-0.06192021288693843,-0.05666328028707221,-0.04542935455930425,-0.047781798439383655,-0.04828902604424881,-0.05443055879888192,-0.04295096349621487,-0.06428720896610379,-0.06375369326288172,-0.04051201048910861,-0.04489678918536782,-0.046773137374473216,-0.05501371172933054,-0.04667256999600395,-0.05483060763521849,-0.06496862794021292,-0.05413762627310444,-0.06071049499134684,-0.04435836261938302,-0.04412204819832243,-0.05025812219308677,-0.06126660695431218,-0.039903070345778203,-0.041232559291829646,-0.06021655905905618,-0.05918730137602815,-0.05033242491502685,-0.05702708576310191,-0.05496406618518817,-0.044087002473896346,-0.04803677809695521,-0.051099094389565905,-0.053451721494768484,-0.05281786511562562,-0.058193553742102416,-0.056107787249073,-0.05106279250579042,-0.04449914297789281,-0.046779172136939086,-0.04015063566558674,-0.05234889878788416,-0.06511067057708408,-0.03817315799414354,-0.06521920542402289,-0.04933448374005278,-0.039597846861835054,-0.053794617271171005,-0.052165968924900046,-0.048011373625891536,-0.04098388947845491,-0.03967727778009327,-0.058363898154588686,-0.05622729432674016,-0.05848452287455498,-0.057881049526760826,-0.04835375650051986,-0.03926135586955251,-0.03889732541864284,-0.057398341326686385,-0.047180833166265396,-0.051349568978141906,-0.049057224486071936,-0.0434715563922733,-0.05687946878370194,-0.06191444739485344,-0.06159489940506645,-0.049703559233003076,-0.04183222548918184,-0.048270564747026075,-0.05844786052859352,-0.03587980490080593,-0.059897376388569734,-0.051724796578112624,-0.05348212477004689,-0.06141878694284639,-0.05538956501613276,-0.05069519946849036,-0.05882870300061887,-0.04571954441653427,-0.04072146236426564,-0.047603523763568266,-0.027531417507305186,-0.05428082833179326,-0.05173402667910813,-0.04029811310413289,-0.029753525170417454,-0.031606311008681,-0.04878349158059733,-0.036365265668179686,-0.04704556354946444,-0.05325425188314673,-0.05342414573873374,-0.05824527426225306,-0.03379672913019799,-0.02691684573011303,-0.05096071664801299,-0.09780260122916874,-0.048335434095345194,-0.058788209251380535,-0.0623683635721685,-0.03168989392656288,-0.0366321981846959,-0.014933845127696407,-0.012750733415999704,-0.026833629786283966,-0.032454383973321156,-0.021461564079179443,-0.0637967848288327,-0.009963428819033565,-0.04976500163699883,-0.05989125400756663,-0.05158750177072768,-0.003104322155064608,0.012114474265138972,0.0023420515715681773,-0.0619402388755675,-0.04945783968815698,-0.056390946754398485,-0.028939111854944098,-0.06608334706291832,-0.01999531062027308,0.005895393420565663,-0.007706365800016423,-0.009066445829776072,0.02574164412341548;-0.044029428195076194;0.031390859513587145;0.03
data/model/LunarLander-v3_277193_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 277193};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 277193};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y = observations[0], observations[1]
    in_box = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        return 1.0 if in_box else -1.0
    return";-0.0013038795980152337,0.03520474914641131,0.0013038795980152337,0.013038795980152337,-0.015646555176182804,-0.01695043477419804,-0.03911638794045701,-0.05085130432259411,-0.045635785930533176,-0.019558193970228507,0.01825431437221327,-0.045635785930533176,0.011734916382137103,-0.03911638794045701,-0.0026077591960304673,-0.026077591960304673,0.015646555176182804,-0.006519397990076168,-0.05867458191068552,-0.03650862874442654,-0.003911638794045701,-0.04433190633251795,-0.03781250834244178,-0.026077591960304673,-0.05345906351862458,-0.03520474914641131,-0.03390086954839608,-0.05476294311663982,-0.01695043477419804,-0.03781250834244178,-0.03259698995038084,-0.023469832764274206,-0.04824354512656365,-0.023469832764274206,-0.0026077591960304673,-0.03129311035236561,-0.01695043477419804,-0.015646555176182804,-0.04172414713648748,-0.026077591960304673,-0.056066822714655046,0.05345906351862458,-0.05085130432259411,-0.04693966552854841,-0.04302802673450271,-0.04693966552854841,-0.02868535115633514,-0.06649785949877692,0.011734916382137103,-0.04042026753847224,-0.05997846150870075,-0.03911638794045701,0.03520474914641131,-0.06258622070473122,-0.05867458191068552,-0.06389010030274644,-0.01825431437221327,-0.03259698995038084,-0.03781250834244178,-0.04954742472457888,-0.02868535115633514,-0.05737070231267028,-0.01825431437221327,-0.17863150492808702,-0.05997846150870075,-0.05867458191068552,-0.03390086954839608,-0.05737070231267028,-0.02086207356824374,-0.045635785930533176,-0.03520474914641131,-0.05997846150870075,0.0026077591960304673,-0.04433190633251795,-0.06258622070473122,-0.052155183920609346,-0.10170260864518822,-0.03911638794045701,-0.04824354512656365,-0.029989230754350376,-0.04693966552854841,-0.052155183920609346,-0.05476294311663982,-0.05476294311663982,-0.03390086954839608,-0.05867458191068552,-0.04693966552854841,-0.13299571899755383,-0.05997846150870075,-0.026077591960304673,-0.13038795980152337,-0.04302802673450271,-0.14081899658564523,-0.03259698995038084,-0.05085130432259411,-0.19688581930030027,-0.05085130432259411,-0.22687505005465067,-0.1473383945757214,0.02477371236228944,-0.05476294311663982,0.009127157186106636,-0.03911638794045701,0.06128234110671598,-0.15385779256579757,-0.1473383945757214,-0.02738147155831991,0.07953665547892926,-0.12256468221343196,-0.06128234110671598,-0.04824354512656365,-0.24904100322090963,-0.05345906351862458,0.01043103678412187,-0.02738147155831991,-0.03781250834244178,-0.18775866211419365,-0.04172414713648748,-0.04302802673450271,-0.04824354512656365,-0.052155183920609346,-0.04824354512656365,-0.22948280925068112,-0.1590733109578585,-0.07692889628289878,-0.04954742472457888,-0.03520474914641131,-0.03650862874442654,-0.0925754514590816,-0.34683197307205216,-0.029989230754350376,-0.04433190633251795,-0.03781250834244178,-0.03390086954839608,-0.04302802673450271,-0.04824354512656365,-0.03390086954839608,-0.02086207356824374,-0.03911638794045701,-0.03650862874442654,-0.02868535115633514,-0.03129311035236561,-0.03781250834244178,-0.03129311035236561,-0.04042026753847224,-0.029989230754350376,-0.07301725748885309,-0.003911638794045701,-0.03129311035236561,-0.04172414713648748,-0.02477371236228944,-0.04042026753847224,-0.01695043477419804,-0.007823277588091402,-0.03650862874442654,0.06910561869480739,-0.026077591960304673,-0.03259698995038084,-0.005215518392060935,-0.019558193970228507,-0.03259698995038084,-0.03129311035236561,-0.02738147155831991,-0.01695043477419804,-0.029989230754350376,-0.01043103678412187,-0.02868535115633514,-0.02477371236228944,-0.019558193970228507,-0.02738147155831991,-0.03259698995038084,-0.03259698995038084,-0.05737070231267028,-0.045635785930533176,-0.03781250834244178,-0.029989230754350376,-0.03650862874442654,-0.03129311035236561,-0.02868535115633514,-0.03781250834244178,-0.04042026753847224,-0.023469832764274206,-0.04302802673450271,-0.02738147155831991,-0.03390086954839608,-0.04433190633251795,-0.007823277588091402,-0.015646555176182804,-0.01825431437221327,-0.02868535115633514,-0.02477371236228944,-0.045635785930533176,-0.04824354512656365,-0.01434267557816757,-0.006519397990076168,-0.02086207356824374,-0.01825431437221327,-0.03520474914641131,-0.03390086954839608,-0.04433190633251795,-0.04042026753847224,-0.03390086954839608,-0.03259698995038084,-0.01434267557816757,-0.015646555176182804,-0.04172414713648748,-0.03390086954839608,-0.01825431437221327,-0.02086207356824374,-0.03520474914641131,-0.02738147155831991,-0.04042026753847224,-0.02086207356824374,-0.02868535115633514,-0.03650862874442654,-0.02868535115633514,-0.02477371236228944,-0.03129311035236561,-0.01825431437221327,-0.01043103678412187,-0.0026077591960304673,-0.01695043477419804,-0.01695043477419804,-0.0013038795980152337,-0.052155183920609346,-0.01695043477419804,-0.015646555176182804,-0.03520474914641131,0.006519397990076168,-0.03129311035236561,0.007823277588091402,-0.03781250834244178,0.15385779256579757,-0.02868535115633514,-0.009127157186106636,-0.02738147155831991,-0.003911638794045701,-0.03129311035236561,-0.019558193970228507,-0.003911638794045701,-0.01695043477419804,-0.02868535115633514,-0.04824354512656365,-0.02738147155831991,-0.04824354512656365,-0.03911638794045701,-0.03520474914641131,-0.005215518392060935,0.005215518392060935,-0.03520474914641131,-0.02868535115633514,-0.02086207356824374,-0.02868535115633514,0.015646555176182804,-0.009127157186106636,-0.01825431437221327,-0.015646555176182804,-0.03390086954839608,0.01434267557816757,-0.03650862874442654,-0.02738147155831991,-0.01825431437221327,-0.019558193970228507,-0.02086207356824374,0.0,-0.023469832764274206,0.003911638794045701,-0.013038795980152337,0.006519397990076168,0.005215518392060935,0.03129311035236561,-0.023469832764274206,-0.0026077591960304673,0.01695043477419804,0.0,-0.02477371236228944,-0.029989230754350376,-0.01825431437221327,-0.023469832764274206,-0.022165953166258974,-0.01695043477419804,-0.01043103678412187,-0.02477371236228944,-0.03390086954839608,-0.003911638794045701,-0.023469832764274206,0.015646555176182804,-0.007823277588091402,-0.03911638794045701,-0.02086207356824374,0.026077591960304673,-0.045635785930533176,-0.045635785930533176,-0.005215518392060935,-0.011734916382137103,-0.026077591960304673,0.0013038795980152337,-0.013038795980152337,-0.0013038795980152337,0.015646555176182804,-0.029989230754350376,-0.03129311035236561,-0.04954742472457888,-0.04172414713648748,-0.015646555176182804,-0.01043103678412187,-0.04172414713648748,0.04433190633251795,-0.03911638794045701,0.01825431437221327,-0.005215518392060935,-0.022165953166258974,0.015646555176182804,0.013038795980152337,0.006519397990076168,-0.026077591960304673,-0.03520474914641131,-0.01825431437221327,-0.03520474914641131,-0.0026077591960304673,-0.01434267557816757,0.04433190633251795,-0.007823277588091402,-0.022165953166258974,-0.0013038795980152337,0.0013038795980152337,-0.01825431437221327,0.18384702332014796,-0.01825431437221327,-0.02086207356824374,-0.022165953166258974,0.02086207356824374,-0.029989230754350376,0.026077591960304673,0.03390086954839608,0.0013038795980152337,-0.02477371236228944,-0.005215518392060935;0;0.044848702925120186;0.0
data/model/LunarLander-v3_939770_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 939770};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 939770};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, left_leg_contact, right_leg_contact = observations
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        # Penalize for high velocity during descent
        velocity_penalty = -np.sqrt(vx**2 + vy**2) * 0.5
        
        # Penalize for angle deviation from vertical
        angle_penalty = -abs(angle) * 0.3
        
        # Reward for leg contact with the ground
        contact_reward = 10.0 if (left_leg_contact or right_leg_contact) else 0.0
        
        return velocity_penalty + angle_penalty + contact_reward";-0.06139446482531935,-0.09360743222822088,-0.0905315199942246,-0.06517589194178229,-0.06907225795096386,-0.06735481762741047,-0.08229529063355351,-0.09840042601031654,-0.06839751752279152,-0.07075483270507066,-0.07219407469906873,-0.08385485824259926,-0.08925793554812542,-0.09020051093033654,-0.06715106390890169,-0.06905523358927411,-0.08828947836523615,-0.0737475662550166,-0.06277017401812185,-0.06243593451327566,-0.08049312229785364,-0.08885229398858256,-0.07132179392934476,-0.07147385954718476,-0.06621011479331551,-0.0945255305687123,-0.06290983062476914,-0.08960962747484258,-0.09723608579625577,-0.09728515546371407,-0.09158581917585068,-0.09454913190098345,-0.08464956559847812,-0.06932801195392936,-0.09343127313786649,-0.09229886237120404,-0.08553672669220039,-0.0927437662262163,-0.11188914610877072,-0.0868076016885317,-0.10180352701536831,-0.07237096274994247,-0.09970153969082576,-0.09288793637948885,-0.12648993387216215,-0.09289262995766562,-0.118105712018765,-0.126954923309616,-0.1665993329389726,-0.11852076552040243,-0.23296501887636517,-0.09631312520958846,-0.11135973553900924,-0.06297143812839559,0.007843135381775354,-0.06467943584308203,-0.10589207653655364,-0.06511318866689235,-0.06871077970772181,-0.08330497347022253,-0.06804930423888404,-0.06959999950585627,-0.06364704742125096,-0.06830443741480777,-0.06802892013865545,-0.06474988161764994,-0.06493291649525548,-0.10181872541845413,-0.061380168665411614,-0.07187966115168391,-0.07346423599342104,-0.06289558128081471,-0.06327593025824284,0.0189802850147333,-0.059914811199492005,-0.04441165059395222,-0.08229865798584264,-0.0618348806013206,-0.0121847930671196,-0.06444729826821967,-0.0649089559709969,-0.06680097064546014,-0.0669375933908927,-0.06462605199531038,-0.06844843713932634,-0.0479997946888606,-0.06909526043233628,-0.06440995859439252,-0.0692494437381238,-0.07750278142400976,-0.06230693765368339,-0.06671745485270263,-0.06627809681225569,-0.07044433696289444,-0.07011508381165825,0.0048076348356801595,-0.06640399556836346,-0.0651368161085997,-0.05992716449132954,-0.06377603415587703,-0.06891288516343697,-0.06395589801261883,-0.07417038119108016,-0.06844205943592992,-0.06259028941481164,-0.06743594689494282,-0.06980631019887049,-0.06813833463273436,-0.06858212841867312,-0.07340183158125983,-0.06943754430293532,-0.07076514400189433,-0.05703402167498624,-0.0759554583675482,-0.06103653255110608,-0.06429249834878613,-0.06223821499026118,-0.06118325916372436,-0.07038180675764043,-0.06716528642850438,-0.06395798699981169,-0.07251543159422386,-0.06151389064006732,-0.0704931228309143,-0.084301702751346,-0.06603428806659169,-0.06838705504436209,-0.06751983784713596,-0.06235725728586796,-0.0666605567410043,-0.06399016624110034,-0.06997711509455128,-0.0666343825578962,-0.06949585110763008,-0.10557392975432421,-0.06461846955310477,-0.07020083501812494,-0.06631417756989313,-0.07004794810051437,-0.06941112645578687,-0.06150205131642628,-0.06594096734247079,-0.06177809703931657,-0.061468344713171676,-0.0676165996499613,-0.07323224860238667,-0.07241113286948696,-0.05634163078733256,-0.06826197894976876,-0.06302599691731704,-0.06991061791712463,-0.03363791888822894,-0.0739386108780396,-0.06354419294404225,-0.06463437005956622,-0.0696959424039782,-0.057544754572299836,-0.05977251563334789,-0.05179973487347635,-0.058303747908191775,-0.07255600925467223,-0.05580673595983649,-0.07935652875665834,-0.0733544734936801,0.025861256270616185,-0.059795645417746755,-0.06958396457925406,-0.07173530619024285,-0.06895758865549612,-0.07175092290327358,-0.06958676988778031;-0.07233218571158147;0.024819511005649546;0.0
data/model/LunarLander-v3_701903_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 701903};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 701903};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    box_boundaries = 2.5  # Assuming the box boundary is symmetric around 0 in both x and y

    if is_success:
        return 100.0

    if is_failure or (abs(x) > box_boundaries or abs(y) > box_boundaries):
        return -10.0

    reward = 0.0
    reward -= abs(vx) * 0.1
    reward -= abs(vy) * 0.1
    reward -= abs(angle) * 0.5
    reward -= abs(angular_velocity) * 0.5

    if leg0_contact or leg1_contact:
        reward += 2.0

    return reward";-0.01570616870367182,-0.017661215116318855,-0.00493934851593342,-0.018576148463566044,-0.015897316875992294,-0.00621010377424515,-0.005409990588185691,-0.02239079903685565,-0.005443338341935754,-0.019814515122260085,-0.004987811733765818,-0.009711894297043153,-0.007177959096308984,-0.009056789564556338,-0.006904104050098507,-0.008738896806178885,-0.014852371763133487,-0.009675084849363408,-0.005433807549982828,-0.005553203393018321,-0.008299495891713018,-0.009495988887281374,-0.006275727868621909,-0.010348636617422214,-0.00564724741512751,-0.0062640968675964,-0.007318610492173331,-0.005766509872506417,-0.004751884969913525,-0.0032645522911257203,-0.008475792447083252,-0.009875362998235326,-0.012206765179857967,-0.02012740403521479,-0.015566477665102371,-0.006379457137638919,-0.010387102904651242,-0.008199921300509332,-0.021997743899257523,-0.016207762656074366,-0.010469655561841474,-0.016019143997028473,-0.007236543336901148,-0.014116373312079855,-0.018925139902909092,-0.007741021269606368,-0.009593691204624093,-0.007941813922401484,-0.016409603768489316,-0.00909361535726094,-0.011755352855438708,-0.027685818800307755,-0.007101612612910436,-0.010897662621818875,-0.009380304680718122,-0.010085109919856734,-0.007895371862556424,-0.007892957066796937,-0.01818129211053396,-0.006916325508299063,-0.008035172652494638,-0.48325362145807554,-0.7459412372478733,-0.007016837949182629,-0.02436908105045722,-0.013929672407006703,-0.010643436721974313,-0.00959202766369731,-0.009909743888209024,-0.01016961316862221,-0.012542618713194096,-0.01055653441107332,-0.009038669387102044,-0.008395395878835886,-0.006872281108450379,-0.008358797055918679,-0.011999002362642758,-0.008740239671992618,-0.018859042782965154,-0.008267374523638838,-0.013131110694365731,-0.005788356161594409,-0.005708999446194436,-0.009595116382672342,-0.008169647156690185,-0.009280004828522167,-0.16212758514058784,-0.18220472208968694,-0.044236398394359916,-0.008951936094694031,-0.050703895048030065,-0.008573168051018546,-0.006941617073936744,-0.010177064354110246,-0.00653883380712676,-0.00714880644053442,-0.3368630761980726,-0.008166832579173994,-0.0075279559001662135,-0.008023488507656572,0.002908173048100298,-0.008032737819531151,-0.006322739110131573,-0.01101120996884987,-0.008953684145125715,-0.008637740057294686,-0.008753003376108537,-0.006553468980928011,-0.004707594934720068,-0.007804281495901797,-0.018396640641071268,-0.006128984411281954,-0.004437282549901933,-0.013207757821099966,-0.005697532843786575,-0.010079206389503381,-0.014255058254831447,-0.005769162905815011,-0.0044703238589849995,-0.004293656550737975,-0.012027070340530533,-0.007199011908759248,-0.013290091600907763,-0.01068353302463702,-0.0053832792215198905,-0.011853762265141038,-0.017115723961544135,-0.009929030994799581,-0.007641068921548883,-0.014893045995196546,0.1187778565210535,-0.014708586232268311,-0.013598574082044115,-0.015174955207710221,-0.009261438367699947,-0.007918379626237189,-0.0158294859655216,-0.0234381998106202,-0.01032766993316457,-0.009907759234420626,-0.008733323240562604,-0.0074951994139687015,-0.012964230729222074,-0.016139475859417357,-0.014108337604863493,-0.01915360488047093,-0.011713422573128313,-0.01653403279915104;-0.022604953807473037;0.07903020194912048;0.0
data/model/LunarLander-v3_779524_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 779524};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 779524};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y = observations[0], observations[1]
    in_box = -2 <= x <= 2 and -3 <= y <= 3
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    elif not in_box:
        return -1.0
    else:
        return 0.5";-0.052782806877109914,-0.05409147151042669,-0.04100482517725894,-0.05758124386593809,-0.058889908499254864,-0.05758124386593809,-0.036642609732869695,-0.050165477610476364,-0.037515052821747545,-0.06107101622144949,-0.04013238208838109,-0.05670880077706024,-0.04711192679940389,-0.047548148343842814,-0.038387495910625395,-0.035770166643991845,-0.05758124386593809,-0.061507237765888415,-0.06107101622144949,-0.03271661583291937,-0.04798436988828174,-0.05932613004369379,-0.049293034521598514,-0.06281590239920519,-0.03271661583291937,-0.04231348981057571,-0.04972925606603744,-0.045803262166087114,-0.045803262166087114,-0.046675705254964964,-0.054527693054865614,-0.05060169915491529,-0.03925993899950324,-0.05409147151042669,-0.04274971135501464,-0.062379680854766265,-0.059762351588132714,-0.05234658533267099,-0.056272579232621314,-0.060634794677010564,-0.05583635768818239,-0.06194345931032734,-0.06019857313257164,-0.060634794677010564,-0.04623948371052604,-0.05845368695481594,-0.06107101622144949,-0.061507237765888415,-0.06281590239920519,-0.051037920699354214,-0.05147414224379314,-0.05932613004369379,-0.06281590239920519,-0.06019857313257164,-0.05234658533267099,-0.049293034521598514,-0.05583635768818239,-0.051037920699354214,-0.059762351588132714,-0.06456078857696089,-0.05496391459930454,-0.06412456703252196,-0.06586945321027766,-0.05932613004369379,-0.05234658533267099,-0.05670880077706024,-0.062379680854766265,-0.061507237765888415,-0.049293034521598514,-0.06499701012139981,-0.045803262166087114,-0.06019857313257164,-0.06325212394364411,-0.060634794677010564,-0.05845368695481594,-0.051910363788232064,-0.05670880077706024,-0.06281590239920519,-0.056272579232621314,-0.056272579232621314,-0.06325212394364411,-0.053655249965987764,-0.06107101622144949,-0.06456078857696089,-0.058889908499254864,-0.06456078857696089,-0.053655249965987764,-0.06019857313257164,-0.05583635768818239,-0.055400136143743464,-0.055400136143743464,-0.05583635768818239,-0.05060169915491529,-0.06281590239920519,-0.06499701012139981,-0.06543323166583874,-0.05147414224379314,-0.06586945321027766,-0.060634794677010564,-0.061507237765888415,-0.06499701012139981,-0.043185932899453564,-0.05758124386593809,-0.060634794677010564,-0.05496391459930454,-0.04885681297715959,-0.06281590239920519,-0.05845368695481594,-0.059762351588132714,-0.06543323166583874,-0.05758124386593809,-0.05845368695481594,-0.062379680854766265,-0.05845368695481594,-0.061507237765888415,-0.062379680854766265,-0.05409147151042669,-0.06107101622144949,-0.06325212394364411,-0.047548148343842814,-0.052782806877109914,-0.06499701012139981,-0.06019857313257164,-0.05234658533267099,-0.05409147151042669,-0.06412456703252196,-0.06368834548808304,-0.05234658533267099,-0.060634794677010564,-0.06499701012139981,-0.06019857313257164,-0.06107101622144949,-0.06456078857696089,-0.06412456703252196,-0.053655249965987764,-0.058889908499254864,-0.05496391459930454,-0.06019857313257164,-0.062379680854766265,-0.05060169915491529,-0.056272579232621314,-0.06325212394364411,-0.06325212394364411,-0.05932613004369379,-0.05932613004369379,-0.05670880077706024,-0.06107101622144949,-0.05496391459930454,-0.05932613004369379,-0.056272579232621314,-0.06281590239920519,-0.04972925606603744,-0.06194345931032734,-0.05932613004369379,-0.06368834548808304,-0.060634794677010564,-0.051910363788232064,-0.051037920699354214,-0.06019857313257164,-0.06019857313257164,-0.050165477610476364,-0.05321902842154884,-0.05147414224379314,-0.058889908499254864,-0.051910363788232064,-0.05670880077706024,-0.058889908499254864,-0.053655249965987764,-0.059762351588132714,-0.05583635768818239,-0.059762351588132714,-0.06019857313257164,-0.059762351588132714,-0.055400136143743464,-0.060634794677010564,-0.05932613004369379,-0.05060169915491529,-0.05496391459930454,-0.05496391459930454,-0.05932613004369379,-0.058889908499254864,-0.04885681297715959,-0.05060169915491529,-0.058017465410377014,-0.05147414224379314,-0.058889908499254864,-0.05670880077706024,-0.057145022321499164,-0.054527693054865614,-0.050165477610476364,-0.05496391459930454,-0.06107101622144949,-0.051910363788232064,-0.054527693054865614,-0.060634794677010564,-0.04885681297715959,-0.049293034521598514,-0.059762351588132714,-0.059762351588132714,-0.05234658533267099,-0.058889908499254864,-0.05670880077706024,-0.05147414224379314,-0.05321902842154884,-0.04711192679940389,-0.05845368695481594,-0.058017465410377014,-0.05060169915491529,-0.051910363788232064,-0.052782806877109914,-0.044058375988331414,-0.04449459753277034,-0.056272579232621314,-0.05758124386593809,-0.047548148343842814,-0.05321902842154884,-0.047548148343842814,-0.05496391459930454,-0.05758124386593809,-0.04274971135501464,-0.05932613004369379,-0.05583635768818239,-0.058889908499254864,-0.055400136143743464,-0.05496391459930454,-0.04362215444389249,-0.056272579232621314,-0.05234658533267099,-0.05409147151042669,-0.04972925606603744,-0.05758124386593809,-0.051037920699354214,-0.030535508110724745,-0.05409147151042669,-0.03533394509955292,-0.055400136143743464,-0.057145022321499164,-0.049293034521598514,-0.044930819077209264,-0.056272579232621314,-0.051037920699354214,-0.05321902842154884,-0.051910363788232064,-0.03620638818843077,-0.03969616054394216,-0.051910363788232064,-0.059762351588132714,-0.04362215444389249,-0.056272579232621314,-0.03446150201067507,-0.04274971135501464,-0.04144104672169786,-0.04274971135501464,-0.04449459753277034,-0.04972925606603744,-0.04536704062164819,-0.048420591432720664,-0.05409147151042669,-0.031407951199602595,-0.051910363788232064,-0.05234658533267099,0.018757526410873773,-0.05060169915491529,-0.051910363788232064,-0.053655249965987764,-0.050165477610476364,-0.04536704062164819,-0.05060169915491529,-0.05758124386593809,-0.04711192679940389,-0.02573707112189657,-0.053655249965987764,-0.05147414224379314,-0.05670880077706024,-0.051910363788232064,-0.050165477610476364,-0.05496391459930454,-0.048420591432720664,-0.04711192679940389,-0.025300849577457644,-0.044930819077209264,-0.02835440038853012,-0.04885681297715959,-0.048420591432720664,-0.05321902842154884,-0.049293034521598514,-0.04536704062164819,-0.044058375988331414,-0.046675705254964964,-0.044058375988331414,-0.05409147151042669,-0.048420591432720664,-0.049293034521598514,-0.046675705254964964,-0.048420591432720664,-0.04187726826613679,-0.053655249965987764,-0.04144104672169786,-0.046675705254964964,-0.012214203244289897,-0.04056860363282001,-0.03009928656628582,-0.053655249965987764,-0.03097172965516367,-0.04623948371052604,-0.035770166643991845,-0.04362215444389249,-0.044058375988331414,-0.049293034521598514,-0.054527693054865614,-0.05147414224379314,-0.05670880077706024,-0.04449459753277034,-0.03271661583291937,-0.05758124386593809,-0.04885681297715959,-0.04972925606603744,-0.04144104672169786,-0.047548148343842814,-0.03882371745506432,-0.03097172965516367,-0.015703975599801297,-0.034025280466236145,-0.047548148343842814,-0.05409147151042669,-0.04623948371052604,-0.04187726826613679,-0.036642609732869695,-0.05409147151042669,-0.052782806877109914,-0.04362215444389249,-0.02922684347740797,-0.04274971135501464,-0.029663065021846895,-0.04231348981057571,-0.03882371745506432,-0.043185932899453564,-0.03969616054394216,-0.04449459753277034,-0.051037920699354214,0.007415766255461724,-0.055400136143743464,-0.03358905892179722,-0.029663065021846895,-0.032280394288480445,-0.051037920699354214,-0.04449459753277034,-0.051910363788232064,-0.04100482517725894,-0.043185932899453564,-0.035770166643991845,-0.034897723555113995,-0.050165477610476364,-0.051037920699354214,-0.03358905892179722,-0.059762351588132714,-0.050165477610476364,-0.02835440038853012,-0.04362215444389249,-0.04885681297715959,-0.051037920699354214,-0.03009928656628582;-0.051534393838328904;0.010326528503932342;0.0
data/model/LunarLander-v3_534991_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 534991};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 534991};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angvel, leg0_contact, leg1_contact = observations
    
    # Punish being outside the box
    outside_box = (x < -2.5) or (x > 2.5) or (y < -2.5) or (y > 2.5)
    reward = -1.0 if outside_box else 0.0
    
    # Reward for being within the box and centered
    if not outside_box:
        center_proximity = np.exp(-((x**2 + y**2)) / 5.0)
        reward += center_proximity
    
    # Punish high velocities
    velocity_penalty = -np.sqrt(vx**2 + vy**2) * 0.1
    reward += velocity_penalty
    
    # Reward for being stable (close to zero angle and angular velocity)
    stability_reward = -abs(angle) * 0.5 - abs(angvel) * 0.1
    reward += stability_reward
    
    # Small penalty for not touching the ground
    if leg0_contact == 0 and leg1_contact == 0:
        reward -= 0.1
    
    # Immediate success or failure handling
    if is_success:
        reward += 20.0
    elif is_failure:
        reward -= 5.0
    
    return reward";0.007674541361020992,0.009827637757378773,0.011763431236366412,0.01887435582650668,0.014611038092777029,0.007433576593712157,0.012277958970450552,0.015538745625385784,0.018262897868500213,0.014535092864526802,0.013480709485415377,0.011168319975198208,0.016095626773322363,0.005684291976356437,0.016148788934179634,0.014559456373953339,0.015177339592275256,0.02000789461877667,-0.0016037231905152343,0.016711129795360748,0.01804792232447352,0.012692848603823855,0.013889008153224162,0.012579142110878154,0.010963163960350925,0.014911093547837454,0.015323395347691591,0.015284487658667271,0.010517033280701723,0.02255381642818903,0.022986371833212976,-0.12330500482088469,0.022420989541725667,0.01888441195074042,0.011925970369838494,0.019164314716204927,0.014727695546429416,0.020666690964532077,0.020639142936594166,0.012301640370280902,0.015976621277935296,0.019894781097205237,0.013434501267797149,0.016972507758719054,0.015279872212538282,0.022400875687061478,0.02228416441015589,0.013198925829423898,0.018602326887948467,0.013948885207405217,0.020081555358281364,0.016548948353922937,0.021157989699468957,0.020236827522418552,0.009768577669240918,0.016621360691270688,0.023050920254229907,0.023581623687855286,0.02055999724035615,0.0181443248842965,0.01782728076775195,0.021074016926445494,0.013763837995106927,0.015935399013879647,0.13105599965607742,0.02039656814859816,0.05917279236405081,0.019772777151513415,0.01987542672297471,0.020465127197245105,0.02406376407139006,0.07434111330345601,0.05597297340504012,0.015583949081523153,0.02416165472120734,0.140465863260102,0.02618628350736593,0.025122491016510026,0.016037999977955266,0.06486083924137168,0.05939406393719428,0.015666875901524484,0.08290646331478474,0.030871919065798996,0.06867744678353999,0.1706908006961267,0.2839588359764958,0.044186804791027184,0.056265724274720784,0.1252696107307052,0.1815285269071269,0.03127549698476653,0.28111683618051925,0.1735660115139975,0.17699963377518094,0.04010795875137149,0.08953785983516996,0.0353531513403748,0.11884195729037027,0.12893160699603123,0.030816450395068362,0.06616984436227877,0.12805159245754233,0.172077244752695,0.29978045988662966,0.2270986026618515,0.054886882153546854,0.05477644398612832,0.028864550093615077,0.08042272697180163,0.04558921869195358,0.1901500034805256,0.30693508380372875,0.3407952862566495,0.031246384122527476,0.02392239432582725,0.03048381095139538,0.021772853432432075,0.026853053526227643,0.033827896950055024,0.025180127118704893,0.027200476529766187,0.025160841173010987,0.04868608972561541,0.026977761954051084,0.03477722656601034,0.03320676778545298,0.15380829114666308,0.03038732804756228,0.08664813623258183,0.02528089642616985,0.03348516734444772,0.15713315475261797,0.03162560609600194,0.10046186252676635,0.03556605450333006,0.021650928714386695,0.027944738955830814,0.028615968767829274,0.06782788671015058,0.04765108627179289;0.05015765784071352;0.06764915329473234;0.13
data/model/LunarLander-v3_978970_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 978970};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 978970};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    
    reward = 0.0
    
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    
    # Reward for being close to the landing pad (y coordinate should be close to 0)
    reward -= abs(y) * 0.5
    
    # Penalty for high velocity (both x and y velocities)
    reward -= np.sqrt(vx**2 + vy**2) * 0.1
    
    # Penalize large angle deviations from vertical
    reward -= abs(angle) * 0.3
    
    # Reward for touching the ground with legs
    if leg0_contact or leg1_contact:
        reward += 5.0
    
    return reward";-0.041863256701366,-0.06195906091164846,-0.05221562835322784,-0.052512628747844264,-0.04426496257481574,-0.06156159704799565,-0.04566860789913453,-0.054207708495703194,-0.05251649721386632,-0.05944236436522374,-0.048978114446744395,-0.04300508653296064,-0.04832883272154682,-0.04859349356048648,-0.04387236143963716,-0.048264089392135195,-0.04681362810680919,-0.045393685610481085,-0.044967281207967454,-0.04383573651901648,-0.06857533715383535,-0.04413225216746184,-0.04975704653194768,-0.05915968291635996,-0.04358221656685151,-0.0613803969631477,-0.07153217628734834,-0.042463394175883046,-0.041417847674788226,-0.045132335973006844,-0.06472616709280482,-0.04444585430426003,-0.04622696796812815,-0.07309052575258317,-0.053559549977462775,-0.04354511434468338,-0.0530338470712184,-0.048596356443597624,-0.04245200141519318,-0.048347833021789674,-0.04380283429778165,-0.07416823688838457,-0.03483467264021909,-0.04651085462051333,-0.061438764624286935,-0.0438183353430514,-0.044986198328761315,-0.04553358262155731,-0.04805423240908911,-0.05354185403165124,-0.043238172130913625,-0.057158650883295054,-0.04257020614207741,-0.0523537994196803,-0.057871404925722264,-0.04864054808166349,-0.04443574421345889,-0.12102933639515842,-0.04922389985780251,-0.044188078277391,-0.04650570118930277,-0.04695182557927613,-0.044728100381065616,-0.04291343860565362,-0.043863147703665645,-0.03848527835147438,-0.04301637551187263,-0.04275603426603139,-0.019324675817125235,-0.05845810845362269,-0.04565440694991099,-0.046160374783139904,-0.055603539018926375,-0.061270049419868036,-0.04711612620746786,-0.04559941083246014,-0.053906019186201255,-0.046710592432230226,-0.04238258826819283,-0.04790817975637135,-0.04685687007466123,-0.04552357186790751,-0.0484179632788282,-0.04733073241742112,-0.04318055465025008,-0.04317507761197289,-0.04584573629332661,-0.04538583032955922,-0.05820469652652004,-0.04829021795723115,-0.04310331232632922,-0.03734227100089507,-0.04768164272920651,-0.05176335711019496,-0.044217940721392075,-0.04221124304285156,-0.04491584091254858,-0.055651528290868675,-0.04440706963742567,-0.042089230348208356,-0.054529174430193464,-0.05001946002073233,-0.04323166998961035,-0.05423058385592141,-0.038929935984490405,-0.037467512090037555,-0.04716422136521283,-0.042701918728257786,-0.046835986526256895,-0.04514262324484306,-0.050388876398343746,-0.04686022713178658,-0.050639999669962577,-0.04677879938913296,-0.05047151343176311,-0.04962952552556788,-0.05095627123032923,-0.039573121796176045,-0.04206066542810835,-0.04516467881055959,-0.04458228413415733,-0.04278479793593737,-0.04686745675224542,-0.04382703211308465,-0.0497176618304642,-0.04686936969333093,-0.03132650692077891,-0.04934755667667957,-0.04302507182888619,-0.04471372015684932,-0.04757218891324227,-0.04216020456583236,-0.042290755176637045,-0.046968118442564814,-0.04194018490143245,-0.054743251382274156,-0.04436655015684868,-0.043684166755912995,-0.0472260680565127,-0.0339275275962914,-0.04373394472073996,-0.03970039594709213,-0.05141748448812239,-0.04824870782325887,-0.041719024352240286,-0.0458582042710876,-0.04404277829172368,-0.04644782450083858,-0.046961568714059675,-0.041946777787613576,-0.053819469310964235,-0.048119419144108125,-0.053827626363403575,-0.0394376398344809,-0.05172758349411233,-0.05509575625290554,-0.04826096784484704,-0.04895340695408662,-0.048659714569663566,-0.048827501587069146,-0.04770222655474909,-0.04465224418666403,-0.04439856022626991,-0.04618474230465307,-0.04971596535728817,-0.04983381456438525,-0.057778327238066085,-0.047493459688088435,-0.04850607908206668,-0.04117275350634387,-0.05792372930417067,-0.04751701663153387,-0.048093182579117606,-0.04565399581943988,-0.04998915235904509,-0.05160354005816305,-0.05540873529635229,-0.05344661262127519,-0.04723121971591291,-0.054523954515826326,-0.056350166169224475,-0.05637240027503515,-0.04748949799061377,-0.05077212348728511,-0.04857340286197927,-0.05682584868470406,-0.04581982128171345,-0.04902037311018726,-0.04455180521089232,-0.051356772520546955,-0.05057152425359039,-0.05376311505054397,-0.04353322345360733,-0.05271473569147648,-0.05408524205150296,-0.050467698200588405,-0.046280044147856025,-0.05253692358989818,-0.050239571758867854,-0.04314247114716073,-0.05843287934402448,-0.054314302801036225,-0.04962441489968466,-0.04210033074508969,-0.045318588838156905,-0.050030341291988654,-0.05551604098354117,-0.041479520492096765,-0.0437828815588713,-0.04616739258669144,-0.054545475649178686,-0.054968855813034005,-0.050741943778493094,-0.05101628149053602,-0.05403304983399936,-0.057748848340670435,-0.05380059566496014,-0.04790279597974808,-0.05607691804001046,-0.05116242052907549,-0.05938359110045363,-0.04601560409058002,-0.05408522590386772,-0.058923596234088466,-0.05142675188175964,-0.05144607850718727,-0.05415225052970994,-0.05648875568493284,-0.052408569721915356,-0.04145391169159406,-0.056817002438306674,-0.044916034009675504,-0.048754193376757265,-0.04484793627078695,-0.051895303041785114,-0.05458383284663171,-0.05778585141192865,-0.05247346410822649,-0.05149550694215412,-0.04719672470260888,-0.05235832560989246,-0.054937922601621884,-0.05114041631565783,-0.047914489263634494,-0.04780760587133536,-0.056403104661167304,-0.04880959698038748,-0.05827428510287933,-0.059131243467613975,-0.05970693211365026,-0.060313871245956704,-0.03691023799984952,-0.05677472227152909,-0.05192652302472935,-0.051335668769337456,-0.06405107646327304,-0.056040363498515704,-0.05566877103578037,-0.0531715684602575,-0.054104450952213314,-0.055340972530291084,-0.05120582180885254,-0.049808423656287286,-0.04895844980822392,-0.048819620393420894,-0.05525560437202122,-0.0506550012861897,-0.04597482394247227,-0.049881804772568254,-0.05641317234932528,-0.05799217987492952,-0.05545907450224208,-0.05651419499566812,-0.05917421085519716,-0.05193400674896698,-0.06204813194214232,-0.0572079393653784,-0.0554771826859062,-0.0559286171411654,-0.04819676454510956,-0.05765692881295743,-0.04978422086783477,-0.05819186561958316,-0.05453301801033377,-0.05119608287205148,-0.049468662249725126,-0.06334182279326751,-0.05993132361941973,-0.05451488514212999,-0.05053099022604774,-0.06324234997762641,-0.051899382715654675,-0.0506871236038235,-0.05859298685214868,-0.05796538498833642,-0.049335493688456085,-0.07399973202604221,-0.048478644471265896,-0.06724279785070317,-0.09277751990894728,-0.05244639261787657,-0.060585984530641034,-0.041485395392401654,-0.053334308697355115,-0.05856385303495305,-0.05842398858089203,-0.0654041396322748,-0.05847101786383864,-0.040354467379023144,-0.05420807020675947,-0.0534140849013526,-0.05031475573244919,-0.0431985259615646,-0.051882561691807785,-0.04320616385343695,-0.04852438415815604,-0.04437561747685574,-0.060541613204831125,-0.055692332610093764,-0.050524002729513594,-0.05603109089011844,-0.03975275574161335,-0.046011648322629765,-0.06375437022944327,-0.06386740719962758,-0.04799679002557006,-0.05675502771357475,-0.046982410207135936,-0.05917813640170041,-0.055932618060078286,-0.05353178632335906,-0.04984697951797589,-0.05654794524459856,-0.07087815348959804,-0.0628980546291818,-0.053992138048436236,-0.06566287615149473,-0.053835310423016085,-0.05721132632180342,-0.05142001821719245,-0.05301598977992679,-0.0558734210306212,-0.04824047043532749,-0.04691877926254438,-0.051299746522527445,-0.05509549954174676,-0.07304746439864876,-0.055144160279476495,-0.05153231159078726,-0.056008847603108675,-0.05644998921942299,-0.05303809194626896,-0.04605879839069336,-0.0650312677211241,-0.052939672089331445,-0.06871402737078769,-0.06185622998183606,-0.06311544444883367,-0.05982508915266158,-0.07016292922139448,-0.07933509250194762,-0.08234625819987385,-0.05601243390833237,-0.06456394894580154,-0.07195254484172765,-0.05528436465938016,-0.05447416610134514,-0.056976811819205136,-0.05433144593195121;-0.05132776409894289;0.008688367676052453;0.0
data/model/LunarLander-v3_882995_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 882995};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 882995};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    in_bounds = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        return float(in_bounds) * 1.0 - (abs(x) + abs(y)) * 0.1";-0.011836281183878932,-0.023922901233614728,-0.07378226430674503,-0.0647739245316583,0.003918806966275427,-0.035693122089495204,-0.06151869003766996,-0.026198706593798346,-0.02388422396514181,0.03037315177131062,-0.030308288762124568,-0.050892126733845446,-0.0013411967696489457,-0.07295605599978208,-0.07080289699364815,-0.008172951613352542,0.017054889183393422,-0.021291422159272055,-0.05171631578594425,-0.049824346820261954,-0.07189212175809905,-0.04086071427862671,-0.05869398050993664,-0.04521198329880817,-0.03939263232962771,-0.05493866492025116,-0.07103802973464057,-0.03948350768383408,-0.04953127933207847,-0.0199660692341107,-0.054048478353205476,-0.011107078925714461,-0.046902776751835636,-0.06713143753161474,-0.05843152479529295,-0.027218384026153272,-0.041830202587217334,-0.06682429754459303,-0.05827543163492989,-0.06043271861980256,-0.06016262768842644,-0.0679019115715817,-0.014201558721556366,-0.05100965584758067,-0.02030045319461516,-0.09282805173645006,-0.013522363394117226,-0.06793014040796708,-0.044464450802210856,-0.06129077903814044,-0.07094393710296996,-0.061737598097059525,-0.002097116919995779,-0.05589164017023178,-0.06553162297755795,0.003130708147064211,-0.03380264937644783,-0.04212729046259602,-0.05744568679481053,0.03238242243932991,-0.06921125068752765,-0.07150768863960769,-0.008658477323880724,-0.0671626798989273,-0.035618963188542054,-0.040851485070743515,-0.061680723342107314,-0.0764779238041852,-0.045762416357147055,-0.00046934563147034734,-0.02983195126384648,0.03810106614023536,-0.08023634591274677,-0.018722320667878253,-0.053315273214564654,-0.0224139714469247,-0.06283284147791246,-0.0758756098924154,-0.053329869331446345,-0.06480572509058471,0.006477570520249458,-0.06760014746685156,-0.07648919725139564,-0.06469835013770797,-0.08136255700776514,-0.07252369106857766,-0.06839792873322013,-0.05638521474870885,-0.06250425549636834,-0.05173981314564429,-0.06610401333217807,-0.06860592254104297,-0.0649062021323107,-0.054239092299901155,-0.02275858056287116,-0.04668185902668924,-0.07333116278768863,-0.001978502213744385,-0.07884922796384967,-0.052794753596427366,-0.06366982882123166,-0.06298018514967844,-0.07152226012392013,-0.06527015107013535,-0.06840212533125895,-0.06274377547389086,-0.031083080979454253,-0.06322775021229099,-0.0512750672066138,-0.07364064339662972,-0.058742683498014106,-0.06003260863045373,-0.02509107487805608,-0.0766507844424092,-0.038488745743380216,-0.05673301202290376,-0.06077651274960074,-0.06753842291090814,-0.04071440860573418,-0.041545040042399554,-0.0512357614557312,-0.05510002434797264,-0.05929070238861971,-0.0756800469986373,-0.05326917811178292,-0.06285332609844647,-0.042804195752856204,-0.0698817844998313,-0.06358450696773583,-0.06928872865124011,-0.055662854802467396,-0.06406569637836819,-0.04985937406981301,-0.05191914643130567,-0.06295564468864419,-0.07645131033650175,-0.044969195019213676,-0.05467886010992592,-0.06841935634128907,-0.04603899673889171,-0.022982449445760455,-0.051344792157128755,-0.06497565814795353,-0.05513230814512363,-0.05468197964887433,-0.1010944495964641,-0.05577806141681633,-0.068202844766967,-0.05643779833415104,-0.04796625731437718,-0.051815261121730294,-0.10113643519493402,-0.03823680496876104,-0.03925728911775886,-0.06643294751268321,-0.037506194079529404,-0.05586216466192204,-0.04667655123585694,-0.05803370853800847,-0.04715373345531333,-0.06653181182491111,-0.0600201057541174,-0.06522394142590661,-0.07017343253621183,-0.07209451649495822,-0.043199517258716576,-0.049428022768833166,-0.0544891675092936,-0.0694346699380547,-0.04222150907226365,-0.05442570794074048,-0.0651162371883631,-0.07272571605297773,-0.037497169497917884,-0.050011668272183715,-0.03936174229602887,-0.04011739403934436,-0.0479907421761837,-0.03462437244444447,-0.029968329747411464,-0.0618211456138083,-0.044028792144604055,-0.0710859187922513,-0.05451802324456635,-0.03820051433232792,-0.036295440575885005,-0.05567419906831443,-0.026424925335820495,-0.030090611099568967,-0.025515853153878873,-0.04130190620304789,-0.033517641752895934,-0.06651650189136199,-0.032871258327297787,-0.0343529795938101,-0.025858878835489957,-0.03284684771509286,-0.07342839035366343,-0.03007241818770968,-0.03052597073537978,-0.044381941988123216,-0.033892554207425804,-0.04860754698857511,-0.045851612649865287,-0.0326383453326885,-0.05158477390735122,-0.05249832807324108,-0.04378466007038359,-0.015635955808054897,-0.040056662791755904,-0.04441822497086518,-0.04110788205308668,-0.04341152503167193,-0.06423525361310906,-0.04097733770557475,-0.059118574833251225,-0.06282258386026313,-0.049928624139582226,-0.04876366398974627,-0.019158177353747117,-0.06744182875385688,-0.05744972979118537,-0.0035477417671683337,-0.016218446571748462,-0.03723942441024913,-0.05007831415154259,-0.049635552692592975,-0.04984028998678769,-0.03152330062117781,-0.03239627491654068,-0.04399926209274812,-0.021614735187474678,-0.031116131729243497,-0.05957982998532534,-0.02099399743350889,-0.04110757951235223,-0.04400656811278724,-0.06910355208028567,-0.027480900794379315,-0.03174616124022368,-0.033158141633024496,-0.062156239080280576,-0.04858684991213132,-0.06997968647036275,-0.06234681194336968,-0.010355880750919113,-0.059869560200242956,-0.04560938203404389,-0.024327602557924564,-0.03122749689441812,-0.018594372153297813,-0.018216007356214297,-0.044402918908148355,-0.0260180022417379,-0.05440368132137151,-0.022484634106566866,-0.02997649553209082,-0.06308969768172519,-0.015637179606879242,-0.06940579027400039,-0.014894251817209096,-0.07586877347471431,-0.029488017784085125,-0.05264845091463252,-0.06120399225056202,-0.024141123715818027,-0.051638546806020806,-0.03298577135887545,-0.04199427986706154,-0.015695796500291556,0.06654243963488686,-0.05970602351732029,-0.024621230613005373,-0.05154803443031701,-0.059776341496939896,-0.06941481846252383,-0.05412503461896074,-0.06619463101211541,-0.054369933997713296,-0.043800618192397806,0.10847426828521217,-0.013095503754166394,-0.007535848244298402,-0.054524632690736506,-0.012937689305053625,-0.036718535743440424,-0.025940271794190634,0.005001519231310856,-0.03448938024668741,-0.010569660221417665,-0.03779557864671638,0.01977599174958387,0.03536141428169268,0.0059513639456603715,0.01655619947596497,-0.030085906102895573,-0.036022639622024226,-0.052629805731207145,-0.026402638930819407,0.15244060287899075,-0.005794742592633849,-0.07322717683647317,-0.053492180983916206,0.07401874568090382,0.09434838838210505,-0.07492101425924554,-0.0012915617907192692,-0.04114375657504642,0.04813965036799081,-0.013829790702464534,-0.016770370516341112,-0.010599971037745315,-0.063036809356212,-0.01281512661376592,-0.05348837014950653,0.028007312523080856,-0.06830016945564342,-0.05485886762419701,-0.06977261928701095,-0.06049640577570085,0.07448737371284789,0.0009523744792113415,-0.005353204844535114,0.07029384937882414,-0.03870267028211695,0.02979053159865504,-0.004580144472770523,0.0007730627470480546,-0.06704841028991788,0.007795274152924522,-0.05410447574882513,-0.07004306395967619,-0.007958440291626923,0.040613562515336765,-0.006401445500402967,-0.007531145271014623,-0.023393562627845692,-0.034513845314465066,-0.05963420075163998,-0.05563817200037227,0.1076268451779839,0.20496029996997533,0.1769691325125146,-0.05349300054468449,0.07705346431251836,0.06919134563615865,-0.012213921079638848;-0.0381385287650818;0.0377795844873721;0.0
data/model/LunarLander-v3_207173_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 207173};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 207173};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    if is_success:
        return 100.0
    elif is_failure:
        return -50.0
    else:
        distance_from_center = np.sqrt(x**2 + y**2)
        stay_in_box_reward = max(0, 1 - (distance_from_center / 10.0))
        land_smoothly_reward = -(np.abs(vx) + np.abs(vy)) * 0.1
        angle_penalty = np.abs(angle) * 0.5
        return stay_in_box_reward + land_smoothly_reward - angle_penalty";0.0010386115751185084,-0.004131460874053152,-0.006931454481424185,0.02333265582721349,0.00618725462515952,0.003981026274071517,0.014512371439300472,-0.007075778650751453,-0.0050617984004335615,0.0008562504486856174,0.0011611706822372498,-0.002517232803398807,-0.0297655610716035,0.0013149635150361953,-0.027186647164250483,-0.018736868257133305,-0.0020608008623235357,-0.011285784061841176,0.031892050261507855,-0.018893647628305112,0.02309949438589908,0.007898049886054843,-0.006701916593593678,-0.02413650742667439,-0.0021141401656763416,0.01712568924296755,-0.0049933183396276976,-0.015744223009449717,-0.004775512721577553,-0.015251013555005874,0.004752235786381891,0.03475162705792528,0.010469246155684382,-0.01982753626003791,-0.004578630405115578,0.008592588407995393,0.025215408891440187,0.010984347996030928,-0.008596221329567803,-0.013723534615446247,0.01221158455515529,0.013333101516218112,-0.0004163447209508304,0.0013586284594755728,-0.006126076855707883,-0.007238501857596392,0.013795953672718747,0.014909985628247004,0.03405759148451871,0.03786939685943623,-0.009376801633634288,0.00037524098400096837,-0.009639200587959165,0.0008340310446522879,0.006806204593213176,-0.008269725149706565,0.005193178956012397,0.0450043874706728,-0.002277165712529794,0.04482122423663917,0.11019767751769265,0.017731143519855986,0.03159798433541188,-0.0017287976837403328,0.03959428524723016,0.01966042128704338,0.04291602800825451,-0.006909793292669683,0.020410152539758725,0.04614406244896791,0.042723855280358575,0.003932620673281828,0.030462029441446003,0.03947937880265184,0.0248941601816887,0.00016636996072396908,-0.0005912862828339156,-0.006303778825936575,0.014885213358468551,0.04063595106864049,0.03193872724301243,0.01703377110271193,0.006009596115419113,0.052916801590319,0.05285817109764374,0.008787542478105165,0.05806767972735251,0.0318187217820481,-0.00015566562577605221,-0.002335971256711124,0.031107237307459262,0.0313510903065153,0.0012101006975411958,0.047005004169573636,-0.002349348995610634,-0.0004600968366191084,0.09980239360549822,0.07885445247513004,0.054019327485845786,0.09304669639768844,0.012302092815482432,0.09316455073131757,0.006374623217333715,0.009796088612958477,0.2008956653562186,0.05060370139471314,0.026821397498241428,0.06125206165282567,0.0861840301236333,0.1629617239168541,0.06029417747589935,0.16614228795104502,0.04287714342556535,0.007909329780511475,0.16245931522929913,0.14293790841393372,0.36180043706319137,0.5504135618195864,0.03549224571868292,0.033727976109413464,0.03592726395320833,0.24014079763289511,0.028463573520235895,0.037844957362695955,0.07518352255893687,0.05450689331137052,0.027278969494769777,0.029420300222778285,0.027799884884472624,0.061134965046762,0.06864109978918062,0.02236333393002663,0.037666247863545575,0.018476088655017476,0.04261103512690715,0.015126403052297295,0.034965022393108385,0.007026005772885975,0.05528825643796742,0.016605131734953493,0.04952095953094432,0.02245962634548827,0.05576580456880671,0.05624946133193759,0.2021272679436268,0.06104287331806407,0.026533606399601076,0.06351381847425949,0.0468744619801606,0.03194345959802367,0.06946119472259517,0.03556875402377542,0.04479920497370035,0.05999002877859573,0.04836026393638501,0.041904407035464455,0.0520978143349031,0.02441024310815146,0.03972991457630771,0.1709596945852202,0.057777901081844024,0.03167847237229939,0.05148859303312566,0.033466189744447865,0.05116997289794419,0.030241187984499016,0.01496049100865837,0.031190892262718595,0.1515954157693259,0.05964473174957223,0.0356872044881926,-0.0005393681579113486,0.04733157438376049,0.14535503420248214,0.12970006606317103,0.010465322531488583,0.01332225861837885,-0.00020228000216311758,0.02437006076248865,-0.030575713330800666,0.021901051847034374,0.11859029723939793,-0.004931757515318467,0.007237534961441979,0.04931216258496432,-0.033060639994756266,0.04124610453428583,0.036002872110194546,0.005590499735830506,0.00754972486719462,-0.03383905092327001;0.03601385231782717;0.0627583025222207;0.0
data/model/LunarLander-v3_51934_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 51934};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 51934};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    within_box = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    
    if is_success:
        return 100.0
    elif is_failure or not within_box:
        return -10.0
    else:
        return 1.0 - (np.abs(x) + np.abs(y)) / 5.0";0.010373300088626587,0.015480963149372872,0.010109896453039668,0.021196865354969476,0.010757229446007285,0.011314273770306789,0.01667182010427219,0.01668022598352078,0.014220557597636324,0.011797049476134738,0.010795626419009103,0.00976277978714103,0.015448181989721437,0.015621897254073898,0.013148473995624906,0.012833640868034436,0.010449012901136496,0.014440505102568392,0.01389605743697373,0.019128631620297286,0.013444214589233497,0.010783763020636238,0.012072055480616302,0.013726173204610625,0.013059713520709301,0.013657811613158153,0.011173629838440306,0.015387935269083759,0.010293431181359152,0.0147785667018988,0.010485465566618576,0.021233247991370493,0.010224484817027526,0.010130798638455013,0.013043314606880529,0.022173433746936155,-0.052412466927642905,0.009165991635784248,0.008827565084816174,0.008460415703841855,0.007497638078558408,-0.038711872405622724,0.009066048453373134,0.010829940536794739,0.017235356096533205,0.014691637215516824,0.011072083155726668,0.009127231910090159,0.013566997044708972,0.026311690747363625,0.014773042452634735,0.020355002598846657,0.010430465632314811,0.010114951491334992,0.008692927205809805,0.008692772062882251,0.02195440403783375,0.0439199504838237,0.015244973179660833,0.015080346904274256,0.010315670318245856,0.012918412910449192,0.008731881362255866,-0.11049449061859379,0.0078305372357705,0.007281670760081951,-0.17387034359122627,-0.1306027378341008,-0.1084178465628033,-0.35024037500388044,0.009525959480987573,0.012246012848856937,0.027230125370664653,0.010020671047769027,-0.619042726482049,0.012745462952392954,0.00872953168648207,0.011428988969465126,0.060204414614103564,0.015051098834170563,0.008983600212474675,-0.06550462580705212,0.012143766593654801,0.012054877069963683,0.014908453436863665,-0.24464126606579878,0.012112228307260837,0.011076731169229068,0.011399242501057458,0.015757963831883395,-0.24181575600443758,0.009762910433816866,0.008663676196449097,0.01066182715913848,0.01108017904231287,0.017158325587983796,0.008685465934865081,0.00868340103717979,0.013111859341165271,0.00988996049990075,-0.2848853308595367,-0.08457350754376446,0.010356139034982966,0.011441048704342642,0.011735263141888125,-0.22538632371616868,0.00910768870957905,-0.06691783802413503,0.010335899897573083,0.01117656311432238,0.012951104778257887,0.010317199201001253,-0.031144970977423945,0.012614200865040283,-0.1204519005580772,0.008423209899561414,0.010246808188182558,0.048703830709215065,0.012607814189391643,0.011363678033600003,0.012635121998035128,0.008822522507211432,0.013867332906449713,0.010376399296928294,0.009535970707652821,0.01709118880911727,0.012400596848469265,0.011349624382994599,0.014349402384314432,0.014460410733259783,0.0125285424570554,0.019174083264580345,0.024649604177188485,-0.07054607975802636,0.016709560604115284,0.013476935043332347,0.015089352670486694,0.016462178191495803,0.016998681477842094,0.018301288911098505,0.010868598759169318,0.01424161584220647,0.020726655845122805,0.016280966062602466,0.012922956591322338,0.014230674139126438,0.009379684665664923,0.017539522037386963,0.01890000750195939,0.014734034348728274,0.023884031720615647,0.012064834642361251,0.013574329721326897,0.011953621014533303,0.019257176558781102,0.013336276349212436,0.01459507114412665,0.012018326976540894,0.025170913322569568,0.015118146570408157,0.01241590984976298,0.02109887114184234,0.011580682733886611,0.010064914459514431,0.015453386043216475,0.012853031373777201,0.010593636220508428,0.014624704997210735,0.018157698201825213,0.01213900224128128,0.013088270418295911,0.012176843907272259,0.011591368684957375,0.01460119029607833,0.011541200669289351,0.017450037669646774,0.011191643349916038,0.012842078426756373,0.012894527672357813,0.011919785651139431,0.018786444051761286,0.012171377622208851,0.01403781220275643,0.01244196273492822,0.014852329416332759,0.014052916905282537,0.011620516673726248,0.01200679155820376,0.02635266201108169,0.02666062157253379,0.012418128512370043,0.018245918175962317,0.012317031953779103,0.012090576171517958,0.014915980368317932,0.0568010430689162,0.011406895153549871,0.03333105190583204,0.010568761061178374,0.018249765055018165,0.02044959237539139,0.013541836770118785,0.03286030868261833,0.03874704927230493,0.045270614285483714,0.013411429735353794,0.0243856061080223,0.06638818124223911,0.013057095676214561,0.0745435109518136,0.01759975041882003,0.07804882815636736,0.026781208381030687,0.013026647905481352,0.04051663273950038,0.17302675837918477,0.021817637345129228,0.032502370507995045,0.020934737415564984,0.045971041621333975,0.026847766947205157,0.012812893466385564,0.014723253329918194,0.06742077973044898,0.034911649517708206,0.012343468408319703,0.03447680829274052,0.013384894555494702,0.01658867575055932,0.0406057987292664,0.0180240305561664,0.015186796531559948,0.008892620649822562,0.013530668473045444,0.014926904611771515,0.01753793592341271,0.016333158779233928,0.04050642200984911,0.018538843767631902,0.01378023841120517,0.010120966449923961,0.01020281233370991,0.01616532043100825,0.012725749421571416,0.020548635375525467,0.021772969654199354,0.02124725111021068,0.04221051940250841,0.021180086199502714,0.03167457116579519,0.02194610149435917,0.05764985036580498,0.007278534961328844,0.01251870228635256,0.011083864005689342,0.033833579983187055,0.012372287947944491,0.012568670373905117,0.018896074262987998,0.01485273295213232,0.007390651212263218,0.010745208207333847;0.004965437229578868;0.06158034042004707;0.0
data/model/LunarLander-v3_237584_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 237584};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 237584};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_v, leg1_contact, leg2_contact = observations
    in_box = -0.5 <= x <= 0.5 and y >= 0.0
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    elif not in_box:
        return -1.0
    else:
        return 1.0 - abs(angle) / np.pi - abs(vx) - abs(vy) * 0.5";-0.024033587593654246,-0.026631587441182873,-0.0244353825357724,-0.038870648036807544,-0.03643823611420468,-0.018809183372253742,-0.019206372596540504,-0.030695791309994776,-0.030833850151554182,-0.021639568658938898,-0.02273158314326295,-0.020459847635406647,-0.033510844049422756,-0.014040522446866342,-0.03544367839862468,-0.0360430590063259,-0.018975508811875614,-0.017328231739862414,-0.01004017013323491,-0.010243641385439643,-0.020715051686847393,-0.01773328734617168,-0.019064883582079147,-0.009221344465028525,-0.017787758093747746,-0.011601638215991717,-0.028062246267741328,-0.01379178047840315,0.014830440606156162,-0.016745206869240508,0.0021254339432687317,-0.02262493589264479,0.17229582619866685,0.05081026419939156,0.0955052167206159,0.036192831051629924,0.18517338177480003,0.20722172922333496,0.2114391714628185,0.2033106679428311,0.21846484936147406,0.09875088051374924,0.22378404396006313,0.21147649336040417,0.2200597889798344,0.21129266218420575,0.19844863692178527,0.17891975155038342,0.185509606477776,0.21539480567601815,0.19937967157343725,0.19731099815668618,0.21454322741993515,0.19922056932000956,0.21834663805942878,0.1814661705249505,0.214093205879674,0.2060179297006402,0.21463586785242844;0.07319087005317416;0.1076673074021648;0.0
data/model/LunarLander-v3_887945_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 887945};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 887945};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    in_box = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    return 1.0 if in_box else -1.0 if not in_box else 0.0";0.04850801051441757,0.053560928276336066,0.042444509200115374,0.055076803604911614,0.03991805031915613,0.03334925722866208,0.030317506571510982,0.03638100788581318,0.03638100788581318,0.03789688321438873,0.027791047690551733,0.030317506571510982,0.04497096808107462,0.03435984078104578,0.03334925722866208,0.060635013143021964,0.05457151182871977,0.04901330229060942,0.042949800976307226,0.037391591438196876,0.04345509275249907,0.03183338190008653,0.04193921742392352,0.03486513255723763,0.07074084866685895,0.03638100788581318,0.0641720555763649,0.055076803604911614,0.03334925722866208,0.07629905820496931,0.027791047690551733,0.03233867367627838,0.0025264588809592483,0.011621710852412542,0.03486513255723763,0.037391591438196876,-0.07326730754781821,0.040928633871539825,0.0752884746525856,0.059119137814446415,0.027285755914359885,0.09347897859549219,0.02930692301912728,0.06568793090494046,0.067203806233516,0.02930692301912728,0.06114030491921381,0.05052917761918497,0.04901330229060942,0.03082279834770283,0.09651072925264328,0.03587571610962133,0.06770909800970785,0.03840217499058057,0.06518263912874861,0.0793308088621204,-0.0682143897858997,0.0914578114907248,0.03941275854296428,0.025769880585784333,-0.06770909800970785,0.03284396545247023,0.04497096808107462,0.011621710852412542,0.03789688321438873,0.051539761171568665,0.044465676304882774,0.042949800976307226,0.042444509200115374,0.01414816973337179,0.05002388584299312,0.03840217499058057,0.04648684340965017,0.05002388584299312,0.055582095381103466,0.05255034472395237,0.04143392564773168,0.06164559669540566,0.036886299662005025,0.03840217499058057,0.02930692301912728,0.040423342095347974,0.05406622005252792,0.03132809012389468,0.03587571610962133,0.042444509200115374,0.03840217499058057,0.042444509200115374,0.03486513255723763,0.06973026511447526,0.05002388584299312,0.035370424333429476,0.03941275854296428,0.040928633871539825,0.067203806233516,0.036886299662005025,0.036886299662005025,0.038907466766772425,0.05204505294776052,0.04648684340965017,0.03991805031915613,0.03385454900485393,0.05760326248587087,0.05052917761918497,0.04143392564773168,0.03840217499058057,0.04800271873822572,0.03435984078104578,0.03638100788581318,0.03789688321438873,0.03435984078104578,0.03789688321438873,0.03941275854296428,0.037391591438196876,0.04547625985726647,0.040928633871539825,0.04396038452869092,0.03941275854296428,0.038907466766772425,0.040928633871539825,0.04699213518584202,0.04850801051441757,0.05255034472395237,0.03638100788581318,0.04143392564773168,0.040928633871539825,0.05608738715729532,0.04396038452869092,0.05457151182871977,0.04193921742392352,0.04749742696203387,0.038907466766772425,0.04143392564773168,0.040423342095347974,0.04497096808107462,0.04749742696203387,0.05659267893348716,0.044465676304882774,0.03385454900485393,0.04547625985726647,0.04497096808107462,0.04749742696203387,0.04345509275249907,0.04143392564773168,0.040928633871539825,0.038907466766772425,0.05760326248587087,0.04749742696203387,0.05052917761918497,0.04143392564773168,0.04143392564773168,0.03638100788581318,0.04396038452869092,0.05457151182871977,0.05103446939537682,0.04193921742392352,0.04648684340965017,0.04648684340965017,0.04193921742392352,0.03385454900485393,0.05002388584299312,0.04497096808107462,0.04850801051441757,0.051539761171568665,0.06669851445732417,0.042949800976307226,0.0712461404430508,0.042444509200115374,0.04547625985726647,0.040928633871539825,0.05052917761918497,0.05861384603825456,0.03486513255723763,0.07579376642877746,0.04699213518584202,0.03385454900485393,0.051539761171568665,0.06568793090494046,0.06871968156209156,0.059119137814446415,0.04547625985726647,0.12783881937653796,0.05659267893348716,0.08792076905738185,0.04345509275249907,0.055582095381103466,0.03183338190008653,0.08286785129546335,0.04598155163345832,0.08640489372880629,0.0843837266240389,0.04800271873822572,0.03941275854296428,0.08488901840023075,0.08185726774307965,0.07983610063831226,0.06770909800970785,0.03840217499058057,0.036886299662005025,0.06467734735255676,0.06012972136683011,0.09802660458121884,0.05406622005252792,0.10055306346217809,0.0914578114907248,0.07326730754781821,0.04648684340965017,0.0803413924145041,0.040423342095347974,0.04648684340965017,0.05255034472395237,0.0803413924145041,0.0752884746525856,0.05861384603825456,0.09853189635741069,0.03183338190008653,0.0702355568906671,0.035370424333429476,0.04396038452869092,0.10307952234313733,0.08387843484784704,0.06164559669540566,0.040928633871539825,0.03486513255723763,0.0793308088621204,0.06265618024778936,0.07882551708592855,0.10459539767171289,0.06164559669540566,0.0742778911002019,0.19605320916243768,0.037391591438196876,0.17432566278618813,0.06316147202398122,0.10762714832886398,0.0924683950431085,0.06467734735255676,0.06973026511447526,0.05962442959063826,0.13137586180988092,0.06316147202398122,0.15310340818613047,0.07680434998116115,0.10661656477648028,0.08640489372880629,0.11217477431459064,0.06114030491921381,0.09398427037168404,0.06164559669540566,0.1616933683813919,0.10156364701456179,0.10813244010505584,0.10762714832886398,0.13087057003368907,0.10964831543363138,0.10156364701456179,0.08185726774307965,0.16927274502426964,0.0742778911002019;0.05431203767337801;0.030186195930746704;0.0
data/model/LunarLander-v3_346111_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 346111};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 346111};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    in_box = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    elif not in_box:
        return -0.1
    else:
        return 1.0";-0.012238900871237366,-0.023536347829302626,-0.032950886961023676,-0.029185071308335257,-0.012238900871237366,-0.016004716523925787,-0.010355993044893156,0.012238900871237366,0.032950886961023676,-0.04424833391908894,-0.010355993044893156,0.0009414539131721051,0.0037658156526884203,0.029185071308335257,-0.032950886961023676,0.029185071308335257,-0.029185071308335257,-0.02259489391613052,0.03577524870053999,-0.03859961044005631,-0.03483379478736789,-0.042365426092744726,-0.0376581565268842,0.016946170437097893,0.0009414539131721051,0.012238900871237366,-0.04424833391908894,-0.043306880005916835,-0.03577524870053999,-0.0037658156526884203,-0.004707269565860525,0.0376581565268842,-0.017887624350269995,-0.025419255655646837,-0.016946170437097893,-0.016946170437097893,-0.00564872347903263,-0.030126525221507362,0.0037658156526884203,-0.027302163481991045,-0.013180354784409471,-0.020711986089786312,-0.0376581565268842,-0.03954106435322841,-0.014121808697581575,-0.02447780174247473,-0.032950886961023676,-0.04613124174543315,-0.03577524870053999,0.006590177392204736,-0.002824361739516315,-0.019770532176614206,-0.03859961044005631,-0.03483379478736789,-0.043306880005916835,-0.0367167026137121,-0.021653440002958418,-0.013180354784409471,-0.02824361739516315,-0.012238900871237366,-0.0009414539131721051,-0.043306880005916835,-0.020711986089786312,-0.026360709568818943,-0.027302163481991045,0.0018829078263442101,-0.0009414539131721051,-0.030126525221507362,-0.023536347829302626,-0.027302163481991045,-0.03859961044005631,-0.02259489391613052,-0.0367167026137121,-0.007531631305376841,-0.021653440002958418,-0.027302163481991045,-0.010355993044893156,-0.016946170437097893,-0.02447780174247473,0.015063262610753681,-0.0188290782634421,-0.012238900871237366,0.01129744695806526,-0.033892340874195785,-0.025419255655646837,-0.033892340874195785,-0.03577524870053999,-0.02259489391613052,-0.0188290782634421,-0.021653440002958418,-0.032009433047851574,-0.03577524870053999,-0.013180354784409471,-0.03577524870053999,-0.042365426092744726,-0.0188290782634421,0.02259489391613052,-0.02447780174247473,-0.00941453913172105,-0.0376581565268842,-0.0188290782634421,0.029185071308335257,-0.030126525221507362,-0.031067979134679468,-0.03577524870053999,0.013180354784409471,-0.041423972179572624,-0.02259489391613052,-0.033892340874195785,-0.0367167026137121,-0.032009433047851574,-0.017887624350269995,-0.033892340874195785,-0.020711986089786312,-0.0376581565268842,-0.027302163481991045,-0.03483379478736789,-0.033892340874195785,0.0037658156526884203,-0.032009433047851574,-0.03483379478736789,-0.0018829078263442101,-0.04613124174543315,-0.0367167026137121,-0.013180354784409471,-0.0376581565268842,-0.041423972179572624,-0.031067979134679468,-0.031067979134679468,-0.042365426092744726,-0.03577524870053999,-0.03577524870053999,-0.029185071308335257,-0.026360709568818943,-0.02824361739516315,-0.019770532176614206,-0.033892340874195785,-0.033892340874195785,-0.029185071308335257,-0.02447780174247473,-0.03577524870053999,-0.029185071308335257,-0.029185071308335257,-0.007531631305376841,-0.0376581565268842,-0.020711986089786312,-0.029185071308335257,-0.0376581565268842,-0.0009414539131721051,-0.040482518266400515,-0.032009433047851574,-0.030126525221507362,-0.03577524870053999,-0.023536347829302626,-0.016004716523925787,-0.026360709568818943,-0.0367167026137121,-0.03577524870053999,-0.015063262610753681,-0.030126525221507362,-0.032950886961023676,-0.03577524870053999,-0.033892340874195785,-0.023536347829302626,-0.032950886961023676,-0.033892340874195785,-0.03954106435322841,-0.03577524870053999,-0.02824361739516315,-0.03577524870053999,-0.025419255655646837,-0.03483379478736789,0.01129744695806526,-0.03577524870053999,-0.0367167026137121,-0.041423972179572624,-0.026360709568818943,-0.032950886961023676,-0.029185071308335257,-0.03483379478736789,-0.033892340874195785,-0.02259489391613052,-0.016004716523925787,-0.027302163481991045,-0.016004716523925787,-0.03483379478736789,-0.026360709568818943,-0.016946170437097893,-0.032950886961023676,-0.032009433047851574,-0.0367167026137121,-0.023536347829302626,-0.031067979134679468,-0.030126525221507362,-0.010355993044893156,-0.032009433047851574,-0.0188290782634421,-0.015063262610753681,0.019770532176614206,-0.033892340874195785,-0.013180354784409471,-0.023536347829302626,-0.02824361739516315,-0.029185071308335257,-0.019770532176614206,-0.019770532176614206,-0.007531631305376841,-0.029185071308335257,-0.032009433047851574,-0.014121808697581575,-0.0376581565268842,-0.02259489391613052,-0.008473085218548946,-0.026360709568818943,-0.02259489391613052,-0.029185071308335257,-0.014121808697581575,-0.021653440002958418,-0.02447780174247473,-0.016946170437097893,-0.014121808697581575,-0.02447780174247473,-0.0188290782634421,-0.020711986089786312,-0.02259489391613052,-0.019770532176614206,-0.025419255655646837,-0.02259489391613052,-0.02259489391613052,-0.031067979134679468,-0.020711986089786312,-0.021653440002958418,-0.027302163481991045,-0.015063262610753681,-0.023536347829302626,-0.013180354784409471,-0.014121808697581575,-0.019770532176614206,-0.013180354784409471,-0.019770532176614206,-0.01129744695806526,-0.02259489391613052,-0.017887624350269995,-0.025419255655646837,-0.019770532176614206,-0.023536347829302626,-0.013180354784409471,-0.02259489391613052,-0.016004716523925787,-0.020711986089786312,-0.014121808697581575,-0.012238900871237366,-0.030126525221507362,-0.017887624350269995,-0.021653440002958418,-0.007531631305376841,-0.017887624350269995,-0.01129744695806526,-0.0037658156526884203,-0.01129744695806526,-0.02824361739516315,0.014121808697581575,-0.027302163481991045,-0.019770532176614206,-0.026360709568818943,-0.019770532176614206,-0.006590177392204736,-0.002824361739516315,-0.02447780174247473,-0.01129744695806526,-0.004707269565860525,-0.027302163481991045,-0.016004716523925787,-0.008473085218548946,0.0,0.0018829078263442101,-0.0037658156526884203,0.0037658156526884203,-0.0009414539131721051,0.004707269565860525,0.008473085218548946,-0.0188290782634421,-0.0009414539131721051,-0.008473085218548946,0.002824361739516315,-0.002824361739516315,0.0009414539131721051,0.0018829078263442101,-0.031067979134679468,-0.010355993044893156,0.007531631305376841,0.015063262610753681,0.014121808697581575,0.032009433047851574,-0.006590177392204736,0.11956464697285735,-0.020711986089786312,-0.0009414539131721051,-0.021653440002958418,-0.014121808697581575,-0.016946170437097893,-0.004707269565860525,0.03859961044005631,0.010355993044893156,0.0037658156526884203,0.019770532176614206,-0.01129744695806526,0.020711986089786312,-0.017887624350269995,0.014121808697581575,0.017887624350269995,-0.0371874296193988,0.040482518266400515,-0.007531631305376841,0.08943812175134998,0.042365426092744726,0.1468668104548484,0.026360709568818943,-0.012238900871237366,0.1845249669817326,0.03859961044005631,0.0188290782634421,0.2090027687242073,0.4424833391908894,0.2466609252510915,0.6081792279091799,0.1911151443739373,0.0037658156526884203,-0.045660514837947745,-0.05065022061002604,0.02843190808240203;0;0.053852919382407646;0.0
data/model/LunarLander-v3_471913_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 471913};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 471913};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, ang_vel, leg0_contact, leg1_contact = observations
    if is_success:
        return 200.0
    elif is_failure:
        return -150.0
    else:
        reward = 0.0
        # Penalize going outside the designated area
        if not (-2.5 <= x <= 2.5 and -2.5 <= y <= 2.5):
            reward -= 1.0
        # Reward for being close to the ground and having legs in contact
        if abs(y) < 0.5:
            reward += 3.0
            if leg0_contact or leg1_contact:
                reward += 1.0
        return reward";-0.027637693297532573,-0.027637693297532573,-0.029347241336555207,-0.02250904918046467,-0.03447588545362311,-0.027637693297532573,-0.03048694002923696,-0.03048694002923696,-0.042738700975565834,-0.029632166009725645,-0.028492467317043888,-0.03846483087800925,-0.02336382319997599,-0.03561558414630486,-0.037610056858497935,-0.023648747873146428,-0.018805028429248968,-0.019659802448760283,-0.026782919278021254,0.004558794770727022,-0.029347241336555207,-0.042738700975565834,-0.027067843951191696,-0.042738700975565834,-0.028492467317043888,-0.029347241336555207,-0.0307718647024074,-0.028492467317043888,-0.0256432205853395,-0.042738700975565834,-0.028492467317043888,-0.0307718647024074,-0.02820754264387345,-0.024218597219487305,-0.035045734799963986,-0.03162663872191872,-0.028777391990214327,-0.03362111143411179,-0.0359005088194753,-0.03419096078045267,-0.035045734799963986,-0.029062316663384765,-0.031341714048748276,-0.032196488068259595,-0.030202015356066522,-0.03333618676094135,-0.042738700975565834,-0.03333618676094135,-0.026782919278021254,-0.025073371238998624,-0.03248141274143004,-0.037610056858497935,-0.035045734799963986,-0.042738700975565834,-0.029917090682896084,-0.03162663872191872,-0.0359005088194753,-0.03248141274143004,-0.029632166009725645,-0.042738700975565834,-0.0307718647024074,-0.042738700975565834,-0.03419096078045267,-0.03333618676094135,-0.0307718647024074,-0.03162663872191872,-0.04672764639995198,-0.030202015356066522,-0.05185629051701988,-0.0359005088194753,-0.03419096078045267,-0.06610252417554183,-0.03162663872191872,-0.05840955799993997,-0.035045734799963986,-0.04587287238044066,-0.03419096078045267,-0.03276633741460047,-0.029347241336555207,-0.051571365843849436,-0.03048694002923696,-0.026213069931680377,-0.055275386595065146,-0.030202015356066522,-0.031056789375577838,-0.029347241336555207,-0.035045734799963986,-0.026213069931680377,-0.04359347499507715,-0.029062316663384765,-0.036755282838986617,-0.029347241336555207,-0.03561558414630486,-0.0359005088194753,-0.03162663872191872,-0.0359005088194753,-0.036755282838986617,-0.027352768624362134,-0.025073371238998624,-0.03248141274143004,-0.023648747873146428,-0.026497994604850816,-0.03362111143411179,-0.029917090682896084,-0.036755282838986617,-0.028492467317043888,-0.029347241336555207,-0.026497994604850816,-0.024218597219487305,-0.017380405063396772,-0.021939199834123794,-0.03789498153166837,-0.027352768624362134,-0.034760810126793544,-0.029917090682896084,-0.055275386595065146,-0.03248141274143004,-0.03248141274143004,-0.026782919278021254,-0.029347241336555207,-0.0256432205853395,-0.032196488068259595,-0.024788446565828185,-0.03362111143411179,-0.024788446565828185,-0.02592814525850994,-0.03333618676094135,-0.054990461921894704,-0.016810555717055895,-0.029917090682896084,-0.025358295912169062,-0.029347241336555207,-0.031056789375577838,-0.022793973853635113,-0.028492467317043888,-0.02336382319997599,-0.003419096078045267,-0.030202015356066522,-0.02792261797070301,-0.02336382319997599,-0.03333618676094135,-0.0307718647024074,-0.03162663872191872,-0.028492467317043888,-0.02079950114144204,-0.03162663872191872,-0.03248141274143004,-0.03419096078045267,-0.028492467317043888,-0.029632166009725645,-0.029347241336555207,-0.02592814525850994,-0.025073371238998624,-0.016810555717055895,-0.03162663872191872,-0.025073371238998624,-0.018235179082908087,-0.019374877775589845,-0.01766532973656721,-0.03276633741460047,-0.031056789375577838,-0.03276633741460047,-0.028777391990214327,-0.026782919278021254,-0.01766532973656721,-0.024218597219487305,-0.029917090682896084,-0.02820754264387345,-0.027352768624362134,-0.03333618676094135,-0.030202015356066522,-0.009117589541454044,-0.01766532973656721,0.004843719443897461,-0.016810555717055895,-0.011396986926817556,-0.02336382319997599,-0.028492467317043888,-0.030202015356066522,-0.03248141274143004,-0.0205145764682716,-0.009402514214624484,-0.006838192156090534,-0.027067843951191696,-0.03276633741460047,-0.03276633741460047,-0.025073371238998624,-0.030202015356066522,-0.029632166009725645,-0.011681911599987995,-0.024503521892657743,-0.026497994604850816,-0.030202015356066522,-0.029062316663384765,-0.03162663872191872,-0.023648747873146428,-0.024788446565828185,-0.013391459639010627,-0.042738700975565834,-0.03305126208777091,-0.01852010375607853,-0.029347241336555207,-0.031056789375577838,-0.0307718647024074,0.01795025440973765,-0.023648747873146428,-0.02820754264387345,-0.021939199834123794,-0.018805028429248968,-0.042738700975565834,-0.042738700975565834,-0.032196488068259595,-0.042738700975565834,-0.021369350487782917,-0.042738700975565834,-0.024218597219487305,-0.029347241336555207,-0.023648747873146428,-0.02250904918046467,0.01054221290730624,-0.021654275160953355,0.05983418136579217,-0.042738700975565834,-0.015955781697544576,-0.02079950114144204,-0.03333618676094135,-0.024788446565828185,-0.009687438887794922,0.04587287238044066,-0.001994472712193072,-0.011966836273158433,-0.007123116829260972,-0.02792261797070301,-0.042738700975565834,-0.035045734799963986,-0.022793973853635113,-0.01054221290730624,-0.031341714048748276,-0.016810555717055895,0.00997236356096536,0.002279397385363511,0.06866684623407578,0.0718010176389506,-0.019089953102419406,0.006838192156090534,0.05413568790238339,-0.01795025440973765,-0.02307889852680555,-0.011681911599987995,-0.018805028429248968,0.09317036812673352,-0.029062316663384765,-0.0008547740195113167,0.11738896534622083,-0.005983418136579217,0.0,-0.041883926956054515,0.10741660178525546,0.2125538061851474,0.008832664868283605,0.11966836273158434,0.058694482673110414,-0.042738700975565834,0.0359005088194753,-0.02820754264387345,-0.032196488068259595,0.06353820211700788,0.3934809736483761,0.004843719443897461,-0.008547740195113167,0.08661710064381342,0.004273870097556583,0.16212213903397973,-0.041883926956054515,0.060688955385303486,0.0205145764682716,0.08775679933649518,0.024788446565828185,0.01795025440973765,0.11197539655598249,0.029347241336555207,0.1333447470437654,0.13790354181449244,0.1193834380584139,0.024788446565828185,0.0,0.02820754264387345,0.011966836273158433,0.05299598920970163,0.13220504835108365,0.022224124507294232,0.029062316663384765,0.4456221888385664,0.16440153641934324,0.04245377630239539,0.02592814525850994,-0.011966836273158433,0.3584352388484121;0;0.056844624840346795;0.0
data/model/LunarLander-v3_447470_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 447470};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 447470};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y = observations[0], observations[1]
    in_box = -2.5 <= x <= 2.5 and -2.5 <= y <= 2.5
    return 10 if is_success else (-10 if is_failure else (5 if in_box else -1))";0.043058121115888366,0.04510850783569257,0.039469944356231,0.06048640823422413,0.04767149123544783,0.041520331076035207,0.04818408791539888,0.0522848613550073,0.06099900491417518,0.03331878419681838,0.04613370119559468,0.03434397755672048,0.029730607437161015,0.04408331447579047,0.052797458034958354,0.04562110451564363,0.039469944356231,0.027680220717356804,0.03895734767627995,0.027680220717356804,0.03690696095647574,0.042032927755986264,0.050747071315154144,0.030243204117112066,0.03793215431637784,0.041007734396084156,0.03434397755672048,0.04767149123544783,0.02921801075720996,0.029730607437161015,0.043058121115888366,0.03895734767627995,0.03690696095647574,0.03536917091662259,0.06356198831393044,0.02819281739730786,0.04408331447579047,0.02921801075720996,0.03895734767627995,0.041007734396084156,0.032293590836916276,0.02419456329368965,0.042032927755986264,0.038444750996328894,0.02614243067750365,0.032293590836916276,0.041007734396084156,0.030755800797063117,0.024912198645621126,0.038444750996328894,0.04613370119559468,0.0601788502262535,0.04869668459534993,0.01568545840650219,0.02921801075720996,0.022246695909875654,0.02419456329368965,0.02901297208522954,0.025629833997552597,0.024604640637650495,0.041007734396084156,0.03639436427652469,0.040495137716133105,0.052797458034958354,0.03793215431637784,0.02614243067750365,0.038137192988358264,0.03383138087676943,0.024399601965670075,0.03331878419681838,0.032293590836916276,0.0335238228687988,0.026655027357454703,0.02819281739730786,0.041007734396084156,0.03485657423667153,0.027680220717356804,0.03126839747701417,0.03793215431637784,0.03793215431637784,0.03639436427652469,0.03741955763642679,0.042032927755986264,0.02409204395769944,0.02419456329368965,0.038137192988358264,0.04408331447579047,0.0324986295088967,0.03321626486082817,0.04767149123544783,0.03588176759657364,0.03536917091662259,0.03588176759657364,0.04613370119559468,0.04920928127530099,0.030755800797063117,0.03895734767627995,0.0661249717136857,0.03690696095647574,0.03793215431637784,0.05638563479461572,0.04613370119559468,0.052797458034958354,0.03741955763642679,0.03741955763642679,0.04408331447579047,0.039469944356231,0.051772264675056245,0.040495137716133105,0.030345723453102276,0.04920928127530099,0.04357071779583942,0.041007734396084156,0.04767149123544783,0.04459591115574152,0.06099900491417518,0.03485657423667153,0.039469944356231,0.043058121115888366,0.041007734396084156,0.038444750996328894,0.039469944356231,0.05689823147456677,0.06356198831393044,0.042032927755986264,0.0661249717136857,0.05638563479461572,0.043058121115888366,0.04428835314777089,0.05536044143471361,0.042545524435937315,0.04767149123544783,0.041007734396084156,0.04767149123544783,0.04459591115574152,0.05792342483446887,0.042032927755986264,0.051772264675056245,0.05023447463520309,0.05894861819437098,0.050747071315154144,0.04869668459534993,0.04562110451564363,0.05689823147456677,0.06817535843348992,0.04408331447579047,0.042032927755986264,0.05023447463520309,0.03895734767627995,0.1045697227100146,0.04715889455549678,0.04357071779583942,0.04715889455549678,0.0897044189914341,0.04459591115574152,0.10098154595035724,0.09124220903128726,0.04818408791539888,0.042032927755986264,0.06048640823422413,0.051772264675056245,0.0779146953525599,0.05792342483446887,0.041520331076035207,0.06458718167383255,0.10251933599021039,0.04715889455549678,0.041520331076035207,0.042545524435937315,0.051259667995105195,0.05536044143471361,0.04510850783569257,0.042032927755986264,0.0938051924310425,0.06356198831393044,0.042545524435937315,0.04869668459534993,0.04510850783569257,0.039982541036182054,0.08816662895158094,0.05792342483446887,0.04869668459534993,0.08047767875231515,0.05792342483446887,0.050747071315154144,0.10559491606991671,0.05433524807481151,0.06048640823422413,0.04920928127530099,0.03895734767627995,0.051259667995105195,0.0522848613550073,0.06920055179339202,0.0661249717136857,0.06356198831393044,0.0671501650735878,0.043058121115888366,0.039469944356231,0.04459591115574152,0.0650997783537836,0.078939888712462,0.04459591115574152,0.12404839654815457,0.050747071315154144,0.05433524807481151,0.06561237503373465,0.15224121394546244,0.07483911527285358,0.05741082815451782,0.0650997783537836,0.04920928127530099,0.04818408791539888,0.06971314847334306,0.052797458034958354,0.05997381155427308,0.0650997783537836,0.07483911527285358,0.04562110451564363,0.04510850783569257,0.04408331447579047,0.05638563479461572,0.14506486042614772,0.0650997783537836,0.04510850783569257,0.16146795418458137,0.128149169987763,0.07535171195280464,0.05689823147456677,0.1747954678633087,0.062024198274077284,0.13737591022688192,0.05946121487432203,0.05792342483446887,0.06304939163397939,0.13173734674742035,0.09021701567138514,0.07483911527285358,0.1194350264285951,0.12302320318825247,0.05894861819437098,0.12712397662786087,0.12148541314839932,0.128149169987763,0.04715889455549678,0.12968696002761615,0.1163594463488888,0.09790596587065092,0.11687204302883984,0.13378773346722456,0.10610751274986775,0.23015590929802232,0.12353579986820352,0.1609553575046303;0.05516553313190219;0.030155150873996246;0.0
data/model/LunarLander-v3_569224_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 569224};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 569224};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    if is_failure:
        return -10.0

    if leg_contact_1 or leg_contact_2:
        return -2.0

    reward = 1.0
    reward -= abs(x_velocity) * 0.5
    reward -= abs(y_velocity) * 0.5
    reward -= abs(angle) * 0.3
    reward -= abs(angular_velocity) * 0.2

    return reward";0.005783965467093535,0.0023943391550966388,-0.0007060674172397809,-0.001357656069919019,-0.00684015677886814,0.007047991260245576,-0.001477416849972873,-0.0011422600845254446,-0.00048424645965016117,0.0017272828901089261,0.007009484784998999,0.00024518740585144453,0.012377522019652318,0.01798155609600068,0.006096807463856124,0.011734405290943604,0.009179127561060775,0.01395010952395992,0.015868578080535125,0.03311842477496319,0.023152152844293918,0.00784674763195231,0.16640561848227217,0.18774499750543988,0.18235878622935853,0.1934582483901619,0.19411607718267074,0.19501587959050123,0.19862771070439927,0.19787613202000875,0.20022925202413666,0.18149002489675928,0.19104917265464555,0.19201016508806532,0.18435752818164347,0.18771353367353935,0.19793795500064382,0.20003799607013661,0.19072475085005494,0.18909684950200656,0.1977661335691104,0.19304300449506018,0.19426674515426734,0.19087896320535183,0.191841655320601,0.19915695977995823,0.18923348198024664,0.19750965246442964,0.2005038424498916;0.10914197949093467;0.09217478819127557;0.0
data/model/LunarLander-v3_329126_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 329126};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 329126};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, ang_vel, left_contact, right_contact = observations
    position_change_penalty = (vx**2 + vy**2)
    angular_velocity_reward = -0.1 * abs(ang_vel)
    contact_penalty = 10 if left_contact or right_contact else 0
    failure_penalty = -50 if is_failure else 0
    return angular_velocity_reward - position_change_penalty - contact_penalty + failure_penalty";-0.06614378177606973,-0.061720416322609654,-0.060074650190062945,-0.055703566025545714,-0.08245152824044906,-0.052642152421300985,-0.072515208529303,-0.06398486935236733,-0.06566399279007684,-0.061190354061476264,-0.11142157929625993,-0.05869566763970775,-0.07448423939033955,-0.07705561298137065,-0.2584591232284826,-0.06771862907442633,-0.08293177171640417,-0.14744920377631995,-0.07258013591327836,-0.07905396315626707,-0.06281204330809723,-0.11568142748112631,-0.699231313271491,-0.12114638816963441,-0.39471006562561023,-0.3143404051309093,-0.04661097970772472,-0.039545909194029824,-0.03284568918975697,-0.02808246258544459,-0.02646120734713241,-0.02835429722799511,-0.032503956432856154,-0.027050656609420222,-0.028170967809180915,-0.03184290759711228,-0.02864133239301892,-0.04339288926881082,-0.07258315229679874,-0.06247167357617702,-0.05426944676034442,-0.04763192812564652,-0.07734086041426386,-0.03960700564031779,-0.04679989293747794,-0.03875917734217848,-0.031802273416648305,-0.03439296958692499,-0.031332758572183414,-0.03888053864410816;-0.08698474043089079;0.11150629996628243;0.01
data/model/LunarLander-v3_375235_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 375235};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 375235};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    vx, vy = observations[2], observations[3]
    angular_velocity = observations[5]
    leg1_contact, leg2_contact = observations[6], observations[7]

    # Penalize vertical and horizontal movement
    velocity_penalty = abs(vx) + abs(vy)
    # Penalize non-zero angular velocity
    angle_penalty = abs(angular_velocity)
    # Reward for maintaining contact with the ground
    contact_reward = 10 * (leg1_contact + leg2_contact)

    if is_success:
        return 50
    elif is_failure:
        return -50

    return -velocity_penalty - angle_penalty + contact_reward";-0.0688822821642462,-0.037732684441564,-0.05579730745091589,-0.04461007295853292,-0.051942316625970174,-0.03385365088437363,-0.05673169309085734,-0.03250603330284707,-0.02839493513083638,-0.03337053336056861,-0.05803808118087269,-0.043275600818250166,-0.04831582749369582,-0.04146864360137426,-0.04099428071479943,-0.04657017944505429,-0.055182582292957714,-0.06978062919286086,-0.12098355196303112,-0.14123530985533894,-0.072909491291267,-0.09744837940050834,-0.09689248785949248,-0.12117569949875524,-0.12277721542366846,-0.10316447403903083,-0.17195138569446708,-0.14500090526053658,-0.19105714854951988,-0.1118361605294235,-0.07800124643846026,-0.09142927820891718,-0.11723659363779328,-0.06951017447984029,-0.1199781896668598,-0.08636105519869976,-0.059466334067608345,-0.08564208864581317,-0.1116278547303176,-0.06214816109157438,-0.06705009291822814,-0.06533324135227814,-0.07805528753046469,-0.05396054384609741,-0.0863610095561615,-0.05325146065222834,-0.05848994104402129,-0.06126204082305658,-0.07330130870302615,-0.0540180696340494,-0.06348168499354802,-0.07271131714535033,-0.07023734787839038,-0.07618075660601856,-0.08537953167946417,-0.06832210704957457,-0.05281882203703767,-0.06402381333263611,-0.055213400149314126,-0.05442961009284154,-0.057977628698443015,-0.06325039966415287,-0.0575940498958605,-0.06840880495799039,-0.06893546590797345,-0.06513002304170916,-0.06233057631257158,-0.060663121505036444,-0.055046238506984264,-0.06844957276971401,-0.05962234190596656,-0.08076912337776185,-0.06409697702829222,-0.0831401761669435,-0.05468041333137934,-0.07916864353880756,-0.07394682169735535,-0.06062818508455217,-0.07015113846628479,-0.04920544836232158,-0.06305551266863632,-0.06091137616660314,-0.06584468371467513,-0.062189743885382995,-0.05870835360283565,-0.05997731334132938,-0.06216775130578711,-0.056989684137556514,-0.06310138846073582,-0.05750116880517327,-0.06148998163749402,-0.050964241044534994,-0.06186233149539173,-0.06912988330125765,-0.06768451084629895,-0.06380922107531711,-0.050276152686882306,-0.07069901085007066,-0.0614766784733523,-0.07790200334330925,-0.06312734543894807,-0.07333569848389716,-0.0700112487283476,-0.05820395043923608,-0.04766129904763206,-0.06448791983856349,-0.06724489779892065,-0.0707304879209856,-0.057457746656832266,-0.06406331872592887,-0.07154564679311137,-0.0568291236794774,-0.07494457876418374,-0.09594461609503273,-0.05455579646973972,-0.06518599757323289,-0.06658844645844732,-0.0642465018747485,-0.055404840627262364,-0.06971850272417143,-0.06141808253826048,-0.06445081199666836,-0.05458382938257734,-0.07023715327483325,-0.0677325106975651,-0.052969204395120505,-0.07973936270145351,-0.10769171017461682,-0.056174370909344976,-0.06481486205459959,-0.0643490892035333,-0.055136089793437426,-0.0699229752607463,-0.0751018466977817,-0.06830250037819577,-0.06749849073625909,-0.06593861689332114,-0.05900449472851383,-0.06011867531997146,-0.06433283143939542,-0.07344922330577935,-0.056943785077245845,-0.09444766079283556,-0.061844354215892905,-0.05856728219550934,-0.08546105085907418,-0.052566967917511496,-0.058359923071266195,-0.059610250104500606,-0.06285784138299848,-0.07023398306273518,-0.06342272432652352,-0.07523344885065578,-0.05642229882678398,-0.053040190244290276,-0.06575747919631823,-0.07406343101828781,-0.04985071958142372,-0.05988994436645028,-0.07579504794536653,-0.05852536126423762,-0.0895029569758675,-0.06311764718682002,-0.05383943026593442,-0.06428241688504711,-0.07504928749317034,-0.053637317120527855,-0.10802302514456044,-0.07088226246950391,-0.0748402642153924,-0.07016258326809559,-0.06657430058394756,-0.05775525067442027,-0.05833171611420547,-0.07741674995380765,-0.052369580596614645,-0.07398568164281202,-0.06572866284172132,-0.06565516897160062,-0.07231870693724415,-0.059140680197179135,-0.05898049958085002,-0.07524269756529987,-0.05493375414803023,-0.06114902352768697,-0.0708939846385559,-0.07066903329013151,-0.07909966723181659,-0.07365168066462192,-0.06743500020952681,-0.058462785212689425,-0.05116271313234087,-0.06317322320939002,-0.05864358067459877;-0.06861524649851858;0.021132608054976652;0.0
data/model/LunarLander-v3_375235_2.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 375235};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 375235};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    vx, vy = observations[2], observations[3]
    angular_velocity = observations[5]
    leg1_contact, leg2_contact = observations[6], observations[7]

    # Penalize vertical movement more heavily as staying airborne is crucial
    vertical_movement_penalty = 2 * abs(vy)
    
    # Penalize horizontal movement to discourage any deviation from stationary position
    horizontal_movement_penalty = abs(vx)
    
    # Penalize non-zero angular velocity to maintain stability
    angle_penalty = abs(angular_velocity)
    
    # Penalize contact with the ground as the goal is not to land but to hover
    contact_penalty = -10 * (leg1_contact + leg2_contact)

    if is_success:
        return 50  # This condition should ideally never be met in this scenario

    elif is_failure:
        return -100  # Increased penalty for crashing as it's a significant failure

    # Reward function that encourages stationary flight by heavily penalizing movement and contact with the ground
    return -(vertical_movement_penalty + horizontal_movement_penalty + angle_penalty) + contact_penalty

# This new reward function addresses several issues:
# 1. It increases the penalty for vertical movement since staying airborne is critical.
# 2. It adds a penalty for horizontal movement to keep the object stationary.
# 3. It maintains a penalty for angular velocity but keeps it moderate.
# 4. It penalizes contact with the ground heavily, which aligns with the goal of not landing or crashing.
# These changes should encourage the agent to hover in place rather than moving downwards or contacting the ground.";-0.15280406984784492,-0.11765920087382069,-0.1052372908015251,-0.11636328967640146,-0.10964958660168865,-0.10951507499621126,-0.14725505993929888,-0.152547349758519,-0.15818774636486124,-0.11445300192927055,-0.1452805789826215,-0.15452424525096634,-0.13805233918951335,-0.12074607837510896,-0.1318403999331222,-0.15493052083169898,-0.15391444320220962,-0.11826141572220546,-0.1488503629709372,-0.15483513713233424,-0.220687997703021,-0.10811375884573914,-0.08952644430855652,-0.11695936712238363,-0.2059432780876525,-0.1557586005867647,-0.1848604773716594,-0.15011543876360864,-0.09570791674549156,-0.15616289158305705,-0.15463020112164563,-0.1446193633189221,-0.11296058373528706,-0.12697493952179195,-0.23140227600253183,-0.12599610496057134,-0.13436752601650892,-0.1057343510561189,-0.10201359702892344,-0.11803530239244006,-0.10920830277974346,-0.13418126691572657,-0.11725590601321613,-0.1524905894299687,-0.10140662016344924,-0.114113209186824,-0.09067537948413566,-0.0916138249154502,-0.11428792095969909,-0.19066424300397594,-0.08983733502492701,-0.10072514395557382,-0.13069738384396337;-0.13363461762885823;0.03177598935502599;0.0
data/model/LunarLander-v3_757152_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 757152};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 757152};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg_contact1, leg_contact2 = observations
    
    altitude_reward = -abs(y)  # Punish being close to the ground
    velocity_penalty = np.sqrt(vx**2 + vy**2) * 0.1  # Penalize high linear velocities
    angle_penalty = abs(angle) * 0.5  # Penalize deviation from horizontal
    angular_velocity_penalty = abs(angular_velocity) * 0.2  # Penalize angular velocity
    
    leg_contact_penalty = (leg_contact1 or leg_contact2) * -5.0  # Penalize touching the ground
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    
    reward = altitude_reward - velocity_penalty - angle_penalty - angular_velocity_penalty + leg_contact_penalty
    return reward";-0.034932255418911436,-0.036823201753550194,-0.032426862312876455,-0.04231631805565812,-0.03124926533307876,-0.05164739660567139,-0.030745129640446858,-0.030109023366615334,-0.05515186132759493,-0.02996559643146865,-0.03154109456639094,-0.03913840625372516,-0.0521144268599134,-0.03402307940096172,-0.03141082092447578,-0.04891186519170003,-0.034741004749656426,-0.0437273995069915,-0.03915306698598273,-0.04349175489669036,-0.03362273173516361,-0.03215102188360721,-0.03568655048220946,-0.02952715770018862,-0.03567503007219833,-0.03567983177838088,-0.04276208190185496,-0.04286073436650739,-0.03981382058642693,-0.04150579916611433,-0.036306370154150495,-0.02860781720852927,-0.03676807539725914,-0.029723394419589502,-0.033347594226921976,-0.02682431449590165,-0.03740395347553107,-0.03083767863706301,-0.028685861788154493,-0.029123329268401082,-0.03491572329015302,-0.03337216770050988,-0.03646816091364945,-0.027722212480494033,-0.03855981224884677,-0.029479508084674314,-0.029275269051802163,-0.029015859274890594,-0.030979457312455543,-0.032340035947009946,-0.03011591484737507,-0.03634555506735395,-0.03036831216555632,-0.034016735795796824,-0.03175842359576555,-0.039257466572503896,-0.026683270761872803,-0.035602120079932506,-0.030596917696791664,-0.03473333211071081,-0.03367129590042244,-0.03766008053692634,-0.029483252637486176,-0.03633712399127009,-0.04427063671039486,-0.02791199733305538,-0.03516116125944354,-0.03466700798482424,-0.037729237952056384,-0.041733944137583925,-0.03384473571821275,-0.03387421454464547,-0.032433836055783025,-0.03349845211699713,-0.028399515020244816,-0.041406207637510385,-0.03172614552189834,-0.03415239446452892,-0.038190081375592586,-0.03185038905882569,-0.04237218286523724,-0.03683083265985463,-0.035168409040195046,-0.029060429707452616,-0.03777645798405539,-0.035544084275149684,-0.02986835179186453,-0.03763036990809277,-0.03648916676332861,-0.03024071576441137,-0.03267861681036926,-0.03447312254368732,-0.03559618717239008,-0.03362292450364092,-0.03568160740118946,-0.03595656083226116,-0.0495742756380276,-0.03841037141897534,-0.03643027220837986,-0.05271304794704714,-0.034996440344182124,-0.04334928695803895,-0.056627503208183376,-0.04920756578933449,-0.02893643945235842,-0.034674899997190714,-0.04552427014427573,-0.03462864452843343,-0.03319294729367376,-0.05269424611210027,-0.12295655896757837,-0.06144900726028898,-0.1043843044848501,-0.046314145699904795,-0.23301511360123905,-0.03673661657659389,-0.03692865618721853,-0.04861412672362714,-0.035130578778067294,-0.03516514903033447,-0.06309048306167722,-0.032823560660837574,-0.09418692405662556,-0.04309139097958405,-0.051415490381150564,-0.08151351206873832,-0.05854259189626751,-0.04044691833907168,-0.049484585116975975,-0.03277614991005269,-0.03447021419571824,-0.09213173447589917,-0.05580185790880098,-0.03775630456615667,-0.042453159732406626,-0.04594811592549094,-0.07955609230909913,-0.060000486440172605,-0.10032434986197292,-0.043724603768916064,-0.05609747233858746,-0.48234537917252934,-0.036298318245329336,-0.030047183919417943,-0.04577300512689884,-0.05005892165364154,-0.04488598017946713,-0.03867736460014335,-0.5798034384044054,-0.04013071492426007,-0.10567533426836434,-0.0829050886178739,-0.03462499897905291,-0.041277506137146217,-0.038983707441991415,-0.044251680228922625,-0.03646305208724301,-0.03880363090546471,-0.03727495865636971,-0.03620996425264359,-0.028906691803378244,-0.03152856784510497,-0.038046102675824506,-0.15413930538546167,-0.04529672881206507,-0.07066643502228614,-0.04988710496059075,-0.03738955945456181,-0.08734101300789973,-0.03973002067334062,-0.12709334740112307,-0.03819141783084681,-0.041372830641716804,-0.03171812149811589,-0.041593366208119494,-0.03280091206299631,-0.035537851514296295;-0.049108197933607566;0.05690432681121809;0.03
data/model/LunarLander-v3_386202_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 386202};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 386202};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, v_x, v_y, angle, angular_velocity, leg_left_contact, leg_right_contact = observations
    vertical_speed_penalty = -np.abs(v_y) * 0.1
    angle_penalty = -np.abs(angle) * 0.1
    angular_velocity_penalty = -np.abs(angular_velocity) * 0.1
    contact_penalty = -(leg_left_contact + leg_right_contact) * 1.0
    reward = vertical_speed_penalty + angle_penalty + angular_velocity_penalty + contact_penalty

    return reward";-0.11836339789155773,-0.151106490783542,-0.2550722388327017,-0.20687638844500034,-0.16386453040346516,-0.14863763387321366,-0.11517231102981441,-0.18543085127581524,-0.13386846627192436,-0.17579074623009844,-0.15495184962706585,-0.0991062925627143,-0.14841297972648398,-0.38978865183971284,-0.07368991996673495,-0.18868497132578047,-0.10249607532964747,-0.2717794912046358,-0.1264851350822931,-0.12213199000791718,-0.14361374310704625,-0.15450522428667995,-0.13448436927942684,-0.1448727392163502,-0.10746328992965434,-0.10338267619547065,-0.07665087050413397,-0.11587556355070718,-0.05832937047167743,-0.05030575578259812,-0.22766142426282518,-0.047944853461582684,-0.04706115898800911,-0.05268737692130533,-0.03976389752884693,-0.05066841252280622,-0.05123653218550751,-0.05834536314780353,-0.050141090908406884,-0.026918535449108216,-0.042748333061990405,-0.028969771083408948,-0.026810494684377625,-0.026877725886338886,-0.04910396924033514,-0.14164382386278745,-0.04018534615203283,-0.04310114895131872,-0.03483154250383308,-0.04959188134404039,-0.02805661896684207,-0.03967276440157996,-0.030447689402742242,-0.04708993117406948,-0.015689641054701175,-0.019731634916893767,-0.039238031516021225,-0.03310570848514625,-0.035268811767207184,-0.02146746585334735,-0.03608069518259582,-0.024989157958791912,-0.020909758875680112,-0.03319015858925423,-0.032968384191420834,-0.028283567525192996,-0.0468322991766482,-0.044956408416687646,-0.02246793878966598,-0.03816979710693557,-0.02301381879195882,-0.018181146807304278,-0.036028508852730526,-0.017078064586849885,-0.022214854524813657,-0.022371605044409718,-0.026664371483694833,-0.031253850282337396,-0.022609197181955726,-0.06473678061009473,-0.05526356576207136,-0.027441381048517576,-0.043073280862960514,-0.01579133205118903,-0.05526332783629497,-0.06855067827160814,-0.019764180885487353,-0.03954627163681634,-0.031550134216731,-0.021713131605396795,-0.033075245985136746,-0.04078552315492355,-0.011227510541474838,-0.021947285656438942,-0.03527350562684763,-0.01513144593461722,-0.030072366083129937,-0.05205282853119934,-0.02093968016679726,-0.03175482683812086,-0.01459892228502545,-0.014354209395745865,-0.016459557231660732,-0.027277969503227143,-0.036756165073975444,-0.02206713596920198,-0.025710063542005814,-0.018089387438956418,-0.044327327750466355,-0.017177222496497176,-0.03804020781493785,-0.020285018297854288,-0.03365904148513494,-0.02836928905001692,-0.024142332177319027,-0.02237049211509434,-0.041157138473533486,-0.03844883593103194,-0.019661210705468293,-0.024422973105275022,-0.04006496933523648,-0.029325498553235598,-0.019976210689673854,-0.03607358995156223,-0.06417128166629922,-0.044665969676912665,-0.02314019832115596,-0.03047670202126836,-0.10889063218993762,-0.01566142847569952,-0.04251976106169353,-0.024427454663513006,-0.0884897795053829;-0.061997976213141806;0.0606221736492177;0.0
data/model/LunarLander-v3_386202_2.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 386202};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 386202};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, v_x, v_y, angle, angular_velocity, leg_left_contact, leg_right_contact = observations
    
    # Penalize vertical speed to encourage hover rather than descent or ascent
    vertical_speed_penalty = -np.abs(v_y) * 0.1 if np.abs(v_y) < 2 else -5  # Strong penalty for significant vertical movement

    # Penalize angle to encourage the lander to stay upright during stationary flight
    angle_penalty = -np.abs(angle) * 0.1
    
    # Penalize angular velocity to encourage stability
    angular_velocity_penalty = -np.abs(angular_velocity) * 0.1

    # Reward for being off the ground (neither leg in contact)
    hover_reward = (leg_left_contact + leg_right_contact) == 0

    # Penalties if the lander is too close to the ground but not landed
    proximity_penalty = -np.clip(y, 0, 10) * 0.1  # Penalty for being too low without touching down
    
    # Combine all rewards and penalties into a total reward
    reward = vertical_speed_penalty + angle_penalty + angular_velocity_penalty + hover_reward + proximity_penalty

    return reward";0.020809132078547586,0.03477791035673415,0.026808173505185554,0.029573969649130134,0.028445186954077693,0.031692000443590065,0.026029422770297326,0.040627268332062164,0.02698155298029931,0.03496165079223653,0.03798123195574315,0.029265740286182937,0.024852737424851914,0.025170114514211313,0.034672065709275536,0.0204713524378646,0.020122500285624817,0.03193991449025941,0.03021853118339117,0.03765645733330397,0.035327698219036044,0.050567642773804135,0.019811107303997565,0.017736677944462834,0.02643580740133719,0.019144639311908948,0.021510985740819073,0.03247590677692519,0.021297068856340726,0.042708160414340064,0.03567728515792113,0.018998731842963742,0.024352986941243406,0.01976774747645583,0.03245924651230841,0.040274180621035945,0.019864676968511685,0.0710698437764306,0.0518182422308427,0.027449781935966498,0.040675469557020824,0.02069878461818941,0.041226434388566276,0.02097952190166219,0.026528755083194258,0.046822760355091655,0.08799526958410865,0.02905034262743194,0.07826494122626888,0.07732739989830208,0.03992368558207132,0.03241977308598176,0.02600657729394637,0.03931859229918156,0.04134922210542303,0.040007303610342465,0.02670800324541359,0.09513393356738181,0.05899432259707579,0.0802578821864467,0.10149700238564685,0.026014497202984255,0.0920784528884737,0.027738129381328004,0.04057986084739388,0.05799309422548103,0.059923070984432274,0.11570009668632217,0.06766016125937126,0.2451363367774938,0.03640214248911163,0.11022775658757779,0.15731390999325118,0.17192545253475727,0.14037600663867048,0.05596644749967592,0.19253365621802074,0.043071861972753006,0.05550724660009103,0.09178145921011045,0.1281622757932717,0.09535321525774855,0.041902271577719835,0.1543800381172542,0.0793655104390396,0.10274762462523675,0.1378003848275563,0.09682071379386205,0.10816642549942718,0.038729624673063776,0.04150621389941381,0.057742846232243274,0.06645061684835567,0.04801609097574079,0.06198614087162756,0.056929305022173686,0.05305200825145717,0.09531033346348673,0.047030832704638405,0.06304526580367434,0.04215722559553343,0.05931870927180095,0.054424128948817485,0.08348160131091725,0.03896540521038154,0.052169513408135075,0.10642380690812342,0.0781858439028135,0.09113469959673996,0.08067295796404325,0.06719379354836447,0.051883170826867366,0.04662901822355368,0.0866111748009958,0.10011401540833188,0.0896769546784847,0.08566953734969669,0.0545579770551367,0.05156431217985196,0.08485510111566923,0.13948591771104646,0.09277963292923545,0.09423438305771763,0.09315369054426072,0.08175728377557422,0.06485497931388147,0.04635228229607087,0.11324196458232438,0.0723625959725231,0.0503708776846051,0.0925206671476245,0.1492347048273765,0.07520864882486163,0.07075235259118594,0.07229748489226392,0.08828076432076563,0.050473539238636934,0.1024415216567354,0.09051873190035854,0.046253688122663124,0.18770855734554048,0.1606467234428008,0.09536193358872494,0.10639062067317877,0.09604893764643398,0.06297104238113413,0.08925704136964727,0.08905753382828752,0.08192302552752467,0.06365599548018468,0.0633304258355551,0.08682279891570513,0.08797994275326021,0.07115014182478409,0.04202396206275833,0.09226957950308416,0.06997524390241151,0.058354396785985904,0.06888682452965267,0.06541550414212023,0.09466900365308396,0.07087020996452657,0.06725939487060362,0.05712926197462353,0.08588782834838105,0.1100961902904432,0.06856002024573012,0.07159144626047506,0.0426577971395028,0.04745233771279639,0.028320594667887382,0.12203715473049838;0.06589212103287126;0.03836902232480704;0.0
data/model/LunarLander-v3_386202_3.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 386202};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 386202};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, v_x, v_y, angle, angular_velocity, leg_left_contact, leg_right_contact = observations
    
    # Penalize significant vertical speed to encourage hover rather than descent or ascent
    vertical_speed_penalty = -np.clip(np.abs(v_y), 0, 1) * 2 if np.abs(v_y) > 0.5 else 0

    # Penalize angle away from upright to encourage the lander to stay upright during stationary flight
    angle_penalty = -np.clip(np.abs(angle), 0, 0.3) * 2

    # Penalize angular velocity to encourage stability
    angular_velocity_penalty = -np.clip(np.abs(angular_velocity), 0, 0.5) * 1.5

    # Reward for being off the ground (neither leg in contact)
    hover_reward = 1 if (leg_left_contact + leg_right_contact) == 0 else -1

    # Bonus reward for maintaining a safe altitude without being too high
    safe_altitude_reward = np.clip(y, 15, 30) * 0.1

    # Combine all rewards and penalties into a total reward
    reward = (vertical_speed_penalty + angle_penalty + angular_velocity_penalty +
              hover_reward + safe_altitude_reward)

    return reward";0.0029583680086914463,0.009012901164208002,0.007026537508137765,0.01889284780137243,0.004441527913863792,0.002107475022117498,0.009073107581219557,0.00795516549419935,7.490394702978255e-05,0.026909939147402185,0.008401492252134926,0.004352706610707204,0.03193799971312235,0.012406046631429407,0.03038461232761518,0.025369271581918196,0.02185485649314927,0.03399247860985972,0.03141288637408187,0.046372467374889086,0.09634857286145417,0.09338404432172696,0.0364708918638239,0.0204922084180835,0.03560384572009684,0.13925587086594607,0.04433513559102197,0.05554095920234855,0.029859769714412617,0.034290497649044065,0.042472299581868586,0.026072090340178114,0.15447377967527293,0.05555561538252384,0.1056550694598406,0.15352780879795822,0.15160727136564234,0.0669840122355869,0.13224792620559528,0.13505266650311473,0.07044046063204411,0.14197212531760384,0.10306236446058153,0.10053109782065447,0.1214334181085989,0.177083863284974,0.2052848377132494,0.16741773266875873,0.06558331626411926,0.02582292044055511,0.0419822516159163,0.17841692696273903,0.23778954044778766,0.22044313221092138,0.09903276764335396,0.06976054099675487,0.24236144615981842,0.22370479904767734,0.20979220732888074,0.24222231893657617,0.04273057335540627,0.24310578506637218,0.07478203920179224,0.05450612090411085,0.2420482011560767,0.032361916571943254,0.044955642790876674,0.03988353955405628,0.05354144863532911,0.2423114365870908,0.06506926705015609,0.04316411109083845,0.034552101586462894,0.24270917550840654,0.0371205928025027,0.07185012502591881,0.08687964452916064,0.04274774270533669,0.08783119738602181;0.08443616021369763;0.07435565006418846;0.0
data/model/LunarLander-v3_53536_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 53536};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 53536};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    y = observations[1]
    vx = observations[2]
    theta = observations[4]
    omega = observations[5]
    leg1_contact = observations[6]
    leg2_contact = observations[7]

    reward = 0.0

    if is_success:
        return 100.0
    elif is_failure:
        return -100.0

    # Reward for maintaining altitude
    reward += max(0, y)

    # Penalize for contact with the ground
    reward -= 20 * (leg1_contact + leg2_contact)

    # Penalize for large horizontal velocity deviation from target (e.g., target vx = 0)
    reward -= abs(vx) * 5

    # Penalize for angle and angular velocity to maintain stability
    reward -= abs(theta) * 10
    reward -= abs(omega) * 10

    return reward";-0.004968385546365473,-0.0031676979106300186,-0.008701838259734649,-0.0046132067432232485,-0.004278491742662187,-0.0014991763570629158,-0.004564744340698238,-0.0029393540111731027,-0.004400820699268036,-0.003142645667412838,-0.004808591374808446,-0.0020108736284252843,-0.0015072730050651386,-0.002027598954002339,-0.0023428543596949237,-0.004834078405806513,-0.0019654588962801593,-0.003178412508459718,-0.0049549213862923784,-0.0035378164772040302,-0.005777327337022677,-0.004721182805566393,-0.004315904520117376,-0.0036168889589149674,-0.0021968388365588808,-0.008343455387888872,-0.00389194762779919,-0.003707222058723073,0.000419028036158264,-0.0017547705227307238,-0.001318609640218299,-0.0006929516888224829,0.02228908636125928,0.007610446548252203,0.00814346809557934,-0.002153059164159431,0.09079037637435425,0.02933787559944974,-0.0014801817028696795,0.023730029155504363,0.040681957298500375,0.011146128511556993,0.015376939336611058,0.10809666379007712,-0.004576743753832254,0.008812025366292003,-0.002652301873487593,-0.003408410954115088,0.00026360345200451173,0.026330326768248546,0.03004038336316758,-0.00043284091976132595,0.06309912295005095,0.05708648026260819,-0.0034494828966311077,0.1609238788952891,0.0068982719041315145,0.17773858298190034,0.00596319485436149,0.0068909794987151995,0.18965318659465516,-0.0029341939758064234,0.16981700310211337,0.18145034684616032,0.03164454342669414,0.09880498948916258,0.14634637151026847,0.06700686098807875,0.09544368462885011,0.035132748370115666,0.14289205231895172,0.41239118182869255,0.38088462013899355,0.3082614132937271,0.30281782559551224,0.3563798528647773,0.33658862618431956,0.039583620363878344;0.052075631051919584;0.10054173994444879;0.0
data/model/LunarLander-v3_146485_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 146485};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 146485};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]
    leg0_contact = observations[6]
    leg1_contact = observations[7]

    reward = 0.0

    # Penalize high linear velocities
    reward -= abs(x_velocity) * 0.1
    reward -= abs(y_velocity) * 0.1

    # Penalize large angles and angular velocity
    reward -= abs(angle) * 0.2
    reward -= abs(angular_velocity) * 0.2

    # Penalize if legs are in contact with the ground
    if leg0_contact or leg1_contact:
        reward -= 10.0

    # Small negative reward to encourage short episodes
    reward -= 0.01

    return reward";-0.020781625126571154,-0.016738477787380697,-0.028415831473057547,-0.020705679087299075,-0.009480836265522182,-0.012389653630906815,-0.009710230370911831,-0.012704658203021166,-0.013985103799696537,-0.014481034097322877,-0.013049718942716268,-0.012841540721274677,-0.01643310702594319,-0.01026647562686678,-0.012677130994925366,-0.012413996806233864,-0.014178032598234408,-0.018748963964441888,-0.01284301456033513,-0.027591459783905193,-0.03078215612713613,-0.01232772313954385,-0.0449584442500355,-0.012285927255190357,-0.024364025693361845,-0.014912862199086623,-0.01202304326945127,-0.01178558279152564,-0.018479938465068943,-0.025964360670254493,-0.00956130322373673,-0.04284304975562792,-0.007213955426296379,-0.01719637355360873,-0.01556096994833254,-0.04740359009113609,-0.01877180781461947,-0.00855230497688453,-0.015097521130682573,-0.012462581114216841,-0.011667468501679943,-0.007662758796116857,-0.005348080359266683,-0.007582688952848451,-0.01027744077519155,-0.005156348560252387,-0.005315412957133534,-0.008069711104867894,-0.00800606542926113,-0.007163002979266288,-0.004822457526973336,-0.03032127358790584,-0.01637960644537555,-0.026788921371166858,-0.024100870460016726,-0.01202535876130357,-0.02010365254812008,-0.015655063077114922,-0.015784482004006176,-0.01656281632951917,-0.006983123721407093,-0.012896391240125454,-0.012054546655719534,-0.963752700767184,-0.03021152543480078,-0.006790540965753415,-0.2123907175725989,-0.010369313974365647,-0.0059074262485751036,-0.012491974940520244,-0.016819347332193167,-0.013404220455901499,-0.013861671039744899,-0.01303325980208471,-0.008220678788556193,-0.013552739392647731,-0.011157565811751828,-0.01905773982111963,-0.01657364999504012,-0.012494288509476283,-0.02030917233802518,-0.009541229042317226,-0.013116249673407654,-0.011930513434411363,-0.01201839391233431,-0.012176992264426145,-0.011867854192035876,-0.01654134280414265,-0.008670270820916879,-0.009673767831524566;-0.027884964234142866;0.10165402048503387;0.01
data/model/LunarLander-v3_858835_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 858835};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 858835};30;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, leg1_on_ground, leg2_on_ground = observations
    angle_reward = -abs(theta)
    velocity_reward = -np.sqrt(vx**2 + vy**2)
    angular_velocity_reward = -abs(omega)
    ground_contact_penalty = -10 if (leg1_on_ground or leg2_on_ground) else 0
    collision_penalty = -20 if is_failure else 0
    return angle_reward + velocity_reward + angular_velocity_reward + ground_contact_penalty + collision_penalty";;nan;0;0.0
data/model/LunarLander-v3_858835_2.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 858835};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 858835};30;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, leg1_on_ground, leg2_on_ground = observations
    
    # Penalize descending towards the ground by adding a penalty based on vertical velocity (vy)
    descent_penalty = -5 * abs(vy) if vy > 0 else 0

    # Stabilize the lander's angle around 0 radians
    angle_reward = -abs(theta)

    # Minimize linear velocities in both x and y directions to achieve stationary flight
    velocity_reward = -np.sqrt(vx**2 + vy**2)

    # Penalize angular velocity to keep the lander stable
    angular_velocity_penalty = -abs(omega)

    # Encourage staying aloft by rewarding altitude (y-coordinate) if above a certain threshold
    altitude_reward = y if y > 1 else 0

    # Penalize ground contact as it indicates failure to achieve stationary flight
    ground_contact_penalty = -20 if (leg1_on_ground or leg2_on_ground) else 0

    # Penalize collision heavily as it signifies the end of an unsuccessful episode
    collision_penalty = -50 if is_failure else 0

    # Combine all rewards and penalties to form the final reward
    return angle_reward + velocity_reward + angular_velocity_penalty + descent_penalty + ground_contact_penalty + collision_penalty + altitude_reward

# Explanation of Improvements:
# 1. Added `descent_penalty` to explicitly discourage downward movement, which is critical for avoiding crashes.
# 2. Increased the penalty for ground contact and collisions to make these events more costly.
# 3. Included an `altitude_reward` to incentivize staying aloft, which aligns with the goal of not landing.
# 4. Adjusted penalties and rewards to ensure that the agent is sufficiently motivated to maintain a stable, stationary flight without descending towards the ground.";;nan;0;0.0
data/model/LunarLander-v3_200021_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 200021};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 200021};30;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]
    leg1_contact = observations[6]
    leg2_contact = observations[7]

    reward = 0.0

    if is_success:
        reward += 100
    elif is_failure:
        reward -= 100

    # Penalize horizontal movement
    reward -= abs(x_velocity) * 5
    # Reward for staying stationary vertically
    reward += (1 - abs(y_velocity)) * 2
    # Penalize angular movement
    reward -= abs(angle) * 3
    reward -= abs(angular_velocity) * 2

    # Reward for leg contact to ensure stability
    if leg1_contact and leg2_contact:
        reward += 5

    return reward";;nan;0;0.0
data/model/LunarLander-v3_126295_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 126295};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 126295};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    y_coord = observations[1]
    dx = observations[2]
    dy = observations[3]
    angular_velocity = observations[5]
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    if is_failure:
        return -10.0
    elif is_success:
        return 0.0

    reward = 0.0
    reward -= abs(y_coord) * 0.5  # Penalize deviation from the desired altitude (ground level)
    reward -= abs(dx) * 0.1  # Penalize non-zero x-velocity for stationary flight
    reward -= abs(dy - 0.5) * 0.2  # Penalize deviation from a small y-velocity to hover
    reward -= abs(angular_velocity) * 0.1  # Penalize angular velocity for stability

    if leg_contact_1 or leg_contact_2:
        reward -= 1.0  # Penalize contact with the ground as we want to hover, not land

    return reward";-0.0407660222602074,-0.046722877675295704,-0.05201167172025463,-0.06188685953781878,-0.043005900798793364,-0.05947913713885184,-0.03467034057105274,-0.06269743227663266,-0.06879002122281551,-0.050317603802517576,-0.03397669433097886,-0.042964594739504924,-0.0700694902571534,-0.04451597946234586,-0.04856155167254525,-0.03344938821783815,-0.033492598938401515,-0.04735180965189771,-0.06693453675853354,-0.0751388670541135,-0.030333552765175596,-0.03900395443773444,-0.10253243338445531,-0.043276000194196466,-0.062177184351371685,-0.12042210716826778,-0.169354565824406,-0.12220342287621645,-0.10140379279171459,-0.153014909282747,-0.20832915892319567,-0.19446295668804214,-0.08480697559886376,-0.31444528177518755,-0.05247510008285159,-0.126785937324591,-0.06515066291145152,-0.21570329175926195,-0.2645580542328562,-0.0833126002878261,-0.03886353463051808,-0.13725593487817686,-0.13816334746982914,-0.08892082623173403,-0.059300251751593,-0.037465149560916684,-0.11654634513560144,-0.07701328647202198,-0.04534878387607092,-0.12122323566395508,-0.04729703747377197,-0.043195521222953316,-0.048067467598410914,-0.04776299739204189,-0.07627661310475006,-0.05053163571670965,-0.04012655583229766,-0.03602527028640498,-0.03631143558290541,-0.04138478463884298,-0.04181454020314408,-0.03796959532965444,-0.06874794367056505,-0.05120996063593659,-0.03865928674675233,-0.06847351180099134,-0.04756484894511885,-0.047381751775748916,-0.06322187892847653,-0.0486091788692962,-0.048662024455150076,-0.030152686430556543,-0.08920999291113939,-0.05135048687720139,-0.03431878766362429,-0.032067420117068306,-0.044847744276031075,-0.04574618082700541,-0.034237684016850296,-0.06660134327353004,-0.30856875838149495,-0.03160537896160384,-0.044256981317136034,-0.05873391801219464,-0.04043514182256275,-0.04725364682455294,-0.027994040462085562,-0.04202780597828592,-0.02846920986733403,-0.03728923403433351,-0.031547943198050106,-0.025876845953122257,-0.026780935010985125,-0.02669464873465804,-0.03608985022967827,-0.02939007361836422,-0.032371548331585655,-0.02807328571454422,-0.027250964975856575,-0.033822828389045115,-0.04084448398056016,-0.035759642137420715,-0.040950419743007886,-0.041299041584148204,-0.029533513246556054,-0.03803086654112971,-0.03674906113985464,-0.04434959454292612,-0.03856175221670226,-0.028207327652874536,-0.03349840197753435,-0.027744693014857245,-0.03408415477011754,-0.046890766614468685,-0.03369901011746414,-0.033295511653972466,-0.040170330903835025,-0.04074996982978117,-0.03817142891414142,-0.0331165262029613,-0.0372325862119895,-0.044553646951650656,-0.03371177208237962,-0.03772855003882521,-0.025487669017555257,-0.026866061893420723,-0.03350583068760316,-0.03750518478191994,-0.026074107024955214,-0.035657372430279166,-0.026547441813555384,-0.027366812432327657,-0.030793828317918808,-0.02959929060508366,-0.026151296947899555,-0.028720651209419835,-0.02615475451558212,-0.030153209353132936,-0.029005403359514625,-0.03009830573217831,-0.03586665930415725,-0.026969125926383373,-0.034286360995453874,-0.03270584881658457,-0.03148387760250519,-0.03207228562039745,-0.025135672164906864,-0.038481346711435785,-0.030219423012525153,-0.02811315603792757,-0.04023283915523793,-0.03333617711914744,-0.027651153934525535,-0.04298617910644,-0.041483773715065744,-0.034402781105756806,-0.039121211504738934,-0.026003112036034105,-0.040854161877558755,-0.023957155446160304,-0.031615133388047355,-0.031657848728617946,-0.03479442088369044,-0.02926923233646444,-0.030955705930749162,-0.04662283994096918,-0.02904378498048593,-0.03513871556162612,-0.026803945980681653,-0.025634637732529324,-0.038731195880322436,-0.025200557395674037,-0.03698935974608848,-0.04047812246807211,-0.03601254609949271,-0.028457783245320042,-0.039157545025408365,-0.03527279879951659,-0.027759190205486475,-0.026953545241435596,-0.02751798110499803,-0.03258191658112201,-0.03767694836422961,-0.026034209158988242,-0.03433055931232765,-0.0362127323254064,-0.029521130392992943,-0.02852512288675855,-0.0289586876734026,-0.04158056714347658,-0.04046569157245566,-0.026155338922252403,-0.02997795938649787,-0.03666482160387858,-0.035699081893936814,-0.035522620411504356,-0.04337077230617961,-0.038382396687275444,-0.03781381280182407,-0.02805363581328069,-0.036768514864628614,-0.03325254654053339,-0.03317729564983241,-0.03245437516492952,-0.028863093607123105,-0.024859099274599752,-0.03206659060430826,-0.038871396076948735,-0.03489147774173938,-0.025220081766316075,-0.026747095139147994,-0.039224761755920184,-0.03368383989431474,-0.029714269868929347,-0.03619784790666549,-0.03954126420620681,-0.029586150931712487,-0.03341245640468445,-0.026154992807602345,-0.03658607479488094,-0.03449309219242543,-0.026799840203160827,-0.027810514264009267,-0.028207669344105502,-0.03919683128568797,-0.03632369589773891,-0.04010775555675155,-0.03349328149057766,-0.029156581852461692,-0.040463349049951455,-0.04044081284625581,-0.027790953919088313,-0.02818190722246123,-0.03091094813009392,-0.030337972047156523,-0.02675575396055272,-0.03382574383737133,-0.03910428723129291,-0.025004031899785274,-0.04064252446462407,-0.030504046368116405,-0.025304118483516304,-0.025326234376506336,-0.0388114100190308,-0.028642586408618,-0.027245719588150374,-0.02696106488211311,-0.028979141219729398,-0.029908846154416246,-0.037834660533484804,-0.032131721857342616,-0.03670597793973559,-0.030001065781798553,-0.029283981075055903,-0.032490080588718065,-0.04091707220201056,-0.02695689295371968,-0.028850730050546853,-0.025085630497093878,-0.02498086168700134,-0.03328188947003818,-0.027280540671686535,-0.03888926857970676,-0.02991380420597984,-0.038771519425222084,-0.02645404723158076,-0.02678937735684439,-0.037003509862944414,-0.032945200567772545,-0.02659515962597905,-0.034788695977313,-0.034854797920321354,-0.029044992788627835,-0.04201924491587471,-0.035982652461468284,-0.047087112926095936,-0.0349638636311332,-0.031066776080282826,-0.04572126196078245,-0.040098031378478095,-0.02475900233946524,-0.04667622866972136,-0.02679935664758285,-0.03183834495619082,-0.03597057011409816,-0.04463499289872107,-0.02760091271181877,-0.02812962777699037,-0.03736646595828635,-0.02576516077655118,-0.03213996175662313,-0.02711702235688444;-0.045233509248291254;0.0371293303916368;0.0
data/model/LunarLander-v3_126295_2.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 126295};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 126295};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    y_coord = observations[1]
    dx = observations[2]
    dy = observations[3]
    angular_velocity = observations[5]
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    if is_failure:
        return -10.0  # Heavily penalize failure to avoid crashes
    elif is_success:
        return 10.0  # Reward success to encourage achieving the goal

    reward = 0.0

    # Penalize deviation from a small positive y-coordinate to hover slightly above ground level
    reward -= abs(y_coord - 0.2) * 0.5  

    # Penalize non-zero x-velocity for stationary flight
    reward -= abs(dx) * 0.1  

    # Reward proximity to a target y-velocity that allows hovering (slightly positive)
    reward += (0.5 - abs(dy)) * 0.2  

    # Penalize angular velocity for stability
    reward -= abs(angular_velocity) * 0.1  

    # Penalize contact with the ground as we want to hover, not land
    if leg_contact_1 or leg_contact_2:
        reward -= 5.0  

    return reward

# Improvements made in this new reward function:
# - Increased the penalty for failure to heavily discourage crashes.
# - Rewarded success to encourage achieving the goal of stationary flight.
# - Adjusted the target y-coordinate to hover slightly above ground level (0.2) instead of exactly at 0, as hovering too low can lead to instability and crashes.
# - Changed the reward for y-velocity to be a positive reward when close to the target y-velocity, encouraging the agent to maintain this velocity more effectively.
# - Increased the penalty for leg contact with the ground to strongly discourage landing.";-0.038736285865799656,-0.04987125087776677,-0.050937942816915,-0.04246827356796465,-0.04353270486657438,-0.029384006015961105,-0.0483255767101173,-0.049883398407526154,-0.03128952923533467,-0.04095497791771253,-0.03764672128785252,-0.04791174578899373,-0.034292509949715465,-0.05756900284063423,-0.03863052009723042,-0.025536546352437437,-0.06218453169125135,-0.0608614073354482,-0.03826590672613119,-0.039281181165495796,-0.06724160545416037,-0.03362310722795804,-0.033156146478453455,-0.035431195258273616,-0.028589024485043128,-0.03169824174096157,-0.04200193447951757,-0.03426321962274449,-0.057483113049269535,-0.04873949482818753,-0.046354595752408405,-0.026649264298435008,-0.03345416273992634,-0.059298379639454606,-0.03678014833855195,-0.041015305919284185,-0.03580768355216576,-0.04902898069749817,-0.04615151102223932,-0.043969918754549676,-0.04805596631203279,-0.032686612278352026,-0.03266707401954668,-0.031084463800513343,-0.03027560076068857,-0.06103382175242748,-0.09002571205600386,-0.0340772535060161,-0.03947333584206613,-0.03947121771878085,-0.051518605633040296,-0.037874453064308936,-0.061149451667819425,-0.0774290239715137,-0.031174859542696793,-0.040952113343114625,-0.05459004925688687,-0.032166494777088724,-0.039772813298183655,-0.04538584008405931,-0.05667260956528941,-0.03532466674499915,-0.05413745865828463,-0.03720463370927338,-0.04211990413674004,-0.04966843827188738,-0.03520472902703676,-0.055426562596737526,-0.0318635728107813,-0.03732109963415719,-0.03594123034072794,-0.03054549051655682,-0.06956523287529723,-0.03275257626695363,-0.04491789674222869,-0.03456855047682727,-0.03999512394202289,-0.05401911446052773,-0.02788909144744348,-0.033300488857960504,-0.08398958859045161,-0.0340705880482039,-0.028353093825492094,-0.052316401063597466,-0.03034208876539063,-0.04024250767152191,-0.04606713755719355,-0.060902908761264814,-0.040965080522397175,-0.07315120786265343,-0.035103274021455536,-0.04440580098723109,-0.034374472682827714,-0.10401316879926546,-0.04486312246181067,-0.05975080245295177,-0.053296255423032596,-0.4934062891177885,-0.05678856247303514,-0.03824150340054708,-0.0713943090450082,-0.03943967357754155,-0.05442187668109034,-0.038211083086187383,-0.04556659594798972,-0.04174511019589637,-0.06903955360812865,-0.05032030380512287,-0.06432300877489194,-0.025645402654912018,-0.10414712648224533,-0.03478641547892395,-0.039457553230472245,-0.03128671022542446,-0.0300578650370822,-0.07097160813509677,-0.03891602233128867,-0.5704712003098469,-0.03482097386672669,-0.061258310698111294,-0.04253949469003965,-0.09331263989487162,-0.08080314865123905,-0.06494117753657373,-0.04210852675861588,-0.04889821316403346,-0.04805621609227134,-0.03570352007076571,-0.03723400268982506,-0.053886129875011415,-0.035378025821547296,-0.093466576866368,-0.04710890050911777,-0.04176712517205274,-0.040367697467611964,-0.047052523223839265,-0.046825083028318795,-0.04526080356577652,-0.041283059929171605,-0.05067796072534186,-0.047236198816012834,-0.0552975063405225,-0.05967771273449193,-0.05856632242620301,-0.05400744440404003,-0.03178147819085874,-0.01952427224123399,-0.03170800940936544,-0.010248312177912302,-0.020213829899654322,-0.036826453805268375,-0.04808823927966996,-0.06559807723986531,-0.03789274057998253,-0.06851223719925703,-0.017112421656878686,-0.03770584973000356,-0.018506912381240356,-0.024821212020580213,-0.024979722065082536,-0.03565418571518069,-0.23674974410383193,-0.03743393623801625,-0.02961381367293746,-0.035376965557096324,-0.023803149085202775,-0.059611740011453994,-0.034997215078341144;-0.051885389119496986;0.057098925982012466;0.0
data/model/LunarLander-v3_50915_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 50915};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 50915};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, left_leg_contact, right_leg_contact = observations
    reward = -abs(vx) - abs(vy) - abs(angle) - abs(angular_velocity)
    if left_leg_contact == 1 and right_leg_contact == 1:
        reward += 1
    if is_failure:
        reward -= 1000
    return reward";-0.1266290726717348,-0.12377385643836611,-0.132432223281498,-0.13812952041575255,-0.12704154961837497,-0.12869450344690248,-0.1333253676344707,-0.13492345594249772,-0.12673817369195423,-0.12892886990422603,-0.12972906750709656,-0.1363711969120252,-0.13437570699182472,-0.1434644781552918,-0.1482740299482007,-0.12977357878825324,-0.1452710075353379,-0.1449224563410475,-0.13206008844272243,-0.13048807213333816,-0.14693650672413958,-0.15832051162500005,-0.1378087671586561,-0.21927696312758907,-0.14005548691835382,-0.14297475166691892,-0.1346077043847032,-0.14220939245570496,-0.14245282679157284,-0.13076666105725845,-0.13144488784893965,-0.14466496161627945,-0.1369488779214581,-0.13443641715767465,-0.13877953876083052,-0.13806709597899097,-0.13461343398904502,-0.12714969122126338,-0.1297878475607587,-0.12916926213736568,-0.12883148857912907,-0.13023717097938,-0.14871674667946938,-0.13534196792544564,-0.1408506184415129,-0.13871392931365967,-0.12917474320221087,-0.13582414877359592,-0.13395964536705654,-0.1444586037836064,-0.1355112093035089,-0.15847464650987547;-0.13799832270695905;0.013683280338983883;0.0
data/model/LunarLander-v3_256094_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 256094};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 256094};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, left_leg_on_ground, right_leg_on_ground = observations
    
    velocity_penalty = -np.abs(vx) - np.abs(vy)
    angle_penalty = -np.abs(theta)
    angular_velocity_penalty = -np.abs(omega)
    
    if is_failure:
        return -10.0
    
    if left_leg_on_ground or right_leg_on_ground:
        return -5.0  # Penalize touching the ground
    
    altitude_reward = np.clip(y, -2.0, 0.0) * 5.0  # Reward for staying close to initial height
    stability_reward = (velocity_penalty + angle_penalty + angular_velocity_penalty) * 1.0
    
    return altitude_reward + stability_reward";-0.1551205688685326,-0.07528967350906068,-0.0787687176467456,-0.07029610996603722,-0.13053856431365082,-0.11503580333264798,-0.07862359462218887,-0.07634211559208101,-0.07149767309162117,-0.04742244846664148,-0.08643922326399371,-0.08239185282647046,-0.07483337790521374,-0.13382672272548657,-0.08590526031699589,-0.11311119310335019,-0.130602688603267,-0.6656072184392191,-0.11272567284359757,-0.09006955662583342,-0.08984953390976858,-0.13183899751691514,-0.08996125162160687,-0.07150781705274131,-0.21860803310772567,-0.09505445163835884,-0.14973630573010072,-0.09715960924929157,-0.06931446725021331,-0.10980406981263348,-0.08979576160000427,-0.0885743448857034,-0.10694511139090832,-0.0996541486385245,-0.08003723940798577,-0.11057668512935745,-0.1226713174602036,-0.06975255870922309,-0.15187414389396897,-0.07261844131999534,-0.06268800875116402,-0.08284903102474273,-0.1435272239805396,-0.09544510475590294,-0.11208830418551742,-0.13171415309282491,-0.10530872580967332,-0.07940097368400775,-0.08361633416333372,-0.10127979048732343,-0.1311293302107291;-0.1121339079516397;0.08386793084813825;0.0
data/model/LunarLander-v3_256094_2.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 256094};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 256094};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, left_leg_on_ground, right_leg_on_ground = observations
    
    # Penalize touching the ground
    if is_failure or left_leg_on_ground or right_leg_on_ground:
        return -10.0  # Higher penalty for failure or touching the ground
    
    # Define penalties for non-zero velocities and angular velocity
    velocity_penalty = -0.5 * (np.abs(vx) + np.abs(vy))  # Reduced penalty for velocity to encourage slow descent/stationary flight
    angle_penalty = -0.5 * np.abs(theta)  # Penalize tilt, but not too harshly
    angular_velocity_penalty = -1.0 * np.abs(omega)  # More significant penalty for spinning
    
    # Reward for maintaining a stable height close to initial (y=0)
    altitude_reward = 2.0 * np.clip(-y, 0.0, 5.0)  # Higher reward for staying aloft without excessive height gain
    
    # Stability bonus for being near zero velocity and angle
    stability_bonus = 1.0 if np.abs(vx) < 0.1 and np.abs(vy) < 0.1 and np.abs(theta) < 0.1 else 0.0
    
    # Combine all rewards and penalties
    reward = altitude_reward + velocity_penalty + angle_penalty + angular_velocity_penalty + stability_bonus
    
    return reward

# Explanation:
# - Higher penalty for touching the ground to strongly discourage landing.
# - Reduced penalty for velocities to allow for controlled descent or stationary flight.
# - Penalize tilt but not too harshly, as some angle may be necessary for maneuvering.
# - More significant penalty for angular velocity to encourage stable orientation.
# - Reward for maintaining a stable height close to the initial position.
# - Stability bonus for being near zero velocity and angle to incentivize stationary flight.";-0.07882413779162313,-0.07006825693376227,-0.04006510041784039,-0.04560786576866778,-0.03301623889079423,-0.04404470087087679,-0.034347975620106226,-0.02836717658748873,-0.03278615792688011,-0.06687302410006687,-0.08460742454109288,-0.04795945437335316,-0.04044588338852806,-0.03802867325469867,-0.03939360275056268,-0.05295648987020192,-0.0456674112394121,-0.04401678595212741,-0.08049754940915707,-0.05397996444074778,-0.05257221424508552,-0.04351599907638702,-0.002838523546459916,0.04074173740913292,-0.023713061737071862,-0.05243043495581918,-0.03659736696430705,-0.034114913848894445,-0.022611389453556188,-0.01827647886663564,0.011817925429303515,-0.07158903729398075,0.010072198829602896,0.04417917311078129,-0.03440140154778013,-0.06424336367025904,-0.0313264502187892,-0.004989505153198024,-0.03741367184705776,-0.023347446518598238,-0.05020835613644191,0.25025251513808494,-0.016200056317962647,-0.00021142062036576048,-0.03643158589082897,0.0003799025638416657,0.2879310385681167,0.28532741859139676,0.26516641557373444,0.3167671978561401,0.2707592405427954,0.3069434722048196,0.21526789483005532,0.18503322740994824,0.3397608669840101,0.36549214600798224,0.13007661101629636;0.029252323333834648;0.12918266613093105;0.01
data/model/LunarLander-v3_237834_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 237834};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 237834};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    # Penalize vertical movement and angular velocity to maintain hover
    vertical_movement_penalty = -abs(vy)
    angular_velocity_penalty = -abs(omega)
    
    # Penalize horizontal movement
    horizontal_movement_penalty = -abs(vx)
    
    # Penalize if both legs are in contact with the ground (landing)
    leg_contact_penalty = -20 * (leg1_contact + leg2_contact)
    
    # Reward for staying off the ground and stationary
    stay_off_ground_reward = 5 * (not leg1_contact) * (not leg2_contact)
    hover_reward = 5 * (abs(vy) < 0.1) * (abs(omega) < 0.1) * (abs(vx) < 0.1)
    
    # Final reward calculation
    reward = vertical_movement_penalty + angular_velocity_penalty + horizontal_movement_penalty + leg_contact_penalty + stay_off_ground_reward + hover_reward
    
    if is_failure:
        return -100
    
    return reward";0.00631750299875705,0.010076231846791094,0.003068784552075453,0.0056577725001347445,0.006012884801964792,0.011275071905037725,0.0038564332396840884,0.009420159282189318,0.0070596994112961395,0.0042817598726603194,0.012831433471782255,0.00978291807190018,0.009509579996512564,0.00751340466858082,0.012794051057579832,0.002249863757252767,0.002912157210881921,0.008442853624982396,0.0028329318801349297,0.001701709448018501,0.016099019384125817,0.0022111616985388597,0.004848374448524676,0.00287128985731418,0.0070225499142963594,0.0019109206748947982,0.0011431704640103317,0.022851658998082478,0.025357126806060015,0.013098656589499196,0.05079303027844368,0.02599133586190756,0.14257526024642092,0.1743756789249489,0.12665123705777845,0.14694214562565872,0.04190994610839284,0.04059914791485458,0.0800444346882882,0.09086635430753028,0.08110382226782105,0.09907095805220494,0.17366272517526082,0.1510138233220016,0.18022127221030307,0.1825627425178849,0.18199219864413543,0.1740571587277998,0.17687596080076257,0.19026047914015082,0.21321644449137478,0.21342447818388022,0.20799234574849554,0.2562323150593741,0.25639787334254177,0.2396946581152874,0.21860264212999292,0.24340879954660172,0.23517720221516708,0.2551233836999755,0.2661181098095113;0.08773719830571008;0.09325034400159239;0.0
data/model/LunarLander-v3_616521_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 616521};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 616521};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_vel = observations[2]
    y_vel = observations[3]
    angle = observations[4]
    ang_vel = observations[5]
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    reward = 0.0

    if is_failure:
        return -100.0

    # Penalize high linear velocities
    reward -= np.abs(x_vel) * 0.5
    reward -= np.abs(y_vel) * 0.5

    # Penalize non-zero angle and angular velocity
    reward -= np.abs(angle) * 0.3
    reward -= np.abs(ang_vel) * 0.2

    # Penalize leg contact
    reward -= (leg_contact_1 + leg_contact_2) * 10.0

    return reward";-0.10993572668902758,-0.11811041056500513,-0.10992235769309358,-0.12222227895727318,-0.12589493935707263,-0.16014924262730604,-0.11936035324906037,-0.2043129922542032,-0.11886263305896737,-0.11240108311684192,-0.12138214661121197,-0.12727195889451837,-0.1430030802380647,-0.1219569721383447,-0.12301610560810591,-0.1200436279859327,-0.11981075088461271,-0.15710864381709053,-0.1533588687954004,-0.14014113285833718,-0.14301695953251983,-0.15549069403979562,-0.1402755386776294,-0.1504223770024881,-0.11451613759399706,-0.1535406643911884,-0.1441514528147851,-0.12180594622991517,-0.13015381152162736,-0.178185947451492,-0.20048472263792128,-0.11579711584406129,-0.13547721248586242,-0.12987996789983494,-0.11121624401680888,-0.11733797200075075,-0.11452985251982634,-0.11020789798311773,-0.11372408382987452,-0.12846109411214426,-0.10921901663531808,-0.12107948535105377,-0.16923977222503994,-0.13912581853168593,-0.1365483502783306,-0.12897939535135217,-0.11937250437775104,-0.13454490139046058,-0.15993716824948856,-0.12115329826140536,-0.12732235624103605,-0.10285845883113472,-0.12360379422459875,-0.1131611233412466,-0.1364863793967977,-0.10547263334664679;-0.131875811678901;0.021585021454098362;0.0
data/model/LunarLander-v3_781334_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 781334};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 781334};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, dx, dy, angle, angular_velocity, l_leg_contact, r_leg_contact = observations
    
    altitude_reward = -abs(dy)  # Reward for maintaining a constant altitude
    balance_reward = -(l_leg_contact + r_leg_contact) * 0.1  # Penalize contact with the ground
    crash_penalty = -50 if is_failure else 0  # Heavy penalty for crashing

    return altitude_reward + balance_reward + crash_penalty";-0.13262697677150814,-0.16230493557198944,-0.162363946939338,-0.18556579144161484,-0.1651740798400688,-0.16056184084432515,-0.16271124132971723,-0.14202855733336464,-0.17181237402758157,-0.15379610043917855,-0.15141615552681567,-0.15049936155882437,-0.2175084862234093,-0.1354517438206681,-0.13736441848986986,-0.13748920959670852,-0.09905740799791558,-0.08388043773809886,-0.08660890870102768,-0.08010541606222,-0.08903625802184906,-0.08068678710850036,-0.11107719969474307,-0.08121835414639442,-0.07676182738571814,-0.07627356842031703,-0.08226816140838071,-0.07440833596496146,-0.08363120749309286,-0.07291543866647333,-0.08571015630082737,-0.07229517833436426,-0.07947929940181654,-0.07524821773114793,-0.0768277203155525,-0.07516697073995264,-0.07473715367495133,-0.07640198847914378,-0.07274665691834928,-0.0724570250469181,-0.0766769481728436,-0.07526353843736223,-0.07239161815370593,-0.07936805332978293,-0.07256945334976818,-0.08802829660950094,-0.07307814463468504,-0.08092010063903694,-0.07661441822893365,-0.07651950188187909,-0.07578499108407102,-0.08705968607698003,-0.08536636024268526,-0.0793496324305126,-0.08444559960628738,-0.08268603908146269,-0.07501670450937184,-0.07770014068226777,-0.07684699970492788,-0.07291557791900284,-0.07894538557003684,-0.07450084654567994,-0.07653232836611133,-0.08115566021428469,-0.07431326685844351,-0.08146122144279477,-0.07993426484980992,-0.0767556117329986,-0.07662160827475542,-0.08112418508893478,-0.07722661752128633,-0.07367414568715494,-0.08023354137394477,-0.07994525231695725,-0.15454679862852466,-0.09945185668036216,-0.09824355134677595,-0.09345264876167514,-0.09302526775159288,-0.09986764874259206,-0.09797859898062206,-0.0957684842314167,-0.11405537041172052,-0.09915661033420006,-0.09648604156943161,-0.09442091776620426,-0.07877923287121695,-0.09393163728009393,-0.09523021199939488,-0.08925975554648641,-0.09792384768392765,-0.08387619599659694,-0.09877870937545961,-0.0863520533276123,-0.09726158816816313,-0.10140390871086231,-0.09881762478328623;-0.09677081646468225;0.03073576794671394;0.0
data/model/LunarLander-v3_15289_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 15289};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 15289};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_vel, y_vel = observations[2], observations[3]
    angle, angular_vel = observations[4], observations[5]
    leg0_contact, leg1_contact = observations[6], observations[7]

    if is_success:
        return 10.0
    if is_failure:
        return -10.0

    reward = 0.0
    reward -= abs(y_vel) * 2.0  # Penalize vertical speed
    reward -= abs(x_vel) * 1.5  # Penalize lateral speed
    reward -= abs(angle) * 3.0  # Penalize non-zero angle
    reward -= abs(angular_vel) * 1.0  # Penalize angular velocity

    if leg0_contact or leg1_contact:
        reward -= 5.0  # Penalize touching the ground

    return reward";-0.11801471987951566,-0.1776878127221915,-0.06090478731601531,-0.20005291191815155,-0.11610532148624757,-0.10005847460122808,-0.14809843208239443,-0.14699812562416567,-0.11562917125315139,-0.1702233751787282,-0.17885488222758053,-0.1278367423411977,-0.0867227696661314,-0.14217344591544448,-0.09635184448176937,-0.16229832159196522,-0.15596937129756488,-0.11425726789740802,-0.22098431480012032,-0.09909283087070675,-0.14497048256858952,-0.12560835104805101,-0.08414765897259473,-0.09968365665158568,-0.14254092348986153,-0.09668018059077625,-0.10454153159389935,-0.16403203104234418,-0.1134952608347,-0.10363430547478755,-0.09548138286668108,-0.13924044391649118,-0.17517383426721111,-0.0846814870387836,-0.10900350911110757,-0.11315047824792365,-0.09517184406530284,-0.07391079652892264,-0.10468150231591207,-0.07319187573846511,-0.09056253392143435,-0.12234565391877261,-0.09346997044320818,-0.08568502613243019,-0.08433348956966613,-0.08600184413625686,-0.0755327147446963,-0.06965244642046149,-0.08463392441942147,-0.08062002879422979,-0.09579513788939904,-0.1370292918108592,-0.09226397002594287,-0.128230857588046,-0.10333721419237049,-0.09648825554753584,-0.09189926886641088,-0.09846194060493575,-0.11404995407241986,-0.09608436758290666,-0.0996451670452266,-0.06484787609069635,-0.10943963555936058,-0.11617365091796737,-0.07904006311601083,-0.09932209565081418,-0.14779942672188975,-0.10381582187244873,-0.06532188402899367,-0.09035736601713525,-0.10377267163411087,-0.1550898541900983;-0.11308944254224758;0.03316122546548264;0.01
data/model/LunarLander-v3_633998_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 633998};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 633998};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x_pos, y_pos, vx, vy, angle, angular_velocity, left_leg_contact, right_leg_contact = observations
    
    if is_failure:
        return -10.0
    
    distance_from_center = np.sqrt(x_pos**2 + y_pos**2)
    speed_penalty = abs(vx) + abs(vy)
    angle_penalty = abs(angle)
    angular_velocity_penalty = abs(angular_velocity)
    leg_contact_penalty = left_leg_contact + right_leg_contact
    
    reward = -0.1 * (distance_from_center + speed_penalty + angle_penalty + angular_velocity_penalty + 5 * leg_contact_penalty)
    
    return reward";-0.044230314834612164,-0.06068205905973349,-0.05120328629130526,-0.07054169814220967,-0.04657034386185994,-0.03690760680451698,-0.08770826204868917,-0.06449930079364893,-0.05223600846487521,-0.04164925278464731,-0.06189007868576311,-0.051353294234374444,-0.06242643305263731,-0.04981297413835387,-0.05886803769377941,-0.04050099254724396,-0.06148511663758527,-0.06770321361028575,-0.05672751945108711,-0.048727794697127035,-0.0559652650933791,-0.046464369742146315,-0.06437533215836475,-0.04096072377672633,-0.058859336936547435,-0.045283744740459056,-0.06180131723332533,-0.05830800952002278,-0.06126274574389118,-0.044370240600707156,-0.039000190913589354,-0.09432689923014209,-0.04567836738838457,-0.07780535811773844,-0.10988991030250715,-0.050918482437047344,-0.06449485013381295,-0.05332600689479439,-0.051415194173248746,-0.0769677733316425,-0.11136634883370194,-0.08940828325602718,-0.0794772020394989,-0.11859392504268274,-0.12015052325850749,-0.252303772834339,-0.09695281951420283,-0.23735159340403839,-0.2422025296106152,-0.11143070090175315,-0.25517746770064575,-0.19779452677739218,-0.1968467825198849,-0.15031045274491722,-0.25183737119432437,-0.11290077999999128,-0.22574697170350383,-0.15715800125477652,-0.1725031991341593,-0.14077830988803006,-0.13179799573126968,-0.13680528015965823,-0.13541355061713223,-0.14630210281269931,-0.15049530311111928,-0.13859702028577928,-0.1381410781718937,-0.15095461573750124,-0.14809397598822358,-0.13580443913430537,-0.12928224677307432,-0.13162942193694405;-0.10153897636632507;0.059822447019223214;0.0
data/model/LunarLander-v3_926013_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 926013};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 926013};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_velocity = abs(observations[2])
    y_velocity = abs(observations[3])
    angle = abs(observations[4])
    angular_velocity = abs(observations[5])
    leg_contact_left = observations[6]
    leg_contact_right = observations[7]

    reward = 0.0

    if is_failure:
        return -10.0

    if leg_contact_left or leg_contact_right:
        return -5.0

    reward -= x_velocity
    reward -= y_velocity
    reward -= angle * 0.1
    reward -= angular_velocity * 0.1

    return reward";-0.09454954654000566,-0.08492467130763293,-0.08126106351853642,-0.09492252373757257,-0.10366080441011148,-0.1326032866913564,-0.11521352823828168,-0.13320702226579173,-0.1396733973875995,-0.14489586012945457,-0.1073861515841108,-0.09671343772123149,-0.16882333445602782,-0.12067441547554457,-0.15129547221312856,-0.14455520135364966,-0.16179821381645346,-0.1000628335720105,-0.14157077046366168,-0.16125854136357204,-0.1694779498803083,-0.227608220103808,-0.15847548750494989,-0.23059715596221225,-0.15001722538660728,-0.10714120532902759,-0.08458215476229751,-0.14997915015243973,-0.14774010703807558,-0.1139554870434489,-0.17761905660115782,-0.39167523183684694,-0.07612378064848686,-0.08130715310162197,-0.08558491759732068,-0.09777210113927229,-0.08101471756218451,-0.1731103309440978,-0.13448962002973755,-0.16156107512013856,-0.07626527338357186,-0.10013878238165842,-0.08260547519672669,-0.09076178116550765,-0.1800432122279418,-0.07466946307761266,-0.11850327307705759,-0.07990130490496943,-0.11346242540493298,-0.12034893730486504,-0.07710845835876717,-0.05960043438560122;-0.12792867355498047;0.05352591627643998;0.0
data/model/LunarLander-v3_318570_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 318570};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 318570};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg_contact_1, leg_contact_2 = observations
    if is_failure:
        return -10.0
    if is_success:
        return 5.0
    reward = 0.0
    reward -= abs(vx) * 0.1  # Penalize horizontal movement
    reward -= abs(vy) * 0.2  # Penalize vertical velocity for maintaining altitude
    reward -= abs(angle) * 0.3  # Penalize non-zero angle
    reward -= abs(angular_velocity) * 0.4  # Penalize rotation
    if leg_contact_1 or leg_contact_2:
        reward -= 1.0  # Penalize contact with ground
    return reward";-0.09658379996592434,-0.09899594734024428,-0.08388206647692016,-0.10767800465313526,-0.12989692004521491,-0.141785976080088,-0.13824794607291252,-0.08981615341319181,-0.1199371954596043,-0.16543045746076526,-0.07662528876037347,-0.15845641844272373,-0.07736711633139436,-0.10981564358696431,-0.12381193494006944,-0.11239770931763084,-0.13032550411156607,-0.09847168504811837,-0.11991207403059234,-0.1161532619686408,-0.12020777003898396,-0.1433835832605162,-0.1823396953670196,-0.08914575459100883,-0.08114021800848958,-0.1058906054437705,-0.1635839871707999,-0.23393522557901844,-0.0657051651488217,-0.2527202328130522,-0.1555024374147705,-0.14343150694869755,-0.14820071984665278,-0.06441940093935673,-0.1624782746795609,-0.10675850890559335,-0.06782435566298053,-0.13525346111630607,-0.06412086887752746,-0.06882581854243704,-0.07768208186682243,-0.06850767033347512,-0.11030929435462318,-0.062342570424460175,-0.07481154864714422,-0.07378033973162298,-0.15033344258838305,-0.06466525441460377,-0.0773622123967567,-0.0803042705625878,-0.07136355549754007,-0.06138041107507208,-0.06242371283115712,-0.07648356305394464,-0.06490433908227422,-0.06549672308873433,-0.0672583917682887,-0.06240804548688577,-0.07931843491984966,-0.0682623403848445,-0.06475097683590002,-0.11794914190631055,-0.10130073810303583,-0.061950999158732784,-0.06431297801320483,-0.06498932066832168,-0.09707938462422364,-0.09937058324516383,-0.14727180015560967,-0.1708740759489658,-0.09619349697595736,-0.07016991035572347,-0.0769403860492557,-0.09774855787667407,-0.1279046967649516,-0.1231154396957353,-0.11382788710352174,-0.0779570925449052,-0.06203787827577644,-0.14966188925886081;-0.10444080162414174;0.03990136534138489;0.0
data/model/LunarLander-v3_239673_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 239673};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 239673};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    reward = 0.0

    if not is_success and not is_failure:
        reward -= abs(vy) * 0.5  # Penalize vertical movement
        reward += abs(vx) * 0.1  # Reward horizontal movement
        reward -= abs(theta) * 0.2  # Penalize angle deviation from horizontal
        reward -= abs(omega) * 0.1  # Penalize angular velocity

        if leg1_contact or leg2_contact:
            reward -= 1.0  # Penalize contact with the ground

    return reward";-0.17600769859841228,-0.24846799988368512,-0.27706702489927426,-0.2313602706420246,-0.2490971804206221,-0.24613650532566628,-0.2606911720119116,-0.16943928695071114,-0.21116538044771085,-0.24666702974648916,-0.40000401032505273,-0.13766569908544488,-0.2475124948097819,-0.15820632684825783,-0.11822456539766599,-0.19457342744367404,-0.05088778395131928,-0.10521956734410312,-0.07247822979634404,-0.03359645751198307,-0.009252215788013128,-0.20856201748327305,-0.053677346507051756,-0.022687481090879903,-0.021222046499075428,-0.03158613407979094,-0.010845528909809856,0.004885876149237475,0.020316153147207427,0.023067971892106784,-0.008148094906711466,-0.0022449449506580016,0.0022308072798580335,-0.004449431037269904,-0.007962741572530395,0.009665084827801667,0.03529787851556888,0.022857701849590416,0.015422346782675258,-0.03210553054050418,0.007107864338489462,0.01001409629425304,0.027506749047928755,0.022163890014771093,0.014582676450823147,-0.033912918154137564,-0.005443320173825467,0.019011588301323795,0.040541436415992074,-0.024531842514102554,0.013643752541679306,0.0317248731006786,-0.018844263997699263,0.031090314878879144,0.033064637939434066,0.03575750667057547,0.012705502336912216,-0.03672268769075179,0.019780152648209922,0.015575438695683822,0.016712302239973647,0.025895273683384002,0.03960238583087578,0.033238837854120455,0.04083106897728626,0.035023048614462315,-0.00766214773069978,0.021810236740690457,0.015436117061063742,0.024314050789380294,-0.020649329153472347,0.03429818573240558,0.027491369225166925,0.02864511461695046,0.00012231609200324706,0.02563060488246034,0.007085706972022123,0.030092620700946836,0.018560350697692785,0.0240528068448547,0.0264820210125515,0.04204047126049683,0.025042677434445725,0.01727052553520373,0.01524328302861182,0.01665891153424311,0.019655747998330874,-0.03168657309582943,0.0272623562267215,0.018870236429716733,0.023015291245777305,0.004077155053882328,-0.02508474873418818,-0.00023327719511446673,0.036852814419277936,0.009177464193531298,0.017084132099974038,0.008194804761008657,-0.006434026001990133,0.002505053979551194,0.02091020953729476,0.010716656666494004,0.011944512397537738,0.013821980545101793,0.03832987135837462,0.016768809714263855,0.04368939751824118,0.017814369842159512,0.013343477577722428,-0.00887900432847705,-0.01172304620942334,0.018717976041077874,0.012723240544468554,0.02833642822651156,-0.017832941656442412,-0.008243014409958383,0.010359882345567782,0.026479487383715593,-0.02397431983433485,0.02952631940683908,-0.021724984833747147,0.021183936679684472,0.031046619778645337,0.015287533055392533,0.02836252411811714,0.00631044388658417,-0.02466590642676005,0.023014316762269026,0.021134524715330758,0.0009360776171925516,0.018975190963268544,0.012081257023130629,-0.03007105481246282,0.021272195276759075,0.03431187513998319,0.01609426491887805,0.015055232835810227,-0.0050126924284056365,0.007167742647762851,0.03399288417079005,0.015521084023651243,0.01488077605248205,0.02396829508307867,0.0015508978703386398,0.03381403756507966,0.037340720242360986,0.041879517969536595,0.02334623302467852,0.016870673320469612,0.02891667404683102,0.03336353227785423,0.015934701104702933;-0.016297090125149655;0.07945660590456782;0.0
data/model/LunarLander-v3_504541_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 504541};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 504541};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, ang_v, leg0_contact, leg1_contact = observations
    
    # Penalize contact with the ground
    contact_penalty = -5.0 if (leg0_contact or leg1_contact) else 0.0
    
    # Reward for maintaining stable altitude (near zero vertical velocity)
    altitude_reward = -abs(vy) * 0.2
    
    # Reward for minimizing horizontal movement
    stability_reward = -abs(vx) * 0.2
    
    # Penalize large angle and angular velocity to maintain balance
    angle_penalty = -abs(angle) * 0.1
    angular_velocity_penalty = -abs(ang_v) * 0.1
    
    reward = contact_penalty + altitude_reward + stability_reward + angle_penalty + angular_velocity_penalty
    
    return reward";-0.11897800469541367,-0.09279687743222084,-0.10042109486886829,-0.06801567362191013,-0.08797549963438463,-0.08340099670415752,-0.10097055008389774,-0.1543324297729914,-0.09131474937339215,-0.3150357171396894,-0.08050321406965556,-0.09670069525018553,-0.13432137868580857,-0.12945454371391196,-0.11220510080885292,-0.11162689257021167,-0.08041996835216216,-0.13519103416321585,-0.3074318420243017,-0.1129219772371241,-0.09555750758622963,-0.10746871786743979,-0.105912635123289,-0.17282844200521544,-0.11736206847931031,-0.1338308428208387,-0.1313540470806493,-0.18029302717706328,-0.1811536681288998,-0.11928209074146727,-0.10732088350845201,-0.21022876312820588,-0.1126842228395817,-0.16997532412688038,-0.15287479579588545,-0.10847908454137507,-0.12665708758895255,-0.13166141082230143,-0.18154010741686152,-0.11308226111474941,-0.10775176720703851,-0.11738941784981831,-0.1184394718866365,-0.08694591817882563,-0.08855702834998318,-0.10844581564321214,-0.06414785480925903,-0.10975727864337315,-0.1019019289322764,-0.06786320806681889,-0.11424609884743905,-0.12459219818557704,-0.10871153602807736,-0.12260886540101366,-0.11895653268067755,-0.12575005523448946,-0.07947366450879303,-0.08530430712340754;-0.12283462371849517;0.046400803077969746;0.0
data/model/LunarLander-v3_187191_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 187191};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 187191};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    vx, vy, _, _, _, _, leg1_contact, leg2_contact = observations
    velocity_penalty = abs(vx) + abs(vy)
    contact_penalty = -50 * (leg1_contact or leg2_contact)
    reward = 1 - velocity_penalty / 20 + contact_penalty if not is_failure else -100
    return reward";-0.08184881959470588,-0.045000508676797404,-0.04501988670926536,-0.08991567688383119,-0.02749021106506468,-0.013526640387264035,-0.07253870186989636,-0.09709359759329683,-0.04592456899442965,-0.033680120789803855,-0.09756355297990538,-0.04536288495560175,-0.0467213363167105,-0.0852849551075057,-0.049735849848811395,-0.05129060865451706,-0.07884594297152389,-0.044563286688628474,-0.03489079682073646,-0.067184220884656,-0.05417493080415156,-0.05155226431709303,-0.06735907752468613,0.0023479216094446586,-0.048233498565850075,-0.05479019669532938,-0.04825797583566817,0.004495037573645444,0.0006853131723367899,-0.051016952268739986,-0.03453003648908736,-0.041155226825226494,-0.048255490223750926,-0.002865272756272747,-0.1388338671651882,-0.01098487094609657,-0.0539131719423911,0.005378844695029085,-0.004833049087190367,-0.018163908558946566,-0.009082333581172252,0.012478588069610275,-0.0034523008432915353,-0.10179292222838209,-0.06988333752575794,-0.05075848175820141,-0.012351704122998934,-0.013254850633699418,-0.001983006902108501,-0.013766937437406304,-0.041608076543126,-0.08730669565118317,-0.008580053758703285,-0.06627770735785746,0.012323844995872555,-0.012125662130654228,-0.040132127213082784,-0.03677951813904651,-0.012789019164909671,-0.08266409304451001,-0.01442085429879635,-0.011049298384376278,-0.008023141998256328,-0.10185026101785652,-0.002082894062681345,-0.003264445931023961,0.0008450163766967313,-0.06626419283121492,-0.00689209927016425,-0.008019217973660689,-0.06709835041782822,-0.0835413530381692,-0.06702022047142338,-0.025269496742443935,-0.011467462018452763,-0.06937331225015608,-0.032348197305727695,-0.09568144032972263,-0.010959067811239195,-0.002724983125740481,-0.04449485292058011,-0.07897848301320141,-0.06615178942540328,-0.004145548225691648,-0.38013319450781535,-0.01193329434885123,0.0049215842297677444,-0.011477885609971487,-0.1177585097399736,-0.12588522432240348,0.010414204054771883,-0.006787849741559228,-0.06461677123865536,-0.010378661704202454,-0.010668709894323428,-0.027661271780175682,0.0011616750505863802,0.002666687713643924,-0.11261774511122835,-0.18264931065638418,-0.11195728431006612,-0.0234213584657409,-0.00938580686295058,-0.13804554776563002,-0.012585442025975098,0.05842555904155367,-0.005845638149955237,-0.013133204428040033,-0.0036746760443240986,-0.11189850715099373,-0.005283720658244527,-0.1646373032194315,-0.14679850375576256,0.04952951713440723,-0.00830747983350195,0.000314477209850726,0.0030739422827681354,-0.008352435496284914,-0.0802419290887475,-0.07406807660568607,-0.005502979808259074,-0.00033705801425441394,-0.010690569424526992,0.01199516974518134,0.020895177055682224,-0.07547228520571066,-0.1156028074786896,0.0816500937221317,-0.058347785025711266,0.042876012138611204,-0.14105655099610262,-0.009696004979251964,-0.005567936705097511,0.07536820194604847,-0.010984111093365986,0.05053907688861201,-0.008193859943878107,0.04017959556383704,0.010337654858806057,0.03077151745095582,-0.002228517008112887,0.0007298444928249238,-0.19023723519915975,-0.011865711376333889,-0.008904662905520855,-0.010969442118739108,0.05065104186482623,-0.08543006602041489,-0.0022847054422444057,0.04480607852682087,-0.002879492100388849,0.07969622285127331,-0.012870434468446096,0.0773093345351008,0.05937817828491506,0.010313522921763124,-0.0076747593651637575,0.0070843464052061655,-0.006386546540809704,0.04972279662747779,-0.005772660860641212,-0.001366180206733555,-0.007280369088120965,-0.005429179553375691,-0.0008509413798445715,0.0038087703204322592,-0.014936759386168655,-0.05571206779444421,0.002067975889272288,0.025640344013544456,0.04292492504100598,0.033398285755569454,0.013519878008140987,-0.0021342227220663593,0.059166669197640055,-0.09353348410315743,0.03162071565634746,0.004004287992935772,0.051173995686979834,-0.013848675456488982,-0.006592901850902563,0.04963628225891297,0.014619529422616899,0.01808575672768023,0.019936503050899692,0.038830323932817705,-0.008678189419528939,-0.001493741119316569,0.05413336813496959,0.007018924821244561,0.0430776024509168,0.054794962662426436,0.009143687187261246,-0.002117877099949881,-0.0104092619102317,-0.005620402041787005,0.05694247376038643,-0.006845994049026433,0.047943243158831826,0.02674425459686805,0.0023418929332275277,0.021692698522535893,0.2233305596531504,0.04869233622741445,0.06978270179952875,0.007614295003894943,0.005036432471863925,0.04953048706888408,0.0036608238101435713,-0.0010973365949472785,-0.0008985199088139567,0.004583402333098349,0.05420910308915435,0.048434492214116755,0.033321809796344866,0.05040648881224832,5.965821860972494e-05,0.01813217251568134,0.10819185191742348,-0.41509980262126916,0.06088842535019077,0.05981774621822765,0.010290433315869782,-0.0008800501627189028,0.016003263657697393,-0.0004222080038701538;-0.019180980194787263;0.06369355351861855;0.0
data/model/LunarLander-v3_955376_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 955376};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 955376};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    if is_success:
        return 100.0
    elif is_failure:
        return -10.0
    else:
        return -(abs(vx) + abs(vy)) - 5 * abs(angle) - 0.1 * (not leg1_contact) - 0.1 * (not leg2_contact)";-0.1270330715824549,-0.08380720982474188,-0.0451451794923142,-0.035700623510742456,-0.14885258454442718,-0.11144946859486535,-0.061567111648266296,-0.11582215279018379,-0.07267692500408428,-0.08894155654432936,-0.0680757286358062,-0.09020940827565337,-0.11264045959132918,-0.09467011005282283,-0.10006492226607651,-0.0558601933303416,-0.05048533234138627,-0.07363906360979855,-0.0685141794476397,-0.06302063118661395,-0.09122259297381462,-0.07115228961515166,-0.2623207740436955,-0.22674636343872984,-0.11032357993830579,-0.1232431280995386,-0.0849807517438568,-0.27463800882572975,-0.2048932618711859,-0.053416576905887025,-0.2245350925603831,-0.19583738179081248,-0.06138254821264441,-0.1747553544429725,-0.12352741394954042,-0.13900117020275463,-0.10649476991047997,-0.07292505419167135,-0.060034611235908975,-0.06587873038920923,-0.1237751063385944,-0.0658543383828913,-0.0837720812453387,-0.06048530486454547,-0.07461220958639109,-0.1572212988015733,-0.14199764878433466,-0.14155167072865574,-0.0724859430387939,-0.057859501551368424,-0.08129714203064632,-0.18332915811528938,-0.058362006290938476,-0.17320132008559255,-0.141362939586004,-0.10747410042672764,-0.059757841464588075,-0.03826191228599287,-0.07362942922752672,-0.036860029945155144,-0.1756639764140205,-0.08212777399808162,-0.03824029078620678,-0.15992337761005426,-0.033702340368667684,-0.05483534184033761,-0.04338449839323287,-0.03724715791383439,-0.032070530901438736,-0.03723829581867705,-0.0378948822620865,-0.0412411178336316,-0.05463103486075797,-0.042982681484440816,-0.035828794226045735,-0.041626141304512566,-0.06155596282436853,-0.0703711923163981,-0.03363015571695372,-0.041741136003197836,-0.03908256761078998,-0.0388751436411473,-0.042943509146515166,-0.03481877140862543,-0.047874912113086136,-0.03130909169886148,-0.04030764987064781,-0.049202361183161604,-0.03964280586570401,-0.04465828246582569,-0.033598592850376766,-0.041916026017575485,-0.04555930842628785,-0.03835141570419875,-0.03435507160084243,-0.04851878918118866,-0.050819288935224756,-0.030054902733803644,-0.04401080045270785,-0.03283128703700885,-0.037742499300994,-0.03516932530703192,-0.03557317680598325,-0.04147386417556244,-0.02818009869294429,-0.03042375301075365,-0.038941825867931025,-0.036306532210924995,-0.051121293708086234,-0.04401014035088457,-0.04456197277805618;-0.07852980263447547;0.05331115368475288;0.0
data/model/LunarLander-v3_149296_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 149296};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 149296};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg1_contact, leg2_contact = observations
    
    if is_success:
        return 500.0
    elif is_failure:
        return -100.0
    else:
        reward = 0.0
        if abs(vx) < 0.5 and abs(vy) < 0.5:
            reward += 5.0
        if abs(angle) < np.pi/6:
            reward += 3.0
        if leg1_contact or leg2_contact:
            reward += 2.0
        return reward";0.013573388361581807,0.0017219970309469456,0.010196923595019168,0.006212695170475254,0.014349975257891213,0.0031738768805688804,0.0033089354712313858,0.0006752929533125277,0.001485644497287561,0.0044906981395283095,0.010298217538016047,0.015092797506534994,0.005638696160159606,0.0103657468333473,0.03676970130786713,0.025053368567894776,0.0020934081552688357,0.020697729019028974,0.003106347585237627,0.04838474010484261,0.020495141133035216,0.06648259125361836,0.07083823080248415,0.05101838262276147,0.0560493151249398,0.05274037965370841,0.04537968646260186,0.12259943567388941,0.07863786441324384,0.0994368873752697,0.11925673555499239,0.09845771259296654,0.11358427474716716,0.10936369378896386,0.11125451405823894,0.13060165717064284,0.17949286699046987,0.22352196754644665,0.05875048693818991,0.20086588896281135,0.10402887945779489,0.2664705993771234,0.07232387529977172,0.23267218706383141,0.07539645823734371,0.06273471536273383,0.09156972446917876,0.15261620744863125,0.12644860550777082,0.10605475831773248,0.11250380602186712,0.06094518903645563,0.06229577494308068,0.10868840083565133,0.06557094576664643,0.06665141449194649,0.07549775218034059,0.06259965677207131,0.054394847389324104,0.1298925995696647,0.20863175792590544,0.055205198933299136,0.07364069655873115,0.13627411797846808,0.09143466587851624,0.23756806097534724,0.06496318210866517,0.0769158673822969,0.15815360966579398,0.05034308966944894,0.1073715795766919,0.2664705993771234,0.08360126762009093,0.17219970309469457,0.09143466587851624,0.09089443151586622,0.0973772438676665,0.2664705993771234,0.1273602509947427,0.23000477989824694;0.08776487073535848;0.06926274225588977;0.0
data/model/LunarLander-v3_514863_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 514863};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 514863};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    distance_to_target = np.abs(y)  # Assuming the target is at y=0
    if is_success:
        return 50.0 - distance_to_target
    elif is_failure:
        return -20.0
    else:
        reward = -0.1 * (vx**2 + vy**2 + angular_v**2)  # Penalize high velocities and angular velocity
        reward += 3.0 if leg0_contact or leg1_contact else -0.1  # Reward contact with the ground but penalize lack of it
        return reward";-0.04898282044884929,-0.07128533840726493,-0.05335541630344466,-0.03739397011197151,-0.06815834841842189,-0.05081311211234154,-0.04398738610318771,-0.04491971151907612,-0.04445298769733871,-0.040367386427769096,-0.03791236445818456,-0.06342796879166723,-0.04013357637261866,-0.05051019756916968,-0.04010651044934362,-0.04909134611231167,-0.046162901443932605,-0.047160799433158145,-0.04869120180766962,-0.040202131688720937,-0.038934424684977736,-0.048169192611948346,-0.04777875851151101,-0.06610489811086262,-0.0432958124787562,-0.049668082119114866,-0.06212948153038112,-0.042812183725694106,-0.050121313762617574,-0.04884407794566804,-0.06121190310494492,-0.04451149366412721,-0.040686120333455394,-0.048130036934916805,-0.036700352884197325,-0.05974872281498328,-0.05051973875625586,-0.04480090968269373,-0.05967684814132635,-0.05953794050907859,-0.07459458625522312,-0.055174809777694546,-0.06164529832875785,-0.07999449291429106,-0.06519933496961512,-0.0838336816663796,-0.09780354252659576,-0.03793889963150122,-0.04841247319038235,-0.10910473055179955,-0.08022995279951561,-0.05543211306831876,-0.059747935505020784,-0.07850725703047434,-0.11273316998471047,-0.07153454461355312,-0.04980497207865261,-0.06653525103682786,-0.06086971773462943,-0.06524263537181585,-0.08835422398958764,-0.054883202769813386,-0.0798866127600368,-0.07960340286450593,-0.0926437455543936,-0.054798280287295824,-0.052085848229086726,-0.04300555203289155,-0.09721706930494074,-0.10825518865495301,-0.05929757603137523,-0.08973456198714962,-0.04944710701740572,-0.06172051174880027,-0.07115975424470891,-0.05196602375273606,-0.05630092949962297,-0.05938543372573629,-0.05951625644181082,-0.050623901943064174,-0.0567535535475677,-0.04143513818818405,-0.06138807960840802,-0.05845315745564829,-0.056409884000823036,-0.07095438813927102,-0.04380420133452801,-0.01082282819978089,-0.046105116289074016,-0.06398057473504755,-0.07865160394464056,-0.07808924103757277,-0.013444495761308397,-0.05434024494523566,-0.04310214546013353,-0.03379279568499927,-0.04480242652698855,-0.01946373782800113,-0.0415246156059307,-0.04085107892225545,-0.035114327039749815,-0.03530748410640665,-0.033202353060520814,0.3893810719173405,-0.03308279428829661,-0.030017709143717798,-0.04834685587358944,-0.03415031712679152,0.03481373100988453,-0.03101534089395258,-0.05573423043739614,-0.030943275654317377,-0.035602774796716995,-0.027738925001845424,-0.02540683356845521,-0.028724303576708618,-0.03585303587883331,-0.04387701107441007,-0.035656812167717315,-0.029493458712295317,-0.028679706066867337,-0.04514860694275629,-0.039995855408819524,-0.06032266230437009,-0.035082670386481045,-0.029269542957527015,-0.01907030539144715,-0.01768910971840979,-0.04709777634193216,-0.03937081228939906,-0.04224546436948147,-0.023303311435524613,-0.0329888926890703,0.017931877300265804,-0.038303085708749574,-0.05092459042216639,-0.037784901152772006,-0.04676849047906452,-0.03376659050238349,-0.04000889052493891,-0.0011093362047996567,-0.04647564464317973,0.3693566973745102,-0.05375644773195609,0.25226237216941877,-0.048330547717106535,0.057193442239975155,-0.06438640513062456,-0.060583916380425804,-0.06336381315614537,-0.07289759284492718,-0.05868417114767012,-0.0009709639305719369,-0.10523254315134398,-0.062427412238871084,-0.12167265771293968,-0.10637731212050681,-0.06420571946397337,-0.14494145174263398,-0.11971660476452158,-0.05822675807907861,-0.05806498143913758,-0.05675442562323575,-0.131114184058834,-0.05715167705260075,-0.11462075946968382,-0.06794318515218727,-0.21982379348906353,-0.058400633472896556,-0.05878832029429058,-0.06425627322264994,-0.10966534451432425,-0.06712454120360115;-0.04760756641451615;0.059277874800777744;0.0
data/model/LunarLander-v3_843719_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 843719};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 843719};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_pos, y_pos, _, _, angle, _, leg0_contact, leg1_contact = observations
    if is_success:
        return 10.0
    elif is_failure:
        return -10.0
    else:
        distance_to_target = np.sqrt(x_pos**2 + (y_pos - 3)**2)  # Assuming target y is around 3 based on the annotation
        angle_penalty = abs(angle)
        contact_bonus = leg0_contact + leg1_contact
        return -distance_to_target - angle_penalty * 0.5 + contact_bonus * 2";-0.05362749753495643,-0.07142485357212255,-0.04943736737181549,-0.047393426191276636,-0.06860362668436305,-0.055157253922089526,-0.08965425611797505,-0.05365986204222651,-0.06696065278250316,-0.07283580056087614,-0.05553515937501397,-0.06323488818412183,-0.0847920800676045,-0.07469885729561168,-0.06635378391153103,-0.08665923048434014,-0.08940379154108107,-0.05196745276033933,-0.07685699495480221,-0.08061231069767781,-0.08621104961455969,-0.12204156831508763,-0.08081564663320391,-0.08265049423935375,-0.10702794008975126,-0.13784322279043082,-0.07454645099341879,-0.09282606529687097,-0.07370229182210293,-0.19892121318663805,-0.08296786192308306,-0.09267887153564955,-0.0870113580257487,-0.05863665389470757,-0.04720796497873659,-0.04608480625785025,-0.1074956176542896,-0.08271536943314102,-0.1058168885798479,-0.06908533353841699,-0.07627563791897617,-0.10374803712943988,-0.05247936998208191,-0.050647381099484544,-0.10176138459046372,-0.06130843433876763,-0.08962515029273355,-0.2016487870394032,-0.061386695467612946,-0.07205958340888183,-0.05450397199483917,-0.05455793992614842,-0.053767945576024656,-0.04207054184527886,-0.04908769841464299,-0.09148629385759499,-0.12732522719317732,-0.09756331177039623,-0.05122935832713898,-0.06592430381311302,-0.04920709789494,-0.044415600746287524,-0.1050715649650071,-0.05508293325829531,-0.07561670111536661,-0.06029814602471133,-0.06863552931042236,-0.09927460867689171,-0.07948575642879152,-0.11119486999388367,-0.04614755404628128,-0.0672084416914441,-0.03907405984438205,-0.03451116542778754,-0.07875420062345428,-0.034904413221547206,-0.036391391141146104,-0.12273428696186318,-0.05785248435055025,-0.09629965233870263,-0.04385021184917458,-0.09211651313023946,-0.05072420377932826,-0.041807243574410353,-0.039432362645199504,-0.04012004445243061,-0.09633373228957756,-0.057336414070907206,-0.06199117528744654,-0.05518859329087668,-0.05979926336531283,-0.0415984681734692,-0.046920306192528224,-0.05287719157378328,-0.03738444119967227,-0.0649574176998753,-0.03558898763473547,-0.09602581934392088,-0.09730819855404653,-0.0705016173958522,-0.045299188529454866,-0.0457343726174451,-0.06450308147818963,-0.052159651283958365,-0.15582846058762878,-0.05893136057014992,-0.039743149685834665,-0.041721662557441246,-0.04175477905898252,-0.05324806850245647,-0.04580548993634428,-0.12239820062618623,-0.04841152894648274,-0.04283196895780158,-0.04480129646804091,-0.05045889158039534,-0.03704481180305099,-0.05230815830747977,-0.033325744504831015,-0.07072241768250064,-0.038948196468478254,-0.05275935083143122,-0.049780821721742606,-0.03961326957548083,-0.06524516128511701,-0.05193997491980984,-0.06304333185456838,-0.03643721287976476,-0.04121170938197876,-0.039146733294111766,-0.03327407628954927,-0.036040008571376854,-0.05702665661441249,-0.050293031392399545,-0.05489320938355951,-0.042701820842114706,-0.03783926183225679,-0.0360229022237797,-0.04226700883305345,-0.04574799329828997,-0.06583548384077867,-0.04494531292537131,-0.055520305815385,-0.04780024561294825,-0.04516236273477981,-0.048901272223161714,-0.04353197857332204,-0.05227547202502575,-0.04452812079009529,-0.04843938959579935,-0.07795756723388765,-0.0500643785675769,-0.04041408834815258,-0.04731217200467175,-0.056803523517960586,-0.05823669038521542,-0.0699442554573883,-0.04746241807899291,-0.046329994879105565,-0.04707582430428142,-0.03653596726908259,-0.040144543310604325,-0.0534038526604394,-0.060982513707290124,-0.036761551896998645,-0.06406825845293976,-0.05828443364250227,-0.03982950979298077,-0.03793921781498584,-0.039736838931826744,-0.06060976172083728,-0.04554002959906094,-0.05391980876956945,-0.05150973343849476,-0.0666658045392415,-0.04201744411752062,-0.06947024447352373,-0.03737460773678944,-0.0611696600651488,-0.04280731394402389,-0.040283165271475685,-0.06477137029348433,-0.06047882309189409,-0.05218494761774016,-0.035137397714212246,-0.03642363972978024,-0.07486367973151323,-0.04219359523409256,-0.06440932369144822,-0.05014874168536723,-0.06470499638566357,-0.03954915816072468,-0.05823848974625712,-0.06659344050727482,-0.0642629326200637,-0.05109991187183821,-0.04259909179385797,-0.040217211877645785,-0.043060026908438624,-0.043653837873597216,-0.046555737561448804,-0.03483054366389555,-0.056925974859256566,-0.04109611981510216,-0.10851687828812388,-0.0388851735918022,-0.03681543808848973,-0.05035102169434836,-0.04530800967844644,-0.04685667367304162,-0.0517189938531358,-0.05944709156323943,-0.03708080312293196,-0.05674858543869136,-0.051689832690760766,-0.03856061458233643,-0.05376519374416286,-0.0443884203880609,-0.05319232764293019,-0.058763666058653324,-0.05776150656154825,-0.04997521727423557,-0.08226411873889125,-0.03810068292047204,-0.036627779319624854,-0.038060937627105225,-0.051125050362173186,-0.062058171587319404,-0.03853012764954026,-0.06338465240944846,-0.03958208297154192,-0.06301156002126018;-0.06061665633461224;0.025218362405154713;0.0
data/model/LunarLander-v3_108563_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 108563};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 108563};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    
    if is_success:
        return 200.0
    elif is_failure:
        return -100.0
    
    distance_from_center = np.sqrt(x**2 + y**2)
    angle_reward = -abs(angle) / (np.pi / 4)
    velocity_penalty = -(abs(vx) + abs(vy)) * 0.1
    angular_velocity_penalty = -abs(angular_v) * 0.1
    contact_bonus = 10.0 if leg0_contact or leg1_contact else 0.0
    
    return -distance_from_center + angle_reward + velocity_penalty + angular_velocity_penalty + contact_bonus";-0.05159052412654808,-0.05055333706362766,-0.08012463220630635,-0.06572521942347027,-0.08532412585068254,-0.04136157131186829,-0.06593302108073411,-0.05033734539755983,-0.041232154592183344,-0.04840863737906403,-0.05942703140121698,-0.05048301183826602,-0.09180147098125349,-0.051739095095334024,-0.04292846272623743,-0.06741026628450525,-0.045156426826971796,-0.0836299901042504,-0.03756099338275567,-0.06870514562014346,-0.07567456192221717,-0.04511225491886844,-0.059098621616435316,-0.04569957532406346,-0.05398391422156692,-0.08067506602560022,-0.04886578631905543,-0.04927155825765812,-0.047879267396786246,-0.061037010966589776,-0.08826833828947879,-0.09192980575351355,-0.045308675531214156,-0.05256957820369844,-0.05408136057510362,-0.04802170994943067,-0.05532203702275615,-0.05012748902916012,-0.03752773963967604,-0.04748140788033255,-0.04113975821559253,-0.05025619209405675,-0.04841770400863583,-0.048724235316996045,-0.04333288391720768,-0.1354533304198196,-0.04742124882867403,-0.05297888702473436,-0.06788101683566011,-0.05669100477872447,-0.05325076939422914,-0.044416346214535087,-0.04160105780351794,-0.05341765487537842,-0.037828910945220576,-0.04781523919687365,-0.03970346839755696,-0.03656163407157263,-0.0405175102609821,-0.0436834370973421,-0.053182809374166216,-0.04410775782182509,-0.05374823534922759,-0.0417050329399377,-0.039517405871753744,-0.04798043707688526,-0.04097650700595541,-0.05070391914467332,-0.041606085873873946,-0.04740331623706859,-0.04319624173745852,-0.056863874410008876,-0.04876779138006002,-0.045654799508424784,-0.0416662679115775,-0.04658528346919781,-0.047837631684440225,-0.03788516455988267,-0.04912282854546726,-0.039611695247573846,-0.03933690513544536,-0.038923300471820126,-0.04017661805366466,-0.05168720974993974,-0.05002485965582988,-0.04258409973724056,-0.04617659482689621,-0.038244048728838985,-0.03927686791141294,-0.04018822781608058,-0.03949366802589333,-0.039472111250919116,-0.047679792148597085,-0.046520773379868076,-0.048899901038740305,-0.04220255583619549,-0.049065260011559225,-0.03822756197216552,-0.0521271330620795,-0.04595111304353811,-0.037164330466151065,-0.04183271549904431,-0.04524910441750442,-0.04963878023346559,-0.042399028262388574,-0.03376366353419973,-0.05082205471666486,-0.04235581176734205,-0.044886839172766785,-0.043538915426763296,-0.04223389091123726,-0.04003823167281681,-0.0542784930405,-0.0373017663391133,-0.04454884755669266,-0.039029513929935054,-0.03905349976474262,-0.05088812439645053,-0.0448687122316107,-0.039889749608274794,-0.05397337763600277,-0.0493627866161499,-0.04426144003457404,-0.05224830610975241,-0.0457284057615368,-0.04181738637071403,-0.0360765396092186,-0.0428899480044781,-0.0407313127840616,-0.04766891051043084,-0.04136230038064122,-0.04346329077506928,-0.05627480323967537,-0.05292377236225387,-0.0401018845715715,-0.04243879613633499,-0.04901285608320976,-0.046004968981938,-0.04205321779546548,-0.03976694008277777,-0.04665403455527046,-0.04146927531896377,-0.04446757734660903,-0.05088591083078935,-0.03991811940413575,-0.04518187142636167,-0.04879476153531983,-0.04957394883954713,-0.047308658179690564,-0.05411668606248647,-0.03993807941888576,-0.046437763381752414,-0.0485797145115688,-0.048312943747178275,-0.04565663729669784,-0.038175308500815235,-0.041337862650982875,-0.056152415852577874,-0.038094737603053284,-0.04606482777044613,-0.046929886271856486,-0.045695125055889844,-0.04383410234405759,-0.0362196275331757,-0.05399507202563471,-0.048103996180803126,-0.042449365018244874,-0.04627831144152252,-0.04028730457550615,-0.0424283225163424,-0.03924794079920601,-0.04616991082471182,-0.03842683648535058,-0.040421284211653426,-0.049999961641731816,-0.049678293256781164,-0.05832707702931205,-0.010570692505413065,-0.05097353461072287,-0.03812307986487065,-0.0382388868219183,-0.04614253460382224,-0.03261473599641238,-0.038981854230796434,-0.04298031276709846,-0.04367562931090845,-0.04436802146783874,-0.036391384912919225,-0.03972629863593693,-0.04299748427932337,0.035690400515208394,0.040418950933622015,-0.16278877800234914,-0.03577077245986096,-0.04351764755684885,-0.07358384914729964,-0.07181156676095089,-0.06224458809674698,-0.03216384880114829,-0.07028158813308187,-0.03832847628174904,-0.04195223297999867,-0.1251750038740866,0.00494486104760496,-0.08038732558681282,-0.027989187069681634,-0.05914435686133897,-0.07302199399401148,-0.088690577872049,-0.04728478652107698,-0.028673694648056147,-0.08097042021082028,-0.036744220878776525,-0.05048938544947077,-0.09622304187136595,-0.05120056825373309,-0.045738234962677135,-0.045652244390453595,-0.044502282464765466,-0.06682605197976554,-0.08288740793386731,-0.06343027132062377,-0.05382027999584242,-0.08624655028179323,-0.0522835022371346,-0.050570970542972396,-0.05423753986129776,-0.044016118436972125,-0.05704656438455163,-0.051034054517889456,-0.05536365744811228,-0.06885038331078731,-0.07762943774330695,-0.050544461283314426,0.014652250848912089,-0.054214052758582584,-0.0670878702396294,-0.06106040452181643,-0.06991045462453122,-0.06619068735921935,-0.0699518990034513,-0.07169533838778622,-0.06430956694654483,-0.04850365235511366,-0.05788991456659626,-0.06475116947817046,-0.06272865833077816,-0.08407377869130514,-0.07615423626562808,-0.04440246284970225,-0.07802225963305168,-0.057167221119300046,-0.0721683883054126,-0.063369093104557,-0.061930995929359106,-0.046956592500331275,-0.06148655912948472,-0.08105875837576176,-0.061365284787645136,-0.062122186549737765,-0.061250329735017144,-0.062146569124000066,-0.054676589862469704,-0.06762988730897686,-0.07108234806281238,-0.07379708516279002,-0.08316684685454595,-0.07618545671205715,-0.06265893559219836,-0.05993162855444581,-0.06831882676510154,-0.05640755512654892,-0.0692746188059362,-0.06295807963334173,-0.06494115206123771,-0.06843043277636733,-0.06398979527938772,-0.0671982815162811,-0.058918597451640006,-0.07409294905720892,-0.07453549604859645,-0.06586520123109772,-0.06980199049448421,-0.06626115890631448,-0.05856566227115463,-0.08196992313716174,-0.05148682661646919,-0.049928950303562605,-0.052397598868926164,-0.05618776189723166,-0.05424445051731568,-0.07268384995251995,-0.06399093477129689,-0.06856592443154066,-0.05154679866839672,-0.060649697568241706,-0.05785215341565441,-0.05662351009907871,-0.049721149376518434,-0.05644009374646375,-0.06230342341890059,-0.06216679836756482,-0.08319079005881212,-0.05673731730989444,-0.036283026839341044,-0.07109160334304658,-0.06929086940004618,-0.06545326136512003,-0.04783505100878084,-0.07832423746621357,-0.06688386728029652,-0.04152061834529526,-0.04501938535993625,-0.033169901702617376,-0.0449509711908662,-0.08608606631893931,-0.05075816341706466,-0.07699647460886468,-0.050938148991338236,-0.08226053462504482;-0.052830631473575175;0.018273597842332213;0.0
data/model/LunarLander-v3_309260_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 309260};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 309260};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    
    if is_success:
        return 200.0
    
    if is_failure:
        return -150.0
    
    reward = 0.0
    
    # Reward for being close to the target coordinates
    reward -= np.abs(x) + np.abs(y)
    
    # Penalize high velocities
    reward -= np.sqrt(vx**2 + vy**2)
    
    # Penalize large angles and angular velocity
    reward -= abs(angle) + abs(angular_v)
    
    # Reward for having both legs in contact with the ground
    if leg0_contact and leg1_contact:
        reward += 5.0
    
    return reward";-0.06640185811759508,-0.05277196571219679,-0.06297438938107286,-0.06792237084703863,-0.07693911244251805,-0.0839058696891372,-0.0588087103632935,-0.04543253283745756,-0.042971243857306135,-0.07118162723417452,-0.0641747739219446,-0.0538897898842734,-0.08805886388241399,-0.058743536546525574,-0.058894552279734884,-0.09222138056362107,-0.047404463655433556,-0.06451256912040512,-0.08925632671845384,-0.08602543641036255,-0.15766527105320358,-0.2864807631490097,-0.28884422320957276,-0.30158129332849526,-0.29203723560662664,-0.20061751444724446,-0.1150531236669899,-0.20362705934422756,-0.1360266454442214,-0.19716756138846114,-0.13566454859611596,-0.19006098035053912,-0.1542604612591098,-0.14154481480909195,-0.1437840195545851,-0.07935641990464364,-0.1848149902751425,-0.15222088798843753,-0.05764958593338512,-0.117591726031393,-0.1374928021782801,-0.10888622875553516,-0.06468876444648916,-0.13686055479623022,-0.11985368862307617,-0.05145182233224683,-0.10743791446899263,-0.12522497821300888,-0.052298927866798406,-0.05653369923527926,-0.05610940560414429,0.025532309619966904,-0.06456018505263816,-0.07196028325794986,-0.05849684437529484,0.1634064236672768,-0.08367910681184915,0.1844015831364932;-0.0998402653172333;0.08528364867739471;0.32
data/model/LunarLander-v3_196361_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 196361};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 196361};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_pos, y_pos = observations[0], observations[1]
    angle = abs(observations[4])
    leg_contacts = observations[-2] + observations[-1]

    reward = 0.0

    if is_success:
        reward += 100.0
    elif is_failure:
        reward -= 100.0
    else:
        reward -= angle * 0.5
        reward += leg_contacts * 0.2
        reward -= abs(x_pos) * 0.1
        reward -= abs(y_pos - 0.7) * 0.1

    return reward";-0.07771629404220408,-0.07379926207596364,-0.09500653521967457,-0.07664271839052302,-0.08638686908972708,-0.07824765891010058,-0.08348040873749239,-0.08017009283757828,-0.07225714654496632,-0.07390214174683972,-0.07970154899560777,-0.08165658688303629,-0.07986666168610687,-0.08334811292836732,-0.07922055695895797,-0.09532134479182433,-0.07165462236857632,-0.09257597434924453,-0.08554070469215805,-0.0700528985425063,-0.07194770962475601,-0.07304151025626945,-0.10820619509883926,-0.09344055589350829,-0.09459516821831308,-0.07564171546338189,-0.07312054673056743,-0.07234211075780965,-0.08794936118149045,-0.07042932043552523,-0.08395328678985443,-0.09670217374102964,-0.07648137750243501,-0.0904228363479507,-0.08431554241886867,-0.0971435085672514,-0.07495783230576121,-0.07704337306953511,-0.08545020692760975,-0.07462656753627707,-0.0777987930963577,-0.07017880964178624,-0.07144695032583288,-0.11005151883069127,-0.08838636300922109,-0.07151820000903072,-0.07063361139581041,-0.07328991049146791,-0.077065610915071,-0.09793182807080646,-0.07381275583810525,-0.07589054231915579,-0.08087172999222986,-0.07073852800569631,-0.07307802465871095,-0.07549679249224042,-0.09245906450523808,-0.0744510858882559,-0.07395375257213894,-0.07233930038169087,-0.0934270286741542,-0.07393511659022572,-0.07589509263668645,-0.07588946367006182,-0.0725249820895742,-0.07249449282002719,-0.07527406946829793,-0.07044781841669746,-0.0742358421927902,-0.08117264303286227,-0.07533428322303215,-0.07147595353520585,-0.07093219343426767,-0.07273104838347606,-0.07252379677616429,-0.07287747353954295,-0.07233691597840901,-0.07691103040120932,-0.07181266696722617,-0.0732930582378281,-0.077401600963992,-0.07295122436294137,-0.11988865100434551,-0.09408765523832986,0.10674278216899066,-0.07318090805645558,-0.0869729451534227,-0.15508297831485068,0.08846613193954364,-0.0751994971812847,-0.08100313344603303,0.08526734644483279,-0.06728280715891051,-0.07351969488428418,-0.10249327616871245,-0.0868138018093384,-0.07376531080598334,-0.07506167898587897,-0.07658318673386003,-0.07155791603541277,-0.07660509008294068,-0.07107009056410739,-0.08135065391191888,-0.0923442550716579,-0.08330385929062996,-0.08183627748216696,-0.031641186759107674,-0.07408977329377686,-0.07171064173054327,-0.078548468717407,-0.07574837473665214,-0.0770413989409195,-0.0830114577689344,-0.07190275588099435,-0.07598044848083933,0.06754730107926318,-0.08210167182175908,0.05374575574575495,-0.08558402976067699,-0.07176239440846362,-0.09045096615815801,0.08161011829775051,-0.11061979486032142,0.09325755745318089,-0.0803967275622467,-0.08250046112644031,0.07106415939061858,-0.06381643876093854,0.12445328508237066,-0.08113634439139301,0.0990984163689078,-0.08215255590261086,-0.07328551185576376,-0.08857151012977789,0.1755465238548909,-0.08101699647479378,0.13110001512949954,0.03543906384431005,0.0731752306796001,0.008302318845119817,-0.07803878214709403,-0.07146704546951602,0.1361118004462385,0.07398252478221953,0.09855347959869029;-0.05899134896455565;0.058451453972334595;0.23
data/model/LunarLander-v3_226899_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 226899};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 226899};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y = observations[0], observations[1]
    distance_to_target = np.linalg.norm(np.array([x, y]) - np.array([0, 0]))  # Assuming target is at (0, 0)
    
    if is_success:
        return 200.0 - distance_to_target
    elif is_failure:
        return -100.0
    else:
        return -distance_to_target / 10.0";-0.05110145772286554,-0.04891141743356106,-0.04958266650045512,-0.04943475964744537,-0.04921265039020243,-0.05214005785004534,-0.0494555392367599,-0.04945856445214107,-0.04873202259670349,-0.05141334582468659,-0.05481718413477846,-0.04965515767900343,-0.04905219381799031,-0.051388610162432846,-0.049935851374944676,-0.04854605031432115,-0.05236345532391282,-0.052245966496262404,-0.0509196904447932,-0.048509172504330136,-0.04950695926200295,-0.04810947041566202,-0.04852810844476766,-0.05151033092039404,-0.04910817072354379,-0.04854552081256289,-0.05092367909677687,-0.051243301444865684,-0.04961646729084308,-0.04903972377708654,-0.05070101109218127,-0.04945440282646391,-0.048651985975820156,-0.05170437963460311,-0.04874150072238773,-0.05032179167915612,-0.049356789067658384,-0.05037201779359204,-0.04913209013436426,-0.04992407460408834,-0.0525838576465474,-0.051450133630131074,-0.05075281269315129,-0.048961504021264,-0.04892280461570489,-0.04895601247177609,-0.04841481473439549,-0.04969248566303294,-0.04985789061952092,-0.05033429649164398,-0.05056546095994283,-0.04902387479049983,-0.04970696900389536,-0.049411701203762474,-0.052662427597909775,-0.04855808206878182,-0.05054139207183064,-0.049005574834753346,-0.05071610558415421,-0.04866721664133115,-0.0487348423864007,-0.049669086181998515,-0.05148888914118295,-0.04825629271528644,-0.04848680972679969,-0.048991688751476935,-0.04866461789465589,-0.050324094980684915,-0.04854535805555473,-0.04842406235840398,-0.0491950718400924,-0.05117961051007993,-0.04826173150904262,-0.05087729675329651,-0.04910415441499895,-0.0503785865582394,-0.05174305947127372,-0.050397430758298306,-0.05024036410991986,-0.04899027942751277,-0.051850152107785714,-0.052338018674799244,-0.051056431761329006,-0.05042349083811798,-0.0487449712705571,-0.04888055621472786,-0.04987764226915881,-0.05048877164057492,-0.04823205002762988,-0.05064238373756698,-0.0497040999005133,-0.04854880339252283,-0.0487001667147473,-0.048489494091547174,-0.05079797308981836,-0.048886433971403735,-0.04938849408889386,-0.04970127438265603,-0.04815022191417261,-0.04798767076318792,-0.04838346605493618,-0.048435024537255046,-0.048120324999536036,-0.050114843076388256,-0.05252129952634412,-0.05041565790181198,-0.0485171043114902,-0.04817700196608639,-0.04832465604305472,-0.04897605860335391,-0.0481408711065571,-0.051479072402903725,-0.05127596754533724,-0.049328043839305516,-0.049717622431270876,-0.049227322510101874,-0.04867305752745681,-0.05071954502298463,-0.04997514477074214,-0.05018743733863881,-0.048340578269393704,-0.04847692511422347,-0.04801151909288608,-0.049097682315252376,-0.048215985058718644,-0.04843728147245088,-0.05071505695442354,-0.05062872326524653,-0.04890844928773766,-0.04906177810628966,-0.04816467866179979,-0.04893489525517879,-0.048087817597213034,-0.05003485275058464,-0.049361287923789236,-0.05041472526893209,-0.05051898470983494,-0.0481795247709661,-0.04814931748867153,-0.04886871262935926,-0.04974795671560885,-0.048448438132852156,-0.048773704111146815,-0.04797401798192568,-0.050366556596270026,-0.05045901825776907,-0.04852019392220716,-0.04930442281819336,-0.04979318197032858,-0.04926887896136271,-0.04919017471525693,-0.04846559276059405,-0.04944677332418488,-0.04922645886238284,-0.04821433294747384,-0.04872660625630456,-0.048111187901760125,-0.04835954608632298,-0.04842127568687217,-0.04952802139190014,-0.0489179839163876,-0.04919721309113619,-0.04836775552156215,-0.04864638581642568,-0.048287973272621264,-0.049003111573979394,-0.04835005675048571,-0.049356279376877955,-0.048788256592553675,-0.04953070854754284,-0.04877465049161084,-0.050065439458990176,-0.04929798651504747,-0.04797390185802092,-0.04820013637517284,-0.05054685987681814,-0.04941172576263169,-0.049868802793187256,-0.048525993703365314,-0.049125325586399926,-0.04923965690725265,-0.04852963569371262,-0.04849984253442598,-0.04819806789000432,-0.04852513922585321,-0.048277768132897476,-0.04908542869792818,-0.050489712556000814,-0.049527962553888305,-0.050124258767515514,-0.049764207332277426,-0.04902343036683437,-0.04828192897972514,-0.048447903103923794,-0.0502351142930787,-0.04833802052595693,-0.049142690807724994,-0.04815001910092883,-0.049834044897434024,-0.04992237432736612,-0.0497712506023372,-0.049109048060470804,-0.04821205256717,-0.050672887976778686,-0.0500167658710175,-0.04988189712412843,-0.048594803297940255,-0.04886636214916757,-0.04878110131067406,-0.049705554562145336,-0.04902916032024057,-0.05037000566201493,-0.04801414305033337,-0.04949181209413626,-0.048400940277416815,-0.0500684743139483,-0.049381321586048986,-0.050391381129349606,-0.0503140276704933,-0.050149961030675844,-0.048815543580301206,-0.05028789193432029,-0.0483475474429453,-0.04921178490535151,-0.048676068481028616,-0.049370493655181376,-0.04947039728213264,-0.048771869566696255,-0.048975882343426376,-0.0496451290481643,-0.0499199009932718,-0.050637924982419646,-0.050099781731768794,-0.04826503718063438,-0.05015444252977349,-0.05018748499547108,-0.05033639696952002,-0.048568824582459855,-0.049550801969814255,-0.0509460269236808,-0.048919654799858096,-0.05084458478290392,-0.04839350862479888,-0.048532871689931346,-0.04941969251070963,-0.050512999855237786,-0.04921202516786351,-0.04901997515528237,-0.04814479951681853,-0.05043306859215127,-0.04901474379818278,-0.04844254449067283,-0.048529025698535774,-0.05043329917280653,-0.04969895778681676,-0.049047504219495025,-0.0508494229332572,-0.049315410781276325,-0.04969717077257372,-0.04815126836649422,-0.049102669790947684,-0.04891382072828987,-0.048842068862263076,-0.049384366852780394,-0.0502310923259101,-0.050385345668636734,-0.0498745016018425,-0.04881056737034504,-0.05086977497562392,-0.05035221759473936,-0.04936599724483966,-0.04853543911243483,-0.04856611214221646,-0.04921479645384499,-0.04847395177807325,-0.049251245167666644,-0.047994717763097584,-0.04817388225645302,-0.0499729932025717,-0.04920228694250601,-0.04837287870507399,-0.04984710437008534,-0.04870349416674749,-0.048628633755432776,-0.04808923677644546,-0.048183140123759495,-0.048808078302160426,-0.04811344511660349,-0.04869453346315622,-0.04833255795207372,-0.049126919372141184,-0.048615693477443586,-0.048105263599974316,-0.050463570916110055,-0.04848914693113807,-0.0488396037051226,-0.04821710498891143,-0.04997978569522215,-0.04868289804672155,-0.04843348586117806,-0.0483475698696899,-0.051633121189579384,-0.04893392503084612,-0.04938631071687994,-0.049917562557883356,-0.049081187437734534,-0.04857701997458562,-0.04977592940897035,-0.050427078277022974,-0.04914073492522023,-0.050082326953698096,-0.04890890224676938,-0.04920646292485378,-0.04952371105640598,-0.04982948944648088,-0.049134882434044035,-0.04876613144835483,-0.04859025160269849,-0.05060808560295505,-0.05057384008156836,-0.0488359887199702,-0.04875002883004389,-0.0491270686219376,-0.04857115860358093,-0.04905274548315662,-0.049216325736082873,-0.0489526944184305,-0.049397541101534104,-0.05002995229377462,-0.04996507542596988,-0.05046357697692834,-0.04895560107356097,-0.050416961013798854,-0.04988496653369165,-0.049308419075387966,-0.04892885307884747,-0.049255399081682236,-0.049160357219955264,-0.05116941755637818,-0.0496958482230447,-0.0501625705289909,-0.04937552643420565,-0.050680514891191325,-0.049593223980613145,-0.049720738306535284,-0.050523760426892106,-0.049410446918706365,-0.050250757753969366,-0.05026452581439908,-0.05033079618708887,-0.05119359613843353,-0.050445934470591376,-0.049382136524018815,-0.04967321736279471,-0.04985863025912059,-0.05095003958371605,-0.049972025700241805,-0.050480139733894015,-0.050033510545246754,-0.05001522685240985,-0.0493556347290155,-0.049991816562451136,-0.0498387583580405,-0.05045889011696143,-0.050947587562068575,-0.050429148225673084,-0.05066016958461716,-0.049866625803918936,-0.051182295191603895,-0.05028335951361815,-0.050074675636765605,-0.05110532041627954,-0.0509104990868119,-0.049844805886306146,-0.04966576524160874,-0.050242890736291436,-0.04945387409303885,-0.04939899707834654,-0.05186859706646345,-0.050309046902904796,-0.051006078740569394,-0.04944843464770178,-0.04961744108749588,-0.05001742561426645,-0.050911184230555385,-0.0511892549408406,-0.05237083249784403,-0.051900412619511574,-0.05174073676997557,-0.050804901848185376,-0.05175747299683204,-0.05126756315456353,-0.05140412445106075,-0.05229376060863759,-0.05050399414286763,-0.0503594420678133,-0.050576315651984435,-0.050696550494751205,-0.05021785741403129,-0.050092237498163536,-0.051235620626513885,-0.05416237370169535,-0.05127023136714444,-0.05114910937853993,-0.055393786575692425,-0.050237712524241016;-0.04961641968865661;0.0011247597393242213;0.0
data/model/LunarLander-v3_81191_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 81191};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 81191};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    contact_reward = 1.0 if leg1_contact and leg2_contact else -0.1
    position_penalty = np.abs(x) + np.abs(y)
    velocity_penalty = np.sqrt(vx**2 + vy**2)
    angle_penalty = np.abs(angle)
    angular_velocity_penalty = np.abs(angular_velocity)
    
    reward = contact_reward - 0.05 * (position_penalty + velocity_penalty + angle_penalty + angular_velocity_penalty)
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        return reward";-0.06298764660153844,-0.06352595313518918,-0.06227835283427645,-0.06162907647930679,-0.06648106739538373,-0.06226351348708385,-0.068712273115685,-0.07265502834051871,-0.07271141700328337,-0.06320235662859461,-0.06406851059242838,-0.06211292350987595,-0.06798378617493128,-0.061411842076625756,-0.0629742855206538,-0.06749053148964627,-0.0628511748336506,-0.06524576521311987,-0.06632646415513718,-0.06404421845286744,-0.06696340379679974,-0.06188087038804053,-0.06520826330044008,-0.06569255333839753,-0.0665042166646514,-0.0676834608469354,-0.06658481604395837,-0.06918186460775552,-0.06317033955486556,-0.06852482198884052,-0.06554193306196716,-0.06837616316942659,-0.07133851615953649,-0.07014398404597687,-0.06929288353838177,-0.06406662324567229,-0.07047052845400345,-0.06831652477584031,-0.09447248479481597,-0.07237394238004531,-0.06665138717806907,-0.06996890771119205,-0.07299046091080857,-0.06715550248862162,-0.0854772893162156,-0.06671101056125675,-0.06827770860572484,-0.08759089540138629,-0.0784588645396616,-0.06514153684596388,-0.0652756377897729,-0.07537003709200471,-0.06868476322326561,-0.061178434907105485,-0.0735430410560347,-0.07255741857646203,-0.06338362741830919,-0.07123058739747519,-0.0709722691489799,-0.07861763780457263,-0.06172829982436114,-0.06257307955383574,-0.07145417363088524,-0.07345199007458543,-0.07450014920758542,-0.07156701897407451,-0.0720523103276335,-0.06805397422549492,-0.06212653374044798,-0.07198828273135864,-0.06823095005948072,-0.07785183724852328,-0.07129488256045131,-0.07388969022651115,-0.07141432528090623,-0.07083652045975262,-0.07243471039415678,-0.07274686542301124,-0.07170884137173554,-0.06985364517792461,-0.06682241760854477,-0.07287318787672922,-0.07612164494359165,-0.06415753352408363,-0.06729751103815428,-0.07708673560545733,-0.07149257355519592,-0.07272324016933668,-0.06645730428024697,-0.06352618322912235,-0.07132164587184028,-0.07065681450204349,-0.06865683294960702,-0.06801945495189625,-0.07073626307593649,-0.06964377333890003,-0.07723632674013538,-0.07037617195840734,-0.09209661750049641,-0.06756220710919807,-0.0634133834002786,-0.07359566238717935,-0.07063595614879713,-0.07058221996185651,-0.07058733207942608,-0.06143255921911748,-0.07022902620027333,-0.06145601965321084,-0.07466821220591409,-0.06271822328675115,-0.07063486791537203,-0.0736859702187804,-0.06397943530044112,-0.07812645786264015,-0.07225594417911572,-0.06416539706491102,-0.06877379657949118,-0.08255768913498289,-0.07490402703354093,-0.06454029471639373,-0.06681609942633064,-0.06729953767125492,-0.0821104374930189,-0.07274771978738384,-0.07366222810018591,-0.07887629877002987,-0.06990866407835364,-0.0810788056072885,-0.07466218307009327,-0.07404269073615725,-0.07587146791601415,-0.06928163573818504,-0.0647613177010954,-0.06679817346459,-0.07568332105351014,-0.06833580273802103,-0.05253747094255207,-0.06245832371364664,0.08330817555502368,-0.061956770235109086,-0.0716459770690677,-0.06480282302547205,-0.07142844972203935,-0.07211480472592896,-0.06912338617486179,-0.09252926758684127,-0.07208770281663451,-0.09656410720542913,-0.1057503031354939,-0.07025152189893455,-0.08404927952602612,0.12248791666190773,0.08238746888933783,0.19575066444654596,0.19005866099467217,-0.08522392680445157,0.1962186772181026,-0.07574550133894746,0.16096623095716145,-0.07902109567511584,-0.06625588416365856,-0.07257929242862161,-0.08487806523769605,0.02262218706868814,-0.014642640660536822,-0.07969782717917999,-0.07287636448815694,0.09027675325456443,-0.09275604470916402,-0.07063626554480336,0.11498540330446974;-0.05893586979560556;0.048729010535918924;0.48
data/model/LunarLander-v3_432457_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 432457};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 432457};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    vx, vy = observations[2], observations[3]
    angle = abs(observations[4])
    leg_contact = observations[-2] + observations[-1]
    
    if is_success:
        return 50.0
    elif is_failure:
        return -50.0
    
    reward = -abs(vx) - abs(vy)
    reward -= 0.05 * angle
    reward += 10 * (leg_contact > 0)
    
    return reward";-0.05298690113402789,-0.08846133153762104,-0.050855661834273515,-0.0488221781547788,-0.03253614161719044,-0.05940057221144174,-0.050976797585277074,-0.05580186344330875,-0.05541744607152012,-0.051768743354444,-0.047033547943334614,-0.07700374856663311,-0.062042583121041626,-0.06656511338922465,-0.07393724447319067,-0.0889724329084464,-0.07327539933687893,-0.05927422645197555,-0.055196850221009494,-0.078451478385403,-0.08476949003208382,-0.06144844204774076,-0.06188792059125248,-0.08965076567531882,-0.04721991661505316,-0.06796431242068714,-0.08306442866345427,-0.07086669526734032,-0.051676816000197606,-0.08236005650442929,-0.05774695661602482,-0.05508213030754653,-0.055902239508547294,-0.053567533719811745,-0.06907995513870187,-0.07380053006313146,-0.05634636580221473,-0.06674674338393444,-0.053767424244052016,-0.05724529418289359,-0.06498281318783514,-0.08275226943946462,-0.05396637630955606,-0.15194197859694197,-0.05423638968853963,-0.059100593485540934,-0.05905237008914208,-0.016936623930371066,-0.07491254640605247,-0.06582656099518963,-0.04651985223370973,-0.05609782221387366,-0.046752677507534236,-0.05817898265508094,-0.07891993689202095,-0.046562589279452574,-0.04709086893703242,-0.06076761016472083,-0.055704947612796964,-0.06990125268321441,-0.061431892078845966,-0.05436818009596827,-0.06568155100951995,-0.048036288507259765,-0.05046045308687595,-0.04628470753541846,-0.06416060415129994,-0.05385662883431467,-0.04450348117961423,-0.06482548016998753,-0.045814083249774734,-0.0599883659596972,-0.0524505544087449,-0.05767307422558391,-0.04329828114413479,-0.04370990225742046,-0.06655885455527003,-0.04432315859118693,-0.04647833011335708,-0.0740209364571507,-0.06685651545636612,-0.05149258878806017,-0.052261562880146495,-0.054003202210660725,-0.05754195156214889,-0.05683782013966503,-0.05171844467713244,-0.03626137334611342,-0.0613623675190925,-0.056282231744726366,-0.04998171304825336,-0.05886995160993173,-0.03798684017806095,-0.04102740112784812,-0.04954519821324165,-0.07095988201910927,-0.06477270949633618,-0.06335822898866833,-0.0504337514266135,-0.05820623851425507,-0.06166022159369901,-0.05716690368363199,-0.04583738249793983,-0.03606192718432275,-0.06697560441571285,-0.0538504140763947,-0.051016748289250284,-0.05470384289574482,-0.06270061569839433,-0.057522132208900865,-0.05752268175352133,-0.05602577285900614,-0.053152888458765674,-0.05780700853141019,-0.05746284920029044,-0.052120268238269235,-0.06500833202857395,-0.0577471955803389,-0.06860665105641726,-0.06391962311767387,-0.0522061200072946,-0.05410806417814636,-0.05539340760539162,-0.06229420109034956,-0.05136270092171228,-0.053903971037015656,-0.07097207450435548,-0.054039113248808106,-0.047216927465913355,-0.05609467626425534,-0.04654322686528125,-0.04547511915219598,-0.05915622195202485,-0.0508965851159803,-0.06581952826076562,-0.05239062838580913,-0.06624081926782292,-0.054635428927527874,-0.0858926502378665,-0.05449927852700467,-0.05021069671302676,-0.053807894066233417,-0.06667517417966004,-0.05317092079631254,-0.07258805535827656,-0.05229427456582844,-0.050062294410692605,-0.05583772870048332,-0.05037361357616062,-0.05433646226237994,-0.05737457409061297,-0.05388782262033045,-0.06380213419911289,-0.05055950562646886,-0.05026960996605161,-0.0589296231004819,-0.06721785032618126,-0.03944745062538885,-0.07977104470327703,-0.05633242818874289,-0.07111724642469351,-0.0796454021537249,-0.04967083456753933,-0.06837285162123194,-0.05354008568433896,-0.058718215085772296,-0.0474900095006771,-0.05939361517348449,-0.05208369145446502,-0.06194464997418082,-0.047518497302744184,-0.0802597207392639,-0.06393633018979944,-0.05668529789738957,-0.056414999024160375,-0.06415614752792713,-0.05683980789806515,-0.05482115933484841,-0.07829629364039885,-0.06214332202170478,-0.06057693680621905,-0.0658947809087458,-0.05358849711776772,-0.05562382038114218,-0.06935513600949758,-0.06312092417545302,-0.04976369482331886,-0.03842184497876158,-0.04454593152888332,-0.05340795569347094,-0.04691752893629605,-0.06736602119979315,-0.050500715750530015,-0.05241171701096145,-0.07258977560813026,-0.05869492693826926,-0.04982103898348296,-0.05841204406193222,-0.07126004788256413,-0.054844578033100944,-0.058370674916613255,-0.05346687757398104,-0.05506840142897545,-0.05649191930036634,-0.07306385603122789,-0.06528809909002434,-0.05288271822738138,-0.0704282159151284,-0.06034303942742911,-0.04095099399268824,-0.05203550043996034,-0.04730031194366699,-0.05762003811187515,-0.06513011897565889,-0.06452267407155797,-0.05118302552314826,-0.05013708868944475,-0.05826102059458036,-0.025483806670635482,-0.05396078636646494,-0.058317977494503646,-0.05686557389537306,-0.05508576210087508,-0.05443678496075422,-0.046076762892147655,-0.06080045734292452,-0.05879638808291606,-0.06292709741038796,-0.0523446287082722,-0.049840181858353455,-0.051875508602806354,-0.06595052871765493,-0.06466838347834786,-0.06705849286842265,-0.058975687357025186,-0.06233678079882991,-0.07177519180633811,0.02905866209668145,-0.05861510922891771,-0.05464373105602609,-0.053848026094764384,-0.05672018739583193,-0.06320462406533237,-0.061015237625455306,-0.040770618902703136,-0.047831362522121494,-0.0626925534229962,-0.06292676608563347,-0.059673866046043474,-0.05549472332510423,-0.051410438551520644,-0.057368036755112074,-0.057733832576168556,-0.05818920545314514,-0.035809658571752216,-0.06384935290007641,-0.0573370267738938,-0.07438126069941857,-0.06906924234162388,-0.055576370339266004,-0.06295863130498279,-0.04507460287001772,-0.059227738840096064,-0.05551727191104103,-0.07106983387675804,-0.05497578836565242,-0.05725543120394758,-0.0653742845752799,-0.05534383801663207,-0.05738436517692017,-0.05083715015703619,-0.06073735665338222,-0.06298452559289716,-0.06605566534358465,-0.033010410444591236,-0.06960194133403398,-0.06803372692979943,-0.05477354099172525,-0.06052300359897329,-0.047368854388799474,-0.07049093784134608,-0.058748028021928037,-0.06868725915611976;-0.058039743077010916;0.012843563685683314;0.0
data/model/LunarLander-v3_319551_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 319551};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 319551};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    reward = 0.0
    
    if is_success:
        reward += 100.0
    elif is_failure:
        reward -= 100.0
    else:
        reward -= (abs(vx) + abs(vy)) * 0.1  # penalize high velocities
        reward -= abs(angle) * 0.5  # penalize non-zero angle
        reward -= abs(angular_velocity) * 0.2  # penalize angular velocity
    
    return reward";-0.08217495623174428,-0.08195554894783692,-0.09210768638123251,-0.1048862188817103,-0.08499720161043857,-0.0968789997417008,-0.08243763691484991,-0.07921774978367793,-0.08688704794443172,-0.07866509289017717,-0.08614200164010523,-0.08177721231002436,-0.07740595168412939,-0.10944604628077864,-0.07913422123649094,-0.11309873443160091,-0.08745484007926707,-0.10433916993345042,-0.10276327663557847,-0.08771367820563195,-0.08279498021314123,-0.08280268563191075,-0.08006528647985243,-0.08249495241862048,-0.09434345874066268,-0.09990843957446201,-0.08963895095326525,-0.12085186639276756,-0.08643519475346957,-0.08281215853347104,-0.08611777525943445,-0.10377952937126948,-0.09325250162690547,-0.09173339546375661,-0.09623756184346156,-0.08329049549638355,-0.10455382694892504,-0.09209481756669373,-0.08251843984128676,-0.09618788076771072,-0.1030513140823501,-0.08259397034442874,-0.08580352099278421,-0.0996523272710189,-0.09414941765574487,-0.10370804790559429,-0.0823517332813975,-0.0904494014301317,-0.11771829698140371,-0.14177171267736033,-0.0886708409357777,-0.08766041668346103,-0.12302145402225062,-0.09449431382348851,-0.09044615639420409,-0.17999424496906136,-0.09072479060568192,-0.11430670384946211,-0.08787569759018538,-0.09043395165511633,-0.09279727283862066,-0.08669965431484705,-0.10612795645363828,-0.11045798626038103,-0.13278894317076634,-0.08493430189844878,-0.1266667990056702,-0.08785259504266775,-0.08688102441728351,-0.08802464671691684,-0.08588948303309908,-0.08888833607532477,-0.08860662019813946,-0.08220336702581257,-0.10623587938481581,-0.09018912757423575,-0.10767895784908375,-0.10247520739083982,-0.09057712761185095,-0.08612620904034207,-0.08753402733824767,-0.08739178653281851,-0.0842895028737093,-0.08903954347006084,-0.09385806419979144,-0.09551679580631825,-0.08716808577947663,-0.08403724457821482,-0.10682330230613776,-0.08623585275396226,-0.090920772956097,-0.09997419576148665,-0.07963382982630485,-0.13230454521026952,-0.11967904068523204,-0.08135868531689716,-0.08605890858354616,-0.09492377809387038,-0.10975798517436561,-0.11137402543378644,-0.08213037549236105,-0.1169110667378303,-0.08928981964583924,-0.13154532122456436,-0.09663947144919283,-0.08328827900079384,-0.08435915843547558;-0.09536841815666024;0.01583222065345733;0.01
data/model/LunarLander-v3_307547_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 307547};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 307547};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg1_contact, leg2_contact = observations
    stationary_reward = -np.abs(vx) - np.abs(vy) - np.abs(angular_velocity)
    if is_success:
        return 100.0 + stationary_reward
    elif is_failure:
        return -100.0
    else:
        return stationary_reward";-0.14584366039622237,-0.11045931410031797,-0.12438282851712268,-0.12707828623790193,-0.12155451246271996,-0.0887667102939818,-0.10580556422422437,-0.10614145338476257,-0.13540159363417473,-0.08356591543509402,-0.1007510328452343,-0.11055487661519413,-0.12165655416444421,-0.10453602294959251,-0.10635959454068702,-0.1350203301117616,-0.11058803944120808,-0.13265357617434734,-0.11457844161358771,-0.15580842951068843,-0.1372898568641659,-0.1149620912192221,-0.13492645367368694,-0.20240426919284846,-0.1891731908595999,-0.1184297390224433,-0.16492232245980032,-0.17107009584091304,-0.11638973286831633,-0.13034409087042503,-0.1224536759594092,-0.1063078335171896,-0.10466376205966942,-0.11071139004949947,-0.11196169370499906,-0.13187190393352163,-0.11256003091948823,-0.12873699157384808,-0.1095649989777718,-0.10616292709824159,-0.14707902420033098,-0.12258468059994482,-0.10961792538029493,-0.11093406893585739,-0.14900093038864068,-0.1845307986244935,-0.1556180465495801,-0.14056354402646984,-0.13616627347384533,-0.10154379044880059,-0.12122216095455754,-0.10042826286066939,-0.10439320433272552,-0.12028316505382669,-0.113386046020977,-0.10003003855783223,-0.11815289168149348,-0.11736689369540361,-0.12900777908565467,-0.10568552528754145,-0.12082653228196222,-0.11338463593080553,-0.11629786623868221;-0.1238812360623606;0.022944612105624335;0.0
data/model/LunarLander-v3_399215_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 399215};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 399215};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    reward = 0.0
    
    if is_success:
        reward += 200.0
    elif is_failure:
        reward -= 50.0
    else:
        reward -= np.abs(vx) * 0.05
        reward -= np.abs(vy) * 0.1
        reward -= np.abs(angle) * 0.1
        reward += (leg0_contact + leg1_contact) * 10.0
    
    return reward";-0.010706917135166864,-0.022369372513555544,-0.010483795974052227,-0.03459593261651617,-0.017852143826786432,-0.039180441564175404,-0.04152134770969481,-0.06026164358534017,-0.059000257071643455,-0.060500644990205,-0.03801562886285102,-0.020342599152943033,-0.04289230937276316,-0.034929359478109344,-0.03572494817307527,-0.033001768177610684,-0.033975624576341804,-0.035034942795894496,-0.016111150040223322,0.049024968471528506,-0.033779971964859566,-0.0560977800155654,-0.022653247038103716,-0.058914946116749065,-0.044957059869760965,-0.05512806092174977,-0.03342219956407498,0.004842344318037874,-0.027732982454234865,-0.01740337739632057,-0.028197363510619803,0.01846488149858412,-0.029201550480190543,-0.03301670153814796,-0.032978890736712556,-0.0358514352125933,-0.035077310071359266,-0.02612444925775651,-0.066180658589556,-0.04116931139430985,-0.0371938367799214,-0.05591994558925845,-0.08285609539969495,-0.018794555817950562,-0.05561411731412772,-0.026100501161826887,-0.055370624476149224,-0.04382555180412198,-0.05874449992183593,-0.06177495593782388,-0.056082156004811326,-0.06538530425118401,-0.05409603911088229,-0.05757271209368089,-0.05568010788350144,-0.06253901637372677,-0.0617326787755938,-0.05315933150388974,-0.12720397822123666,-0.06020380623005216,-0.061771903014999754,-0.055299649883555534,-0.06294163097578627,-0.06292623642056583,-0.06092602270099892,-0.03592158551066522,-0.03484780286631543,-0.027874684459069047,-0.04168062977915332,-0.04302180229147212,-0.06504540027185185,-0.05883941425319233,-0.06060911283398259,-0.03430714856077349,-0.05830751595206046,-0.06207487022540732,-0.059782341642802814,-0.054259507328331354,-0.060151565237603115,-0.07781919608308349,-0.04207771937912092,-0.05646939684311002,-0.06868042394203337,-0.08434217006785066,-0.05728758006179106,-0.05716674072678687,-0.035881537911129954,-0.0548884857671838,-0.05456632448360706,-0.04561500325750314,-0.054940917192417116,-0.0563841693486087,-0.04336248489300788,-0.05691953136978393,-0.0572282518415983,-0.02963747359460049,-0.055383290966204306,-0.057407456769642054,-0.07395934725580713,-0.059763328935865445,-0.05836822841823225,-0.05772896084639742,-0.058541402398483926,-0.06014215537529316,-0.05888365580375434,-0.020333579362667456,-0.05288215157569922,-0.056485122993106165,-0.059323173406514794,-0.05525890948519173,-0.05758546102791587,-0.05713698428693287,-0.05777183502895567,-0.057634842029947626,-0.05380674897279886,-0.056889901117095736,-0.056565650427239135,-0.05627172545952711,-0.062114889285062085,-0.05775194373291236,-0.05689549306570759,-0.055623419971675685,-0.05804718336954775,-0.05721842723503825,-0.0574646501076065,-0.05746621947538775,-0.06191124945734272,-0.05655144395203658,-0.06456573917568856,-0.057118126224402904,-0.05665647495550919,-0.05958069493475634,-0.06318530047448777,-0.053895042982179994,-0.05437280915660907,-0.05583443710117893,-0.05444324002770077,-0.05961048931978101,-0.05873223166297604,-0.05256214092647313,-0.056267381375686695,-0.05570579923830441,-0.052789321366641474,-0.05294286782198763,-0.05852944745401758,-0.04627857594910055,-0.05302899885272818,-0.054224260984195555,-0.05476763034459237,-0.05636795193972913,-0.05470334950560306,-0.054147109501034484,-0.06261770705492013,-0.05729499713498378,-0.05530873808903275,-0.055329945495680266,-0.05678194601995542,-0.05792023085776004,-0.05360943718058268,-0.055118052156417206,-0.05969399370621247,-0.0639714322806929,-0.056692053550622755,-0.05356892308847352,-0.060744460385044004,-0.056784092391447286,-0.05644645974018939,-0.06573486133269411,-0.06421082592747723,-0.0585260032212118,-0.05407882890428233,-0.05685631399542245,-0.053663643234748065,-0.0580569699932996,-0.06483610386125384,-0.061230242337682296,-0.05388885086314279,-0.053496574973322546,-0.05931932475523203,-0.054290538498785644,-0.06306079186864409,-0.05382565250064059,-0.054187351660390425,-0.037327644945581114,-0.053311834810689386,-0.03494579817108863,-0.05663890878629083,-0.058635896773611244,-0.02704121454204058,-0.05500730803686726,-0.054068240460520264,-0.05817811327913573,-0.05573317542217809,-0.057615861766556656,-0.05332213848566586,-0.05937040481986452,-0.05751224241409038,-0.04429128814031956,-0.05572832308611179,-0.044522136825295745,-0.056207922635103526,-0.06252626716130139,-0.05454113389443535,-0.05442566813430581,-0.05781282732545459,-0.05540211176103905,-0.05358707584342538,-0.05621807377337399,-0.057668666294209886,-0.05485262350295494,-0.05404556558641711,-0.05495333524535295,-0.057663661789630755,-0.02841164063642665,-0.05890939765502431,-0.0540735004191624,-0.05482367182865657,-0.05574465107403928,-0.06030333546360417,-0.05381519769954708,-0.054664199505396596,-0.05532772341548902,-0.05935488796150719,-0.052010945525175344,-0.05948989694830514,-0.05289789713602148,-0.05776415886231494,-0.054271968278226994,-0.054787588170688246,-0.054210526714288595,-0.053681763083048346,-0.05316119883077262,-0.06092371524990112,-0.04056092053425491,-0.05638723962151356,-0.040037995774244495,-0.05138680301079196,-0.05841219179230296,-0.055845438742779745,-0.05565003150832235,-0.06169038314397572,-0.0570988603183812,-0.052868227485026884,-0.05622586335660472,-0.05671542816031392,-0.05792403721101057,-0.053982705382347666,-0.061395696242211306,-0.05523556760541943,-0.06307632248433495,-0.056485353464852964,-0.05360791221935326,-0.04005490933332874,-0.057792210425388825,-0.05908299782215184,-0.056510926372728934,-0.058134779833681184,-0.05029738990494363,-0.05845699468036499,-0.045843720395262993,-0.04537285880348818,-0.05676276761954249,-0.0576558310571305,-0.022306830804766753,-0.0587478119880187,-0.05432962870605649,-0.022666158463351817,-0.05115186941397124,-0.049297636539247874,-0.05422453480537067,-0.05086113717203287,-0.04621835533010307,-0.06337031284970096,-0.060480684324930624,-0.038671554727894714,-0.05903243366325408,-0.02771284761067771,-0.05858263044661982,-0.05390908832295674,-0.044777970855475156,-0.05713580599676247,-0.03711127226466835,-0.05056343439135992,-0.037542511955314134,-0.058623313968137976,-0.05906556201622813,-0.060820506159546664,-0.05659653396368413,-0.05854865379456523,-0.059070819788621005,-0.06077088298786175,-0.05061392081117748,-0.062364840018641066,-0.056608685981503246,-0.056952324627692466,-0.04786533984014133,-0.060721749468919804,-0.061622891285739285,-0.04818442210908898,-0.055279110140415644,-0.04682856016339483,-0.055761648556621794,-0.0619210360254565,-0.05976746316923162,-0.0467502687950664,-0.06020851125775557,-0.05944095217091346,-0.058707041914921196,-0.03608399001311508,-0.055793049190111,-0.05417884934353431,-0.045609659390090464,-0.038903435461620416,-0.02617319391724695,-0.059230435944500275,-0.05615683424766881,-0.04694894916214176,-0.05215767873759431,-0.057049580230735544,-0.04586709256833353,-0.06829626593448151,-0.06205689282450178,-0.06819453672542022,-0.06685527681138101,-0.058323627747590784,-0.04509123551512167,-0.06378068282411754,-0.044915451235883364,-0.048523218492977235,-0.026030085371927737,-0.05352655475588522,-0.0495970194766201,-0.0591599351936163,-0.03948223033222606,-0.06425347963759717,0.02264218226528247,-0.046495934551521546,-0.060217049163346026,-0.040334344671375144,-0.06029122742605101,-0.053647532344972965,-0.061773148415331526,-0.06373013569374514,-0.07536445704360664,-0.04979610000585931,-0.05742260609593314;-0.05173173529298456;0.014628772128281951;0.0
data/model/LunarLander-v3_42158_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 42158};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 42158};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angvel, leg1_contact, leg2_contact = observations
    distance_to_target = np.sqrt((x**2 + (y - 1.5)**2))
    
    if is_success:
        return 1000.0
    elif is_failure:
        return -1000.0
    
    reward = -distance_to_target
    reward -= 0.01 * abs(vx) + 0.01 * abs(vy)
    reward -= 0.05 * abs(angle)
    
    if leg1_contact or leg2_contact:
        reward -= 0.1
    
    return reward";-0.07043013472277013,-0.0704180959623391,-0.07109899554920934,-0.0703539011944612,-0.070165190870941,-0.07139624910053077,-0.07032450770855705,-0.07087871974987368,-0.07110237428554698,-0.07103828542214866,-0.07120872953779839,-0.07088077087487532,-0.07102591106597976,-0.07118486634609517,-0.0711583578156906,-0.07084511079830333,-0.07083377567140961,-0.07225286896276109,-0.07142350483257466,-0.07186114248693934,-0.07198862313512183,-0.0708999345297545,-0.07180462503857259,-0.07143951088311132,-0.0707323582525805,-0.07118034015964278,-0.07133008056981781,-0.07075638740484094,-0.07274784234657888,-0.07294165277543183,-0.0714690511245694,-0.07205920461083123,-0.07319455458110458,-0.07219985448776098,-0.07279539044889712,-0.07185638264512287,-0.09369929191211579,-0.0721234912012225,-0.06988848768832336,-0.07405372229232907,-0.07089155071343468,-0.07013743192834535,-0.07132567580370068,-0.07166895828353398,-0.07160195149068817,-0.07190054888865019,-0.07094519879427771,-0.07262965323434326,-0.07289356592884834,-0.0708540594353423,-0.0721825037168778,-0.070262992759338,-0.0710159947418838,-0.07121432535618905,-0.07238690507799601,-0.0724166738319982,-0.07143287391825066,-0.0769572556552522,-0.07244389201246601,-0.07384897946819573,-0.07083570435036673,-0.07172421428757565,-0.07094671462175775,-0.07516318956887545,-0.07257859198570615,-0.08214044837797851,-0.07221342719236175,-0.07206218607628033,-0.07252498104074648,-0.07107851311571302,-0.072540998637023,-0.07203524780112266,-0.07362270778655156,-0.07098337383829995,-0.07117277701313991,-0.0712526426173117,-0.07279876720343227,-0.07105764895610701,-0.07063234783287947,-0.07118203089058253,-0.0705172357817689,-0.07133161107650933,-0.07284122210943095,-0.07504124889950109,-0.07071023467026824,-0.07080359146384423,-0.07141202186181342,-0.07395016662531595,-0.07160393193290376,-0.07171061535652104,-0.07124660986420218,-0.07067610806607981,-0.07126215293122154,-0.07138841439074393,-0.07171044910297557,-0.071855454114316,-0.07149064340702178,-0.07041724927241215,-0.07113034015246202,-0.0706829482265463,-0.07330410535763843,-0.07042246527637877,-0.07256453124233593,-0.07267855974832327,-0.0716597537120049,-0.07201344858784006,-0.07175765336030934,-0.07405595119908681,-0.07311364443791883,-0.07135095478067326,-0.07187483730603211,-0.07412609450412713,-0.07030264677592511,-0.07162957184483958,-0.07139597538040263,-0.07130064046998606,-0.07255837561507789,-0.07018732173138155,-0.07263825442840208,-0.07575170475754138,-0.07185840476529073,-0.07104333484502398,-0.07201391784956938,-0.07087075083494696,-0.07287218163899553,-0.07052054709224785,-0.07411350529793143,-0.06953469955157791,-0.07276837627989469,-0.07032849773805568,-0.07231912954211422,-0.0699531147625981,-0.06965437752135077,-0.07130995727529188,-0.07156153302221586,-0.07392840471644754,-0.07265471167932057,-0.07378813684283943,-0.07989648276210072,-0.07017453367532177,-0.06935521607420529,-0.06925021221291636,-0.07149723496521661,-0.07112675010449397,-0.0706933586470061,-0.07145430114177329,-0.07206334648386244,-0.07128855834629436,-0.06936773469127104,-0.07383567655667907,-0.07413508095117283,-0.071495068479947,-0.07117495355789144,-0.07162478802907284,-0.07101962651162717,-0.07373956965631585,-0.0704966972112256,-0.07029825856702399,-0.07114062582403986,-0.07173911718806936,-0.07235420330039342,-0.07169866359631749,-0.07166866882017126,-0.07181329783895642,-0.06983922498578954,-0.08268014419641233,-0.07345072844434511,-0.08205680119603213,-0.07593517263265284,-0.07022159486574836,-0.0801314176303583,-0.07103932045593245,-0.07120019465749503,-0.08239030899505433,-0.07049185573787807,-0.09028983891137524,-0.06988959051457674,-0.09093227051456762,-0.07161056305502805,-0.0780630771497989,-0.07977030851015131,-0.07909394273068303,-0.07254927815253559,-0.07192197071580528,-0.08003300244145528,-0.08133927574332041,-0.07406944882157049,-0.0736223590318856,-0.08911986729735288;-0.07264712003671389;0.0036607705987366295;0.0
data/model/LunarLander-v3_337675_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 337675};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 337675};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3""""""
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    
    x, y, vx, vy, angle, angvel, leg_contact_left, leg_contact_right = observations
    reward = 0.0
    
    # Penalize high velocities
    reward -= abs(vx) * 0.2
    reward -= abs(vy) * 0.5
    
    # Penalize tilting
    reward -= abs(angle) * 0.1
    
    # Reward for being close to the ground and having legs in contact
    if y < -0.5:
        reward += (1 - abs(y)) * 2
        if leg_contact_left or leg_contact_right:
            reward += 1.0
    
    return reward";-0.10254220283100515,-0.11439176950372379,-0.10053374033740149,-0.11342712432168621,-0.10318286593197715,-0.11480529255354611,-0.11166455171941095,-0.10724492459358999,-0.09877057837492183,-0.113797560675257,-0.10254999052204464,-0.11268345549333941,-0.10119572159900468,-0.10232082382681744,-0.12401018608961133,-0.11230199814894648,-0.10652500866654399,-0.09955163812437436,-0.10398441298589584,-0.09924225727375793,-0.10931239837977058,-0.10325046367802028,-0.1124067812280372,-0.10770915745236503,-0.092740006989558,-0.10182497490296212,-0.10900745973193557,-0.105285329017033,-0.10358483562636782,-0.12069246453748927,-0.12728854548629853,-0.11296472287843905,-0.11738519866663503,-0.1281014695061426,-0.11234046441224402,-0.12473177351515136,-0.1232077654036898,-0.12118311261940877,-0.12663175338287308,-0.12459975003326844,-0.09411102113976692,-0.09096364381175373,-0.11435418362650873,-0.12476137009550563,-0.09616956436005222,-0.1227850149568115,-0.1517273515383059,-0.14047089813909627,-0.16376314957837254,-0.16439374208769544,-0.09148552405106479,-0.13738484580154453,-0.12237108617764578,-0.1208593375272324,-0.1141751998989791,-0.09807720759031019,-0.09330043579082371,-0.11101405958442233,-0.09357436727019207,-0.08982714884926259,-0.09530273688661536,-0.09821355997860913,-0.0930939215002317,-0.11712094919840152,-0.1009769355800962,-0.11438767877146212,-0.11733687697683631,-0.14986229754102048,-0.10153561432535146,-0.11543844452460665,-0.13599402743738012,-0.128310096930272,-0.11840633525332908,-0.10457515582074521,-0.10862476291430256,-0.11731813066381065,-0.11175999925891206;-0.11289352216179058;0.015558458822077662;0.01
data/model/LunarLander-v3_468194_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 468194};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 468194};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    else:
        reward = -np.abs(vx) * 0.5 - np.abs(vy) * 2.0 - np.abs(angle) * 0.5 - np.abs(angular_velocity) * 0.1
        if leg0_contact or leg1_contact:
            reward += 5.0
        return reward";-0.15479368798560045,-0.12930984900495873,-0.13483892061840888,-0.11681028741652821,-0.11906894555353968,-0.1390798421215829,-0.12430630340681369,-0.11434009321804131,-0.13298194089556908,-0.16325744073464957,-0.17249257189688674,-0.14409422588546855,-0.12261107528090853,-0.17887046157542927,-0.1242205661823447,-0.14946099239776234,-0.1466424620782431,-0.10058069340893626,-0.11384802311070263,-0.12833811077079574,-0.17298133389571285,-0.1015270665248429,-0.10519794678685414,-0.15786061759720404,-0.21296612680366195,-0.10719133175492311,-0.13578569181387523,-0.10545368403405653,-0.12182302815864066,-0.10126868862179145,-0.10369190639596657,-0.09863700129735344,-0.10488804022554686,-0.10561713652672541,-0.10296363970973574,-0.10524087196468149,-0.09396440382056985,-0.11165133765816497,-0.09568492312818035,-0.12108803729035725,-0.10338368301432956,-0.10006243915716909,-0.1080646396446821,-0.10983276440306249,-0.09898004376488825,-0.10729333125384352,-0.1121439093258484,-0.11111998799808166,-0.09306651888349333,-0.10578766679316923,-0.12241547875168311,-0.14065694218745076,-0.127235500887779,-0.24330156931785923,-0.10788823510885438,-0.16128917260443001,-0.1172855961287508,-0.19705889152803377,-0.1291263607019868;-0.12663427184758322;0.030214462364987805;0.0
data/model/LunarLander-v3_55253_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 55253};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 55253};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, theta, omega, leg1_contact, leg2_contact = observations
    
    if is_success:
        return 100.0
    elif is_failure:
        return -100.0
    
    # Penalize high velocity and angular velocity to encourage stationary flight
    velocity_penalty = np.sqrt(vx**2 + vy**2)
    angle_penalty = abs(theta) * (1 - int(leg1_contact or leg2_contact))
    
    # Reward for being close to the ground but not too close
    height_reward = 1.0 / (1.0 + y)
    
    return -velocity_penalty - 5 * angle_penalty + height_reward";-0.3424407536689587,-0.1449450286385017,-0.2849273732065497,-0.11163731556649724,-0.10070797241135157,-0.13730843494063708,-0.15529298127119934,-0.07651577507765524,-0.14742346164935,-0.26320386485761765,-0.1047937940964107,-0.16446018585522332,-0.14140791809821937,-0.18976328972975365,-0.08120480458559574,-0.08949157937603784,-0.09208393840139127,-0.16005537867349878,-0.10321108296010573,-0.10168237081402862,-0.05699517238084204,-0.13034334075690734,-0.09154737407010766,-0.12052894492548603,-0.08902014347968165,-0.06701880152784277,-0.016413685589639206,-0.0687947861618131,0.03647122267564385,-0.07288248161879235,0.06492988172517715,-0.09902125198343399,-0.062094642523188796,-0.059977266996871656,-0.09958386634090446,-0.08842380463837564,-0.020888288754214807,-0.07849196226167315,0.08694183358346706,-0.016391444060171824,-0.09841872072330385,-0.026714219374613768,-0.0014958330418552992,0.09645987048274311,-0.08974040459567867,-0.10030827070938467,-0.0605494573282788,-0.061855983111203716,-0.04007411455877181,-0.06131319480617704,-0.02559926506441323,0.08494435805015901,-0.0495008593250121,0.0031680814972282383,-0.0752113521836182,0.06124855254189136,-0.10763723420315313,-0.07978592157241463,-0.06354857941512712,-0.08955844293283459,-0.10431827039526759,-0.057187105533525476,-0.023948641646192054,-0.05300673448229526,-0.08117174937783948,0.0660841906196608,0.2790807460545054,-0.03707896010673248,-0.08200136425221824,-0.07222388926175345,-0.052428742241271135,-0.0680937491523784,-0.11889264596872973,-0.060516215031335,-0.056153434550132796,-0.07030292132325872,-0.05818341368881937,-0.05709119893684433,-0.08212090273125607,-0.05588248660575175,-0.03163778689252406,-0.06949878701606069,-0.07240330336941099,-0.08569128060539276,-0.04983199824272672,0.08904868271107673,-0.07818488704951543,-0.09375784528994577,-0.08069919933922488,-0.11565650944627612;-0.0695763668609944;0.07918484883824324;0.01
data/model/LunarLander-v3_964795_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 964795};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 964795};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg_contact_left, leg_contact_right = observations
    
    # Base reward for staying in the air and moving slowly
    base_reward = -0.1 * (abs(vx) + abs(vy))
    
    # Penalty for tilting too much
    tilt_penalty = -5 * abs(angle)
    
    # Reward for having both legs touching the ground (stable landing attempt)
    leg_contact_reward = 2 if leg_contact_left and leg_contact_right else 0
    
    # Success reward
    success_reward = 100 if is_success else 0
    
    # Failure penalty
    failure_penalty = -150 if is_failure else 0
    
    return base_reward + tilt_penalty + leg_contact_reward + success_reward + failure_penalty";-0.21575330772858828,-0.13665084205082828,-0.11478037862055782,-0.07648148292611831,-0.1878466347752165,-0.10792913725687767,-0.06683022017037352,-0.170597953743781,-0.07201182020735523,-0.15928936453741094,-0.2845193467104516,-0.07728753316924573,-0.12833314908620283,-0.13778133008409005,-0.07072514805042832,-0.06972609603051357,-0.10918981906400096,-0.06976787846958196,-0.07653486528771881,-0.06896691594547122,-0.07541819485474821,-0.07881756118946723,-0.13125399365038626,-0.06567002635446807,-0.11843057510499239,-0.07136728425920574,-0.07661081467529073,-0.17352336099816,-0.07981087251583328,-0.12173199530485913,-0.07416883814121117,-0.07409064779848423,-0.07565664649155845,-0.14667464754562679,-0.278011662963793,-0.06574548728930203,-0.16069112643689526,-0.0739507426543091,-0.0749348832962605,-0.07711399765671835,-0.0698997668837909,-0.07037159714363218,-0.07778392774054378,-0.07079470868454191,-0.07056121331495102,-0.069567044002854,-0.0704694162013978,-0.07221708097800272,-0.06875580429831556,-0.07521751897295192,-0.08199485799956453,-0.09255232462095969,-0.06785704794192171,-0.07052252630743291,-0.07470069317171017,-0.08358579879605849,-0.07182399292824812,-0.09360185359564827,-0.08545882606696474,-0.07408257616107038,-0.10462218734329368,-0.07136089410208536,-0.07324806367302773,-0.07257477729167791,-0.06921921978168731,-0.08422235533078556,-0.10116026629607182,-0.07079735702661821,-0.07383213203990427,-0.06995055270017829,-0.09345861154961256,-0.0687568981048697,-0.06944174527084077,-0.06841456012866315,-0.10974996753894292,-0.06765213002295463,-0.07189749966655637,-0.06949953189799989,-0.07536619722482113,-0.07176649863970826,-0.07707271894748771,-0.07824721138654438,-0.10525504479632748,-0.09829081854995443,-0.0792239537771998,-0.06546726333259678,-0.07248884299875728,-0.07031682189364839,-0.0755266949894809,-0.07192038031280125,-0.07137555112550699,-0.07290045226407078,-0.06712780876013981,-0.07073225891798157,-0.06636253832402077,-0.07051639786397142,-0.0692910294044663,-0.07034115297408904,-0.07278688728048206,-0.08388365402331216,-0.08322306425229241,-0.0654147315237806,-0.07488083081887976;-0.09025371566072851;0.03953485390778675;0.05
data/model/LunarLander-v3_228071_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 228071};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 228071};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x_pos = observations[0]
    y_pos = observations[1]
    x_vel = observations[2]
    y_vel = observations[3]
    angle = observations[4]
    ang_vel = observations[5]
    left_leg_contact = observations[6]
    right_leg_contact = observations[7]

    reward = 0.0

    if is_success:
        reward += 100.0
    elif is_failure:
        reward -= 20.0

    # Penalize for being far from the origin
    reward -= np.sqrt(x_pos**2 + y_pos**2) / 5.0

    # Reward for landing on the ground with both legs in contact
    if left_leg_contact and right_leg_contact:
        reward += 10.0

    # Penalize for high velocity at landing
    reward -= (np.abs(x_vel) + np.abs(y_vel)) * 2.0

    # Penalize for being tilted
    reward -= np.abs(angle) / 2.0

    return reward";-0.08834281779762665,-0.060016679728017434,-0.0518289413355822,-0.1252322251238513,-0.06485485074323465,-0.12770447276373056,-0.09651367302565145,-0.10286570677804836,-0.06659556074396852,-0.04880677413157972,-0.09291157460307807,-0.06764096639302608,-0.05140277524422936,-0.12250281943191661,-0.0684965683128731,-0.08428596071235663,-0.12296370710701614,-0.11560225790809209,-0.08943793703571098,-0.09894641910921859,-0.18065678620614953,-0.14503801170664807,-0.1358433828603705,-0.2537867478181257,-0.19611053546927812,-0.28179650842916,-0.20400560216055744,-0.16765067278573867,-0.163765692042343,-0.18004045835645688,-0.16602085354785504,-0.1561140784791141,-0.16616801788574154,-0.16443212976751928,-0.152901618738525,-0.17020063930292795,-0.184747866845608,-0.16842909396866151,-0.13206842146745054,-0.1444014116335089,-0.12748536796846657,-0.1429673936520334,-0.11580836941458765,-0.13888640513879458,-0.15578545512278963,-0.08617849130581641,-0.1184931929254433,-0.13787433366755583,-0.055677438392269414,-0.1547710761754747,-0.1725975810777787;-0.13073835926159919;0.05015301142344222;0.0
data/model/LunarLander-v3_795773_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 795773};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 795773};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]

    stationary_reward = -abs(x_velocity) - abs(y_velocity) - abs(angle) - abs(angular_velocity)
    success_bonus = 100 if is_success else 0
    failure_penalty = -100 if is_failure else 0

    return stationary_reward + success_bonus + failure_penalty";-0.09021723090669262,-0.11637977316316442,-0.14546438091700953,-0.11108015427911479,-0.09952215651410241,-0.08181561222078526,-0.11974821181762427,-0.1584954833542369,-0.09396363784309372,-0.08787469480032267,-0.08251591545809844,-0.10232198949179203,-0.12559279166724618,-0.08371105221691472,-0.11361244865202395,-0.13123729757909505,-0.09778563488688803,-0.12193851420320019,-0.10932921253296518,-0.15106125126545425,-0.11043884366488763,-0.11850364095958398,-0.1462383303643864,-0.13388441322267977,-0.24988241476640338,-0.12765500160730167,-0.11136875116859664,-0.11972105109843892,-0.11884450827731,-0.1297190735642308,-0.11013256661962753,-0.14935263088333675,-0.10888184898680754,-0.10966308086769548,-0.1141077573563755,-0.1489956917993615,-0.10663106608354253,-0.14424149871919445,-0.13156529314875526,-0.1543168853634568,-0.21104165730423827,-0.11632062772892668,-0.10792154379767015,-0.13141134648101663,-0.1371219544187325,-0.15528720964540976,-0.1264628735542187,-0.13120102890571836,-0.10822297808600406,-0.09978125642449297,-0.14698840387463227,-0.11791503177032947,-0.15294646017954286,-0.12105780982700812,-0.1251206612111961,-0.10743361284354001,-0.1490179786008931,-0.116527223306746,-0.11679183280477567,-0.1306178091109679,-0.14827603862690125;-0.1250045431277829;0.027700303615034262;0.0
data/model/LunarLander-v3_631760_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 631760};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 631760};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    hover_bonus = 1.0 if abs(vx) < 0.5 and abs(vy) < 0.5 and abs(angle) < np.pi / 6 else 0.0
    no_crash_penalty = -1.0 if is_failure else 0.0
    leg_contact_penalty = -0.5 * (leg0_contact + leg1_contact)
    return hover_bonus + no_crash_penalty + leg_contact_penalty";0.004757136215542839,-0.00040486265664194376,0.006376586842110614,0.00020243132832097188,-0.00020243132832097188,-0.0007085096491234016,-0.00020243132832097188,0.0006072939849629157,-0.0009109409774443734,0.005769292857147698,0.0012145879699258313,0.002935254260654092,-0.00020243132832097188,0.005060783208024297,0.015992074937356777,0.03137685588975064,0.008400900125320333,0.015890859273196292,0.008502115789480819,0.00273282293233312,0.016295721929838237,0.0402838343358734,0.019230976190492327,0.007388743483715474,0.053947948997539005,0.05668077192987212,0.15192471190488938,0.17156055075202367,0.2022288969926509,0.2022288969926509,0.2022288969926509,0.2022288969926509,0.1965608197996637,0.19595352581470077,0.19696568245630564,0.19696568245630564,0.2022288969926509,0.2022288969926509,0.1892732919801087,0.1949413691730959,0.18320035213047955,0.19554866315805883,0.2008118776944041,0.19392921253149106,0.19939485839615728,0.20040701503776215,0.2022288969926509,0.20182403433600896,0.20182403433600896,0.2022288969926509,0.20202646566432994,0.17237027606530755;0.10316017278541528;0.09267549828111256;0.0
data/model/LunarLander-v3_570404_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 570404};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 570404};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_v, leg0_contact, leg1_contact = observations
    if is_success:
        return 10.0
    elif is_failure:
        return -10.0
    else:
        reward = 1.0
        reward -= abs(vx) + abs(vy)  # Penalize linear movement
        reward -= abs(angular_v)     # Penalize rotation
        if leg0_contact or leg1_contact:  # Penalize contact with the ground
            reward -= 2.0
        return reward";-0.012360683429257769,-0.00730267438069638,-0.021853282180327352,-0.031099796027851942,-0.006381697707453041,-0.018464728309126013,-0.022818890321478203,-0.009844211347646714,-0.011793192801947542,-0.008244386924645637,-0.005698859091183195,-0.013199591178855734,-0.002322113994403138,-0.007239303302020743,-0.007445117741007272,0.0037258789935606215,-0.010796289467280186,-0.019284591861662773,-0.008548517750892859,-0.004270995194931011,0.007254045631758272,0.16509209718838772,0.19013753979314177,0.1268271380408858,0.13120070093059452,-0.011265348616795075,0.1586896264810997,0.10478973025520896,0.1764407767126439,0.15836211844221168,0.17285862898379162,0.22360853564561062,0.17192595030086463,0.18368244406192286,0.2309220968349782,0.20206462033991462,0.18102797729657388,0.17981830274133606,0.2049757685881346,0.20413789289823125,0.21119570455423106,0.18842387585055045,0.22780402297028396,0.20210731673345195,0.2239564914455003,0.22425522761649552,0.21995385758007666,0.21768123832458108,0.22755703838320404;0.09959678310183191;0.10241408136126971;0.0
data/model/LunarLander-v3_359613_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 359613};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 359613};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x, y, vx, vy, angle, angular_v, leg1_contact, leg2_contact = observations
    distance_from_ground = abs(y)
    reward = 0.0

    if is_success:
        return -100.0  # Penalize for unintended landing

    if is_failure:
        return -100.0  # Penalize for crashing

    if leg1_contact or leg2_contact:
        reward -= 50.0  # Penalize for touching the ground without landing

    reward += distance_from_ground * 0.1  # Reward for maintaining altitude
    reward -= abs(vx) + abs(vy)  # Penalize for high linear velocity
    reward -= abs(angle) * 2.0  # Penalize for tilting
    reward -= abs(angular_v)  # Penalize for angular movement

    return reward";-0.09609578101938103,-0.13693840104784374,-0.1450479253911794,-0.20974558577443503,-0.3729814289432958,-0.22953686750579755,-0.17319266861170293,-0.1284429638780812,-0.1469444901732985,-0.10643748917268743,-0.28497395153204513,-0.12646491265492127,-0.3755887473779524,-0.12236498514185742,-0.13839546534375863,-0.14160455699716812,-0.18039153300899693,-0.15299574895585652,-0.13923632934605076,-0.18299542455235326,-0.09859555717792326,-0.07944444737700582,-0.06016672290740618,-0.04520809189487127,-0.025875709494980005,-0.06845537022646013,-0.05816747620072825,-0.08403438032429206,-0.07585747355960777,-0.053797862577003676,-0.044302832115222054,-0.09412640108016462,-0.03128440598343229,-0.277416023917732,-0.04706408531837062,-0.060970333649752254,-0.05241457629394307,-0.045227473359331985,-0.06450656881553954,-0.06398261483997669,-0.04342213200027171,-0.08059236586320172,-0.04631300789634791,-0.04707916011454148,-0.0826739300822301,-0.05249732648614387,-0.09606875804956838,-0.05847002779633812,-0.18299823166352175,-0.045114316560431515,-0.10050461643826478;-0.11484328502927976;0.08011780714010155;0.0
data/model/LunarLander-v3_178757_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 178757};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 178757};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_pos, y_pos, x_vel, y_vel, angle, ang_vel, leg0_contact, leg1_contact = observations
    
    # Penalize large velocities and angular velocity to encourage stationary flight
    vel_penalty = np.abs(x_vel) + np.abs(y_vel)
    angvel_penalty = np.abs(ang_vel)
    
    # Reward for maintaining a stable angle close to vertical (0 radians)
    angle_reward = 1 - abs(angle)
    
    # Penalize if any leg touches the ground
    contact_penalty = -(leg0_contact or leg1_contact) * 1.5
    
    # Base reward
    base_reward = -vel_penalty - angvel_penalty + angle_reward + contact_penalty
    
    return base_reward";-0.020993453356660637,-0.014452859314208552,-0.02050451024343569,-0.032172903524191276,-0.0004277563522100059,-0.02042212664897524,-0.04333976357520474,-0.01860828628492409,-0.017548921726227136,-0.00599517169776154,-0.03269887639292112,-0.016277118156050065,-0.023682177400629004,-0.01913414518555948,-0.004099791935646863,-0.005751949903153818,0.005741744575588195,0.0018997765593453022,-0.006762779714565577,0.05628982224028135,0.17334386463502913,0.20148566757351996,0.006622224050475382,0.07788331024595466,0.16790619322541903,0.09242613679229456,0.01657335850529123,0.18565091478325518,0.20411856872330758,0.001412475159052819,0.17694475286837166,0.12248614122668107,0.1458060117618011,0.19788746182690048,0.20951491991217525,0.1993988808257995,0.21573928031972334,0.012605368719943059,0.2105707818572803,0.22068602931084677,0.014588853344993326,0.22393923431869522,0.19170379348883862,0.21250108694823674,0.2035748681139637,0.20298255480323082,0.22169965838408584,0.21265767976824113,-0.010817307337838781,0.21369495003504904,0.18495526204505375,0.20370630637528866,0.196325571031982;0.09191761520011006;0.10207387787395159;0.0
data/model/LunarLander-v3_210114_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 210114};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 210114};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, leg_contact_left, leg_contact_right = observations
    
    position_reward = -0.1 * (abs(x) + abs(y))
    velocity_penalty = -0.5 * (vx**2 + vy**2)
    angle_penalty = -0.1 * abs(angle)
    angular_velocity_penalty = -0.05 * abs(angular_velocity)
    contact_penalty = -1.0 if leg_contact_left or leg_contact_right else 0.0
    failure_penalty = -10.0 if is_failure else 0.0
    
    return position_reward + velocity_penalty + angle_penalty + angular_velocity_penalty + contact_penalty + failure_penalty";-0.07249515757907021,-0.0805923636551781,-0.07228320706314122,-0.06947008523304578,-0.052072271080128824,-0.08892773188917212,-0.08242629294653578,-0.10728955677607296,-0.09165451172705195,-0.10444740127132904,-0.05216822356879653,-0.046167470832865855,-0.11461824805444266,-0.19804953764129757,-0.10504598011602924,-0.1335014136568931,-0.15311963296889775,-0.08029998925125074,-0.13673545901825576,-0.07956271528057042,-0.11720895796091305,-0.14850548074201952,-0.1299979637701271,-0.10291905340861421,-0.08736921666258587,-0.10542195144320086,-0.13799673818077027,-0.24180787587586744,-0.19694078796674458,-0.11861149221885492,-0.22029072016856285,-0.12288969863735286,-0.1908658488849823,-0.18412241195175832,-0.18884347528788592,-0.19415447408450315,-0.22652501832046282,-0.19890878811761398,-0.15074958308011988,-0.18134083365639284,-0.0700817498394255,-0.14269322432454942,-0.0981230414325581,-0.08519422027975443,-0.0600055428588216,-0.11905954771286749,-0.15065477013516132,-0.07981531585862253,-0.07902564152206414,-0.12345115819538854,-0.08929828344332633,-0.07888299430869103,-0.10228401636760949,-0.20842270755808348,-0.09914349781575336,-0.08679075785398305,-0.16376119123373334;-0.12286114527666232;0.049487358289058876;0.0
data/model/LunarLander-v3_442119_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 442119};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 442119};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, vx, vy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    
    # Penalize contact with the ground to avoid landing or crashing
    contact_penalty = -5.0 if (leg0_contact or leg1_contact) else 0.0
    
    # Reward for being near the center of the screen and having low velocities
    position_reward = -np.abs(x) * 0.25 - np.abs(y - 5) * 0.25
    velocity_penalty = -np.abs(vx) * 0.1 - np.abs(vy) * 0.1
    
    # Penalize for angular movement to maintain stability
    angle_reward = -np.abs(angle) * 0.1 - np.abs(angular_velocity) * 0.1
    
    reward = position_reward + velocity_penalty + angle_reward + contact_penalty
    
    return reward";-0.03432982487522034,-0.03417213661425974,-0.041487870039411186,-0.03414032083674191,-0.07225187425491153,-0.061220649652649055,-0.050533282922063494,-0.043864385552865516,-0.05279257271013394,-0.0646063713679716,-0.03356145606352897,-0.040675327213081966,-0.06531992999547465,-0.036388052504844594,-0.08016347586283964,-0.03982746252569919,-0.047001978751693305,-0.057808936798240326,-0.07598964981476193,-0.09258504517736986,-0.07224762306746317,-0.08220882743737565,-0.08474798478598793,-0.054815000952722424,-0.04312568234345256,-0.05288739326191433,-0.09060927922420134,-0.07788164053869273,-0.0640712277819337,-0.05566577551286993,-0.07776315806073948,-0.06812046515901458,-0.12690664670076035,-0.11494382470757965,-0.08082223015636353,-0.08949313411328194,-0.1056092344542567,-0.16814742788030246,-0.07448765592412641,-0.09009891523084199,-0.09783346600226153,-0.06988714627471815,-0.12796987096849607,-0.0984502032851766,-0.15591968439840528,-0.14089697934296944,-0.12099947445426566,-0.1453315943558306,-0.08806025489153946,-0.1669934809940281,-0.11427868179418721,-0.09430113710925417,-0.09423873652332058,-0.13765175820809186,-0.12055865379057992,-0.06090967157325924,-0.07853085190720774,-0.08491728296785926,-0.09801560403174475,-0.09117404778015581,-0.08349178302976842,-0.16328571079533089,-0.07613168897894355,-0.11250040118158199,-0.09979104057048326,-0.09967139190119849,-0.05165269844882001,-0.0899079210058118,-0.08550212195339706,-0.09764711682203413,-0.11858975177081942,-0.10480136558340027,-0.04298365619864551,-0.1261377063342704,-0.06543697993802826,-0.03386282127068179,-0.10476113868361193,-0.11000555359373364,-0.03005782263793271,-0.16185413302175577,-0.10126133392208472,-0.1383914004079859,-0.06485462207938067,-0.12021733314398073,-0.09234187563853836,-0.14342695241630485,-0.11362184315697246,-0.02993095708680271,-0.09719264632268587,-0.03251714069293891,-0.11357949427995288,-0.030173542498204278,-0.03403613584451587,-0.03147517025636971,-0.031204011508650886,-0.03579136999422578,-0.03196007060804808,-0.11692555908668431,-0.09037499085599159,-0.03425772000487239,-0.03170593011878751,-0.03467614053677126,-0.033851357541179704,-0.032081637529007494,-0.039457284924642455,-0.03266691187647453,-0.043325402421369535,-0.03951434392923345,-0.03467085730860589,-0.03897960804959058,-0.1108096922861331,-0.048270746353000944,-0.03958448227836276,-0.028192445791898488,-0.0905462974040322,-0.102843169861243,-0.042968616566020496,-0.03353623208896232,-0.0414286678372848,-0.09613839469093297,-0.03200521448099788,-0.10291569548927078,-0.11792138171186418,-0.05679532877135615,-0.031240405659860505,-0.052345460795333636,-0.047387608882501105,-0.05156519365805649,-0.032492340188421794,-0.04338720798784742,-0.07182243965122366,-0.03558333100397146,-0.032319573470720814,-0.03286774051584439,-0.035493795850252204,-0.03847804879121105,-0.04208523700322871,-0.03199168020292147,-0.03922088624770956,-0.028247152033825086,-0.029949254179710734,-0.03141857229080782,-0.0303851851534832,-0.04884484660950324,-0.17705137589785166,-0.03577576291258534,-0.03132883227340038,-0.031617318213168294,-0.04574673255800192,-0.038698794733598545,-0.037727997856625346,-0.027996640142116898,-0.03431499982826746,-0.03786175035907724,-0.0357264979395655,-0.0319228901887268,-0.03730569823185444,-0.03571522282080686,-0.032708218522776424,-0.03397858250788726,-0.03447413519696689,-0.02953107835674283,-0.035707858258408824,-0.03117681029102772,-0.03150774239147524,-0.03774487137027214,-0.036467344218872925,-0.030497824867993142,-0.03264770227857784;-0.0672138684452458;0.03740929900357395;0.0
data/model/LunarLander-v3_458415_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 458415};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 458415};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    x_velocity = observations[2]
    y_velocity = observations[3]
    angle = observations[4]
    angular_velocity = observations[5]
    leg0_contact = observations[6]
    leg1_contact = observations[7]

    if is_failure:
        return -1.0
    elif is_success:
        return 0.0

    reward = 1.0
    reward -= np.abs(x_velocity) * 0.1
    reward -= np.abs(y_velocity) * 0.1
    reward -= np.abs(angle) * 0.5
    reward -= np.abs(angular_velocity) * 0.2
    if leg0_contact or leg1_contact:
        reward -= 0.5

    return max(reward, -0.1)";0.0151609841003612,0.01332133197424683,0.03023563018086436,0.024220783909807298,0.01429449678007611,0.01898045180339746,0.01722120471836339,0.03513717535149279,0.019491539949242753,0.013641563612031029,0.019893374937468993,0.03154754709423765,0.019265545936308696,0.019452716603750916,0.01437910954762051,0.017581969101914275,0.012917076290717434,0.027811951883341,0.020277505134654462,0.014325385615916944,0.02992040270803702,0.014266972385036145,0.015296791589939757,0.013986807359100769,0.05758564199946724,0.026625881175398377,0.017892316741247076,0.015176172047507203,0.018712193651908255,0.03400652159651183,0.03218596359973821,0.09059601772261137,0.13247434424213916,0.1023312164394016,0.18104903779328496,0.08603848152410132,0.10012593600064082,0.1375355009991454,0.08692013892340966,0.04066546693341868,0.016584432173348502,0.018177975215918404,0.17146936759626233,0.04369437543166581,0.03790524902433472,0.20395244171651877,0.15053509393585643,0.0771439633822682,0.05498197020578023,0.06374187928048457,0.041868803104151836,0.25572734987723994,0.03485144128388996,0.04163262531534921,0.2530151436282096,0.28571495329132535,0.20078481016911742,0.2845159716889962,0.28565908185107547,0.28176022332302875,0.2854710567148253,0.28830216088270305,0.2768594839211755,0.09853774552204511,0.01975371920332109,0.039352685518078294,0.02746759601994979,0.008439063398142939,0.009101347227297723,0.005487074024916041,0.008893985411137603,0.00708716463936274,0.008138831120828789,0.0170361232496823,0.007370258222418643,0.009971453278703265,0.007310412489544257,0.010269880432949215,0.018085625515023098,0.008711751218594613,0.007357919924463558,0.007873841094915492,0.00930458907383652,0.006023308277536287,0.005788512867505629,0.004152968358142143,0.0074532980260218675,0.008309508797824066,0.009410106978015422,0.007367744376200367,0.007207092891064633,0.006511027653405631,0.0074807785621588095,0.0063564134091391175,0.007665882013046667,0.007998327341157584,0.007418777040227813,0.005736379659841612,0.007080020444823951,0.006649427262300314,0.0061439912385385835,0.00773999737590819,0.007240109105209491,0.004283099724159186,0.00851077007528258,0.004221971196678294,0.006748871577678249,0.006212771183638406,0.005545989310872944,0.007513618463783578,0.0059980652222219105,0.007067879998113994,0.005850171507275988,0.005425269116726169,0.00747003506590318,0.0062731936033799665,0.0056846052653482994,0.007524580576843201,0.006405448832024667,0.005254636280693303,0.00520072906307946,0.006610966734036707,0.005598338708500402,0.007585141318568704,0.0073149213647928524,0.007523831084315819,0.00787893029919096,0.006048380220583911,0.005220663182801227,0.0067709385696486536,0.005398284705170073,0.005659784141152006,0.006137622226290049,0.005366137078705571,0.007292576507834332,0.0067955545559820335,0.005451311748267996,0.003687353245454785,0.007024167626138128,0.006719611170981676,0.00646483850157897,0.00546521103115226,0.007633534131148205,0.005455400808983208,0.0045104529249561515,0.0063699612194242925,0.004254770277298374,0.005805797773678659,0.008291852509369904,0.006512280764812822,0.004908576110225834,0.007229239533129473,0.0030622721793399353,0.006007828908163165,0.005206928125616151,0.0037793693109038308,0.006566496624199318,0.0047345783626528875,0.004717178410948214,0.005974881111049835,0.004808016234251617,0.005924038783929456,0.005632750356206405,0.006806358828331085,0.00487697241760477,0.004536586527532865,0.006099442773606451,0.0059034636713943215,0.003316842673936704,0.003312639826489881,0.006437043804262897,0.003715562192271111,0.005897660771887987,0.004332415967476408,0.005584730837379294,0.0060284458197042805,0.0052459029612205174,0.0058743158640230985,0.005721692278701631,0.005620243419843378,0.00667915660401596,0.0037070804769452257,0.003689308043753914,0.005906168871665431,0.004503166776041884,0.003973468842519641,0.003298096826538999,0.006836418167238761,0.006350655073279952,0.00608538501036311,0.00511934389918441,0.004592264169750187,0.005805271430068133,0.003432055701688013;0.03238177513561094;0.06407854410272178;0.0
data/model/LunarLander-v3_215642_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 215642};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 215642};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    x, y, vx, vy, angle, angular_velocity, left_contact, right_contact = observations
    altitude_reward = 1.0 / (y + 1) if y > 0 else -1.0
    velocity_penalty = np.abs(vx) + np.abs(vy)
    rotation_penalty = np.abs(angle) + np.abs(angular_velocity)
    leg_contact_penalty = left_contact + right_contact
    reward = altitude_reward - velocity_penalty - rotation_penalty - leg_contact_penalty
    if is_failure:
        return -10.0
    elif is_success:
        return 0.0
    else:
        return reward";-0.0878753946493361,-0.12603152041698953,-0.09320000331236192,-0.10853383783772014,-0.14372575948841915,-0.14298897247183437,-0.17666764261777176,-0.09908489156972955,-0.09098453156289278,-0.07126830665099021,-0.14525540030096187,-0.10841843580069993,-0.11708409758863855,-0.10398853896785414,-0.1402167237061203,-0.11520600008470624,-0.13165653433167995,-0.49559850547899753,-0.039642089608065555,-0.44774598634868396,-0.08177163997708474,-0.21014739844703595,-0.09953011249083775,-0.06350667767206152,-0.02150896775935251,-0.14924344886145224,-0.029543690558032708,-0.03456375503294936,-0.07108877899480419,-0.20870182253983577,-0.026215740919188168,-0.03306909212523364,-0.18765496677181315,-0.03825389158232178,0.02460982156502402,0.040788507679689084,0.12549888893674224,-0.003933519821320023,0.09339425825413826,0.11143048068084051,0.09995383270539483,0.15178459045616302,0.08018075654979666,0.1239640899382133,0.13854128224035203,0.12359937396112047;-0.06804697376913701;0.13080038148126705;0.0
data/model/LunarLander-v3_143855_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 143855};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 143855};30000;"def reward_func(observations:np.ndarray, is_success:bool, is_failure:bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x, y, dx, dy, angle, angular_velocity, leg0_contact, leg1_contact = observations
    position_reward = -np.abs(dx) - np.abs(dy)
    angle_reward = -np.abs(angle)
    contact_penalty = -5 * (leg0_contact + leg1_contact)
    failure_penalty = -20 if is_failure else 0
    success_reward = 10 if is_success else 0

    return position_reward + angle_reward + contact_penalty + failure_penalty + success_reward";-0.12894273037967183,-0.1485981496573903,-0.15266141313455664,-0.12297074007890949,-0.09682998121730081,-0.15606115106974902,-0.1291898149066996,-0.10987130778937272,-0.1370332397239907,-0.1971089225348331,-0.16065880908276428,-0.1300733388940284,-0.1319272943311173,-0.1712923194154873,-0.1780755925784189,-0.09694947315228897,-0.10913396959059603,-0.19024724226871695,-0.18526292530718183,-0.11496251114769958,-0.11341040210858247,-0.30159536281605653,-0.13623712246120429,-0.15574550615627963,-0.13209109966047103,-0.204307135115601,-0.12610684741587,-0.14194598069822087,-0.15209011286260163,-0.12056689530907158,-0.1484108142268262,-0.12231059434111828,-0.12147342033109351,-0.13782496358913088,-0.1283956845362539,-0.12721870587378442,-0.12919849064602595,-0.11929647727266877,-0.13282047400783412,-0.1342276027327659,-0.06990288480109036,-0.08667726253959585,-0.13404416807071548,-0.10555579749393282,-0.0864566121816839,-0.08062590407743898,-0.10382267808331343,-0.1123570384448185,-0.12005425105209178,-0.07493736750982696,-0.08921639964685768,-0.09744097384949423,-0.0753344282564766,-0.07021207183177124;-0.1303659714122471;0.03902860510266399;0.0
data/model/LunarLander-v3_600632_1.pth;LunarLander-v3;qwen2.5-coder:32b_llama3.2-vision;{'temperature': 0.9, 'seed': 600632};DQN;{'batch_size': 128, 'buffer_size': 50000, 'exploration_final_eps': 0.1, 'exploration_fraction': 0.12, 'gamma': 0.99, 'gradient_steps': -1, 'learning_rate': 0.00063, 'learning_starts': 0, 'policy': 'MlpPolicy', 'policy_kwargs': {'net_arch': [256, 256]}, 'target_update_interval': 250, 'train_freq': 4, 'tensorboard_log': 'data/model/LunarLanderDQN/', 'seed': 600632};30000;"def reward_func(observations: np.ndarray, is_success: bool, is_failure: bool) -> float:
    """"""Reward function for LunarLander-v3

    Args:
        observations (np.ndarray): observation on the current state
        is_success (bool): True if the goal is achieved, False otherwise
        is_failure (bool): True if the episode ends unsuccessfully, False otherwise

    Returns:
        float: The reward for the current step
    """"""
    x_velocity = abs(observations[2])
    y_velocity = abs(observations[3])
    angle = abs(observations[4])
    angular_velocity = abs(observations[5])
    leg_contact_1 = observations[6]
    leg_contact_2 = observations[7]

    if is_success:
        return -1.0
    elif is_failure:
        return -1.0

    reward = 0.0
    reward -= x_velocity * 0.01
    reward -= y_velocity * 0.01
    reward -= angle * 0.05
    reward -= angular_velocity * 0.1
    if leg_contact_1 or leg_contact_2:
        reward -= 0.1

    return reward";-0.13048719653396054,-0.10608525893194304,-0.08027530501312771,-0.06436581016590978,-0.0861157747019454,-0.14372980525701215,-0.08836973750494229,-0.1325420689202838,-0.19486143030590794,-0.078757519479569,-0.11966551660166584,-0.05606246236345092,-0.05498142343539785,-0.08369140795201084,-0.11639033685164696,-0.08763390418198558,-0.0902482611977183,-0.27687595336861565,-0.05656452554238749,-0.059927683660633675,-0.17787126080545276,-0.06727741419823924,-0.04818804042290453,-0.0643941992432838,-0.04598623098477065,-0.09042353115815144,-0.0645490459204202,-0.0616484395437743,-0.06303973246815792,-0.06911883483856944,-0.10383174587212149,-0.12244291406306324,-0.06663973375802451,-0.09008636747786139,-0.1314089955726963,-0.1957183045250221,-0.0743783213842952,-0.09520595656673146,-0.1815487855006718,-0.07803054016933493,-0.05986070998393623,-0.060467298026795686,-0.200601945817161,-0.11738196556346325,-0.058445465983711524,-0.0673794045701145,-0.09108149410683067,-0.0551396557675778,-0.07382704030558725,-0.06431681027077005,-0.06358144540645957,-0.057451305790563276,-0.0662553822681887,-0.060060351544197546,-0.1410225265672085,-0.06788874294269934,-0.07383302044583744,-0.10764362911826142,-0.054304127664421206,-0.09605194420552121,-0.06289881745530505,-0.11035005032541444,-0.05014778791007139,-0.07807118681904655,-0.05006970770717366,-0.06420492279242569,-0.057011973554962785,-0.0708559960806844,-0.05234531431559649,-0.055094445337556884,-0.06427974364848649,-0.058993343161020444,-0.06405018747881934,-0.13165578993867538,-0.058151743489254566,-0.10633236261251706,-0.11331314666974694,-0.061167776328542464,-0.0756198842018111,-0.10991768756095094,-0.1487381252107908,-0.07979104616232803,-0.07629308164208441,-0.08540293822941264,-0.11495581837814604,-0.17963594472686445,-0.1323630462242344,-0.07589856493068678,-0.15654994889617727,-0.12076520612864816,-0.08925649806144037,-0.146165227104695,-0.08783942404871146,-0.05968889732363883,-0.0563112948203072,-0.0599338248817116,-0.09804816101266169,-0.12973871537038906;-0.09212164972789752;0.04144494280444382;0.0
